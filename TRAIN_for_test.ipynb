{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1a372d6-8211-4693-a595-48313ffd82c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<weakproxy at 0x7f50d09f9620; to 'numba.cuda.cudadrv.driver.Device' at 0x7f50d09a6120>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "gpu_device = 0    # número identificador del device puede ser: 0, 1, 2, o 3\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpu_device)\n",
    "from numba import cuda\n",
    "cuda.select_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9d7ad08-5e44-4ca4-bd4a-66cae055ccc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcarrilero/pytorch_env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from datasets import Dataset,concatenate_datasets,load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307c3e2c-0c90-4a75-972b-291d7642dbd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "497e3ee4-3b55-4712-bd04-07af1e70f700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "ground_truth=pd.read_excel(\"data/data_corrected_english.xlsx\",index_col=\"Report\")\n",
    "ground_truth=ground_truth[ground_truth[\"Eliminar\"]!=\"Yes\"]\n",
    "\n",
    "with open(\"data/report_data_q_a_ingles_v2.pkl\", 'rb') as file:  # 'rb' mode is for reading binary files\n",
    "    report_data = pickle.load(file)\n",
    "\n",
    "def fix_brackets_spaces(texto):\n",
    "    ''' \n",
    "        Introduce espacios por delante y por detrás de los paréntesis.\n",
    "        Esta medida mejora el tokenizado de Spacy\n",
    "    '''\n",
    "    \n",
    "    texto = re.sub(r'([(\\[¿!])', r' \\1', texto)\n",
    "    texto = re.sub(r'([)\\]?¡])', r'\\1 ', texto)\n",
    "                \n",
    "    return texto\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text= fix_brackets_spaces(text)\n",
    "    return text\n",
    "\n",
    "def visualize_errors(valid_dataset,valid_targets,validation_predictions,keys):\n",
    "    # Crear un DataFrame con los textos originales, las etiquetas reales y las predicciones\n",
    "    results_df = pd.DataFrame({\n",
    "        'key':list(keys),\n",
    "        'Text': list(valid_dataset),  # Usamos los textos originales\n",
    "        'True Label': list(valid_targets),\n",
    "        'Predicted Label': list(validation_predictions)\n",
    "    })\n",
    "    \n",
    "    # Filtrar los ejemplos en los que el modelo falló\n",
    "    errors_df = results_df[results_df['True Label'] != results_df['Predicted Label']]\n",
    "    \n",
    "    for ind,row in errors_df.iterrows():\n",
    "        print(row[\"key\"])\n",
    "        print(\"EJEMPLO\")\n",
    "        print(row[\"Text\"])\n",
    "        print(\"PREDICTED\")\n",
    "        print(row[\"Predicted Label\"])\n",
    "        print(\"TRUE\")\n",
    "        print(row[\"True Label\"])\n",
    "\n",
    "\n",
    "def train_clean(X,Y):\n",
    "    random.seed(1)\n",
    "    # Agrupar ejemplos originales y sus copias\n",
    "    train = X\n",
    "    # Barajar los datos de entrenamiento para evitar sesgos\n",
    "    train = train.sample(frac=1, random_state=1)\n",
    "    train_y = Y.loc[train.index]\n",
    "    train[\"label\"]=train_y[\"label\"]\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29e1343a-ffaf-4d20-91a9-3ca34ade7058",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions=[\"age\",\"tipo\",\"tecnica\",\"family\",\"history\",\"symtomatic\",\n",
    "           \"prosthesis\",\"birads\",\"density_mammo\",\"calcifications_benign\",\"density_echo\",\"ganglio_mamo\",\"lymph_benign\",\"lymph_suspicious\",\"parenchymal_distortion\",\"simple_cyst\",\"ductal_ectasia\",\n",
    "          \"nodules_echo_num\",\"nodules_echo_description\",\"nodules_echo_shape\",\"nodules_echo_margin\",\"nodules_echo_echogenicity\",\"nodules_echo_location\",\"nodules_echo_size\",\"nodules_echo_known\",\"nodules_echo_stable\"]\n",
    "\n",
    "\n",
    "\n",
    "TIPO=[\"biopsy report\", \"nodal staging ultrasound report\", \"normal control or revision report\"]\n",
    "TECNICA=[\"only ultrasound study\", \"only mammography study\", \"mammography and ultrasound\"]\n",
    "FAMILY=[\"no family history\", \"first degree\", \"second degree\"]\n",
    "PROSTHESIS=[\"no prosthesis\",\"yes prosthesis\"]\n",
    "BIRADS=[\"BI-RADS 0\",\"BI-RADS 1\",\"BI-RADS 2\",\"BI-RADS 3\",\"BI-RADS 4A\",\"BI-RADS 4B\",\"BI-RADS 4C\",\"BI-RADS 5\",\"BI-RADS 6\"]\n",
    "DENSITY_MAMMO=[\"ACR A\",\"ACR B\",\"ACR C\",\"ACR D\",\"unknown density mammo\"]\n",
    "CALCIFICATIONS_BENIGN=[\"no calcifications\",\"yes calcifications\"]\n",
    "GANGLIO_MAMO=[\"no ganglio\",\"yes ganglio\"]\n",
    "DENSITY_ECHO=[\"homogeneous fibroglandular\",\"heterogeneous fibroglandular\",\"fibroglandular and fat\",\"homogeneous fatty\",\"unknown density echo\"]\n",
    "LYMPH_BENIGN=[\"no lymph benign\",\"yes lymph benign\"]\n",
    "LYMPH_SUSPICIOUS=[\"no lymph suspicious\",\"yes lymph suspicious\"]\n",
    "SIMPLE_CYST=[\"no cyst\",\"yes cyst\"]\n",
    "DUCTAL_ECTASIA=[\"no ectasia\",\"yes ectasia\"]\n",
    "NODULES_ECHO=[\"no nodules\", \"yes nodules\"]\n",
    "NODULES_SHAPE=[\"oval\",\"round\",\"lobulated\",\"irregular\",\"unknown shape\"]\n",
    "NODULES_MARGIN=[\"circumscribed\",\"spiculated\",\"indistinct\",\"not circumscribed\",\"unknown margin\"]\n",
    "NODULES_ECHOGENICITY=[\"hypoechoic\", \"isoechoic\", \"heterogeneous\",\"complex cystic and solid\",\"unknown echogenicity\"]\n",
    "NODULES_KNOWN=[\"no known\", \"yes known\"]\n",
    "NODULES_STABLE=[\"grown stable\",\"shrunk stable\", \"yes stable\"]\n",
    "\n",
    "\n",
    "import gc\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "def flatten_and_filter_dataset(ground_truth,reports):\n",
    "    \"\"\"\n",
    "    Esta función toma un conjunto de datos en el formato original (con estructura jerárquica)\n",
    "    y devuelve un conjunto de datos plano, donde cada entrada tiene un solo `context`, `question` y `answer`.\n",
    "    \n",
    "    Argumentos:\n",
    "        dataset: Un conjunto de datos en formato original (puede ser train, validation, test).\n",
    "    \n",
    "    Retorno:\n",
    "        Un conjunto de datos de Hugging Face en formato plano, con solo ejemplos completos.\n",
    "    \"\"\"\n",
    "    # Lista para almacenar ejemplos en formato plano\n",
    "    flattened_examples = {}\n",
    "    examples_raw={}\n",
    "    targets={}\n",
    "    val_data={}\n",
    "    question_tipo={}\n",
    "    previous_message_answer_tipo={}\n",
    "    options_tipo={}\n",
    "    answers_tipo={}\n",
    "    j=0\n",
    "    \n",
    "    question_tipo[\"age\"]= \"does the patient's age appear in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"age\"]=\"search for numbers, but do not mistake it with the age of a familiar. If a number appears without any context between two dots it is surely the age.\"\n",
    "    options_tipo[\"age\"]=\"answer only the age of the patient.\"\n",
    "\n",
    "    question_tipo[\"tipo\"]= 'is the following breast medical report a biopsy report or a nodal staging ultrasound report?'\n",
    "    previous_message_answer_tipo[\"tipo\"]=\"biopsy reports are normally Image-Guided Biopsy and is normally said that they are referred to the hospital for biopsy. Nodal staging ultrasound reports can also be written as 'axilla ultrasound'. If it is any of these it will be written in the beginning of the report, normally in the used technique. These kind of reports are only ultrasound. In these reports no final BI-RADS is given.\"\n",
    "    options_tipo[\"tipo\"]=\"answer with one of the following options: 'biopsy report', 'nodal staging ultrasound report' or 'normal control or revision report'.\"\n",
    "\n",
    "    question_tipo[\"tecnica\"]= 'what diagnostic technique was used in the following breast medical report?'\n",
    "    previous_message_answer_tipo[\"tecnica\"]=\"biopsy reports, simple cysts and analysis of lymph or axillary nodes are only seen on ultrasound. On the other hand, if the ACR density is given or parenchymal distortions are analysed, the technique will be a mammogram. Tomosyntesis is a mammography type. The report may include an ultrasound examination, a mammography examination or both.\"\n",
    "    options_tipo[\"tecnica\"]=\"answer with one of the following options: 'only ultrasound study', 'only mammography study' or 'mammography and ultrasound'.\"\n",
    "\n",
    "    question_tipo[\"family\"]= \"does the patient have any family history in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"family\"]=\"family history of breast cancer is categorized based on the degree of relatives affected: First-degree relatives: Parents, siblings, or children. Second-degree relatives: Grandparents, aunts, uncles, nieces, nephews, or half-siblings. Third-degree relatives: Great-grandparents, great-aunts/uncles, or first cousins.\"\n",
    "    options_tipo[\"family\"]=\"answer with one of the following options: 'first degree', 'second degree', 'third degree' or 'no family history'.\"\n",
    "    \n",
    "    question_tipo[\"history\"]= \"does the patient have any non-familiar history in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"history\"]=\"check for the history at the beginning of the report. Normally it is a previous biopsy result, mastectomy or cancer. It normally starts with 'history of ...'.\"\n",
    "    options_tipo[\"history\"]=\"answer retrieving the information directly from the report or with 'no history was found'.\"\n",
    "    \n",
    "    question_tipo[\"symtomatic\"]= \"is the reason for the consultation that the patient is symptomatic in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"symtomatic\"]=\"the answer is at the beginning of the report, in the reason for consultation. It is normally a palpable lump, lumpectomy or nodule, sometimes painful.\"\n",
    "    options_tipo[\"symtomatic\"]=\"answer retrieving the information directly from the report or with 'non-symptomatic consultation'.\"\n",
    "    \n",
    "    question_tipo[\"prosthesis\"]= \"does the patient have a prosthesis in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"prosthesis\"]=\"it is normally clearly indicated at the beginning of the report. Sometimes it is written as implants instead of prosthesis.\"\n",
    "    options_tipo[\"prosthesis\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "    \n",
    "    question_tipo[\"birads\"]= \"what is the final BI-RADS classification given to the patient in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"birads\"]=\"the final BI-RADS of the patient is given in the conclusions of the report, normally at the end.\"\n",
    "    options_tipo[\"birads\"]=\"answer with one of the following options: 'BI-RADS 0', 'BI-RADS 1', 'BI-RADS 2', 'BI-RADS 3', 'BI-RADS 4A', 'BI-RADS 4B', 'BI-RADS 4C', 'BI-RADS 5' or 'unknown'.\"\n",
    "\n",
    "    question_tipo[\"density_mammo\"]= \"what is the breast density found in the mammography study of the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"density_mammo\"]=\"breast density in mammography is classified into four categories: ACR A (= Almost entirely fatty), ACR B (= Scattered areas of fibroglandular density), ACR C (= Heterogeneously dense), ACR D (= Extremely or very dense breasts). Sometimes it is written as 'density type x'. It can also be written with their real meaning (very dense breasts = C) and not with the A, B, C, D classification. Focus only on density.\"\n",
    "    options_tipo[\"density_mammo\"]=\"answer with one of the following options: 'ACR A', 'ACR B', 'ACR C', ACR D' or 'unknown'.\"\n",
    "   \n",
    "    question_tipo[\"density_echo\"]= \"what is the breast density found in the ultrasound study of the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"density_echo\"]=\"breast composition in ultrasound is classified into three categories: fibroglandular and fat (mixed distribution of fibroglandular and adipose tissue), heterogeneous fibroglandular (predominantly fibroglandular tissue with varying echogenicity and scattered fat areas), homogeneous fatty (uniform fatty tissue with consistent echogenicity and minimal fibroglandular content), and homogeneous fibroglandular (uniform fibroglandular tissue with consistent echogenicity and minimal fat content).\"\n",
    "    options_tipo[\"density_echo\"]=\"answer with one of the following options: 'fibroglandular and fat', 'heterogeneous fibroglandular', 'homogeneous fibroglandular', 'homogeneous fatty' or 'unknown'.\"\n",
    "\n",
    "    question_tipo[\"calcifications_benign\"]= \"does the following breast medical report mention the appearence of benign calcifications in the mammography exam?\"\n",
    "    previous_message_answer_tipo[\"calcifications_benign\"]=\"Consider only benign calcifications in the mammography.\"\n",
    "    options_tipo[\"calcifications_benign\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "    \n",
    "    question_tipo[\"ganglio_mamo\"]= \"does the following breast medical report mention any lymph nodes in the mammography exam?\"\n",
    "    previous_message_answer_tipo[\"ganglio_mamo\"]=\"Consider only lymph nodes that appear in the mammography.\"\n",
    "    options_tipo[\"ganglio_mamo\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "\n",
    "    question_tipo[\"parenchymal_distortion\"]= \"does the following breast medical report mention any parenchymal distortion or asymmetry in the mammography exam?\"\n",
    "    previous_message_answer_tipo[\"parenchymal_distortion\"]=\"If it has any it will appear in the results of the mammography exam using the words distortion, asymmetry or sometimes it can also be surgical changes.\"\n",
    "    options_tipo[\"parenchymal_distortion\"]=\"answer retrieving the information directly from the report or with 'no'\"\n",
    "    \n",
    "    question_tipo[\"lymph_suspicious\"]= \"does the following breast medical report mention any suspicious axillary lymph nodes in the ultrasound exam?\"\n",
    "    previous_message_answer_tipo[\"lymph_suspicious\"]=\"if a lymph node is suspicious the report will recomend a biopsy or Fine Needle Aspiration. A lymph node is considered suspicious when it has eccentric cortical thickening ≥ 3 mm, Short axis >10 mm, round shape, loss of fatty hilum, abnormal vascularity, or irregular margins—especially when associated with known malignancy or progressive enlargement. They can also be classified as UN3, UN4 or UN5. An exam may have both suspicious and benign lymph nodes, answer 'yes' in this case.\"\n",
    "    options_tipo[\"lymph_suspicious\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "\n",
    "    question_tipo[\"lymph_benign\"]= \"does the following breast medical report mention any benign or not suspicious axillary lymph nodes in the ultrasound exam?\"\n",
    "    previous_message_answer_tipo[\"lymph_benign\"]=\"if a lymph node is suspicious the report will recomend a biopsy or Fine Needle Aspiration. A lymph node is considered benign when it has uniform cortex < 3 mm, preserved fatty hilum, oval shape, no abnormal vascularity, no irregular margins and homogeneous internal echo pattern. Benign axillary nodes can be classified as UN1 or UN2. A reactive axillary node is not suspicious. An exam may have both suspicious and benign lymph nodes, answer 'yes' in this case.\"\n",
    "    options_tipo[\"lymph_benign\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "\n",
    "    question_tipo[\"simple_cyst\"]= \"does the following breast medical report mention any simple cysts or microcysts in the ultrasound exam?\"\n",
    "    previous_message_answer_tipo[\"simple_cyst\"]=\"The words symple cysts or microcysts will appear only in the ultrasound exam. Sometimes they can say that some of the cysts have echogenic content, but we still will consider them simple cysts and not nodules.\"\n",
    "    options_tipo[\"simple_cyst\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "\n",
    "    question_tipo[\"ductal_ectasia\"]= \"does the following breast medical report mention any ductal ectasia in the ultrasound exam?\"\n",
    "    previous_message_answer_tipo[\"ductal_ectasia\"]=\"The word ductal ectasia will appear only in the ultrasound exam.\"\n",
    "    options_tipo[\"ductal_ectasia\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "    \n",
    "    question_tipo[\"nodules_echo_num\"]=\"is there any nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"nodules_echo_num\"]=\"do not consider if a nodule is described in the mammography exam or if it is in the axilla. The localization, echogenicity and size of the nodules are normally said.\"\n",
    "    options_tipo[\"nodules_echo_num\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "\n",
    "    \n",
    "    dic_order = {\n",
    "        1: \"first\",\n",
    "        2: \"second\",\n",
    "        3: \"third\",\n",
    "        4: \"fourth\",\n",
    "        5: \"fifth\",\n",
    "        6: \"sixth\",\n",
    "        7: \"seventh\",\n",
    "        8: \"eighth\",\n",
    "        9: \"ninth\",\n",
    "        10: \"tenth\",\n",
    "        11: \"eleventh\",\n",
    "        12: \"twelfth\",\n",
    "        13: \"thirteenth\",\n",
    "        14: \"fourteenth\",\n",
    "        15: \"fifteenth\"\n",
    "    }\n",
    "    for i in range(1,2):\n",
    "        question_tipo[f\"nodules_echo_description_{i}\"]= f\"which is the {dic_order[i]} nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_description_{i}\"]=\"do not consider if a nodule is described in the mammography exam or if it is in the axilla. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "        options_tipo[f\"nodules_echo_description_{i}\"]=\"answer retrieving the information directly from the report.\"\n",
    "        \n",
    "        question_tipo[f\"nodules_echo_shape_{i}\"]= f\"what is the shape of the {dic_order[i]} nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_shape_{i}\"]=\"do not consider if a nodule is described in the mammography exam or if it is in the axilla. Shapes can be 'oval', 'round', 'lobulated' and 'irregular'. Sometimes irregular is also used for the margin, but in this case it is written as 'irregular margin' or 'irregular borders'. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "        options_tipo[f\"nodules_echo_shape_{i}\"]=\"answer with one of the following options: 'oval', 'round', 'lobulated', 'irregular' or 'unknown'.\"\n",
    "        \n",
    "        question_tipo[f\"nodules_echo_margin_{i}\"]= f\"what is the margin of the {dic_order[i]} nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_margin_{i}\"]=\"do not consider if a nodule is described in the mammography exam or if it is in the axilla. Margin can be 'circumscribed' and 'not circumscribed'. Inside the not circumscribed we have 'spiculated', 'angulated', 'microlobulated' or 'indistinc' ('not defined') margins. Sometimes irregular is also used for the margin, but in this case it is written as 'irregular margin' or 'irregular borders', in this case classify it as 'not circumscribed'. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "        options_tipo[f\"nodules_echo_margin_{i}\"]=\"answer with one of the following options: 'circumscribed', 'not circumscribed', 'indefined', 'spiculated', 'angulated', 'microlobulated' or 'unknown'.\"\n",
    "        \n",
    "        question_tipo[f\"nodules_echo_echogenicity_{i}\"]= f\"what is the echogenicity of the {dic_order[i]} nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_echogenicity_{i}\"]=\"do not consider if a nodule is described in the mammography exam or if it is in the axilla. Echogenicity can be 'anechoic', 'hypoechoic', 'heterogeneous' and 'complex cystic and solid'. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\" \n",
    "        options_tipo[f\"nodules_echo_echogenicity_{i}\"]=\"answer with one of the following options: 'hypoechoic', 'heterogeneous', 'anechoic', 'hyperecoic', 'isoechoic', 'complex cystic and solid' or 'unknown'.\"\n",
    "        \n",
    "        question_tipo[f\"nodules_echo_location_{i}\"]= f\"In which location is the {dic_order[i]} nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_location_{i}\"]=\"do not consider if a nodule is described in the mammography exam or if it is in the axilla. If the nodule is mentioned previously in the mammography, the location can be found also there. sometimes the breast location of the tumour may be written in a different part than the quadrant. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "        options_tipo[f\"nodules_echo_location_{i}\"]=\"answer retrieving the information directly from the report or with 'unknown'.\"\n",
    "        \n",
    "        question_tipo[f\"nodules_echo_size_{i}\"]= f\"what is the size of the {dic_order[i]} nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_size_{i}\"]=\"do not consider if a nodule is described in the mammography exam. The localization, echogenicity and size of the nodules are normally said. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "        options_tipo[f\"nodules_echo_size_{i}\"]=\"answer retrieving the information directly from the report (stop after 'mm') or with 'unknown'.\"\n",
    "        \n",
    "        question_tipo[f\"nodules_echo_known_{i}\"]= f\"is the {dic_order[i]} nodule described in the ultrasound exam of the following breast medical report previously known?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_known_{i}\"]=\"do not consider if a nodule is described in the mammography exam. If the nodule is known from before the report, it will say if it it is stable or if it has grown or shrink. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "        options_tipo[f\"nodules_echo_known_{i}\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "        \n",
    "        question_tipo[f\"nodules_echo_stable_{i}\"]= f\"is the {dic_order[i]} known nodule described in the ultrasound exam stable in the following breast medical report?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_stable_{i}\"]=\"do not consider if a nodule is described in the mammography exam. If the nodule is known from before the examination, it will be analysed to see if it is stable or if it got bigger or smaller. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "        options_tipo[f\"nodules_echo_stable_{i}\"]=\"answer with one of the following options: 'yes', 'grown' or 'shrunk.\"\n",
    "    for i, report in enumerate(reports[\"informes_ingles\"]):\n",
    "        informe=preprocess_text(report)\n",
    "        key=reports[\"keys\"][i]\n",
    "        \n",
    "        if key not in ground_truth.index:\n",
    "            continue\n",
    "        \n",
    "        row=ground_truth.loc[key]\n",
    "\n",
    "        #AGE\n",
    "        age=str(row[\"Age\"])\n",
    "        answer_tipo={}\n",
    "        # Verificar si el ejemplo tiene preguntas\n",
    "        if age.isdigit():\n",
    "            answer_tipo[\"age\"]=age+\".\"\n",
    "            \n",
    "        else:\n",
    "            answer_tipo[\"age\"]=\"no\"+\".\"\n",
    "        \n",
    "        #TIPO\n",
    "        if row[\"Biopsy_report\"]==\"Yes\":\n",
    "            answer_tipo[\"tipo\"]=\"biopsy report\"+\".\"\n",
    "            \n",
    "        elif row[\"Ganglio_report\"]==\"Yes\":\n",
    "            answer_tipo[\"tipo\"]=\"nodal staging ultrasound report\"+\".\"\n",
    "        else:\n",
    "            answer_tipo[\"tipo\"]=\"normal control or revision report\"+\".\"\n",
    "        \n",
    "        #TECHNIQUE\n",
    "        tecnica=row[\"Technique\"]\n",
    "        # Verificar si el ejemplo tiene preguntas\n",
    "        if tecnica==\"ultrasound\":\n",
    "            answer_tipo[\"tecnica\"]=\"only ultrasound study\"+\".\"            \n",
    "        elif tecnica==\"mammography\":\n",
    "            answer_tipo[\"tecnica\"]=\"only mammography study\"+\".\"\n",
    "        elif not pd.isna(tecnica):\n",
    "            answer_tipo[\"tecnica\"]=tecnica+\".\"\n",
    "        else:\n",
    "            print(key,report)\n",
    "        \n",
    "        # \n",
    "        # HISTORY\n",
    "        #No consideramos las biopsias o las ecografías de estadificación ganglionar.\n",
    "        if answer_tipo[\"tipo\"]==\"normal control or revision report\"+\".\":\n",
    "            history=row[\"Other_history\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(history,str) or history==\"No\":\n",
    "                answer_tipo[\"history\"]=\"no history was found\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"history\"]=history+\".\" \n",
    "    \n",
    "            # FAMILY\n",
    "            family=row[\"Family_history\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(family,str) or family==\"No\":\n",
    "                answer_tipo[\"family\"]=\"no family history\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"family\"]=family+\".\" \n",
    "    \n",
    "            # SYMTOMATIC\n",
    "            symtomatic=row[\"Syntomatic\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(symtomatic,str) or symtomatic==\"No\" or symtomatic==\"No estoy seguro\":\n",
    "                answer_tipo[\"symtomatic\"]=\"Non-symptomatic consultation\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"symtomatic\"]=symtomatic+\".\" \n",
    "    \n",
    "            # PROSTHESIS\n",
    "            prosthesis=row[\"Prosthesis\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(prosthesis,str) or prosthesis==\"No\":\n",
    "                answer_tipo[\"prosthesis\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"prosthesis\"]=\"yes\"+\".\"\n",
    "    \n",
    "            #BIRADS\n",
    "            birads=row[\"BI-RADS\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(birads,str):\n",
    "                answer_tipo[\"birads\"]=\"unknown\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"birads\"]=birads+\".\"\n",
    "    \n",
    "            #Density mammo\n",
    "            density_mammo=row[\"Density_mamo\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(density_mammo,str):\n",
    "                answer_tipo[\"density_mammo\"]=\"unknown\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"density_mammo\"]=density_mammo+\".\"\n",
    "\n",
    "            #Lymp nodes mammo\n",
    "            ganglio_mamo=row[\"Ganglio_mamo\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(ganglio_mamo,str):\n",
    "                answer_tipo[\"ganglio_mamo\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"ganglio_mamo\"]=ganglio_mamo.lower()+\".\"\n",
    "\n",
    "            #Calcifications benign\n",
    "            calcifications_benign=row[\"Calcifications_benign_mamo\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(calcifications_benign,str):\n",
    "                answer_tipo[\"calcifications_benign\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"calcifications_benign\"]=calcifications_benign.lower()+\".\"\n",
    "\n",
    "            #Parenchymal distortion\n",
    "            parenchymal_distortion=row[\"parenchymal_distortions_asymmetry\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(parenchymal_distortion,str):\n",
    "                answer_tipo[\"parenchymal_distortion\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"parenchymal_distortion\"]=parenchymal_distortion.lower()+\".\"\n",
    "    \n",
    "            #Density echo\n",
    "            density_echo=row[\"Density_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(density_echo,str):\n",
    "                answer_tipo[\"density_echo\"]=\"unknown\"+\".\"            \n",
    "            else:\n",
    "                if density_echo in DENSITY_ECHO:\n",
    "                    answer_tipo[\"density_echo\"]=density_echo+\".\"\n",
    "\n",
    "            #Benign lymph nodes\n",
    "            simple_cyst=row[\"simple_cyst_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(simple_cyst,str):\n",
    "                answer_tipo[\"simple_cyst\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"simple_cyst\"]=simple_cyst.lower()+\".\"\n",
    "            #Suspicious lymph nodes\n",
    "            lymph_suspicious=row[\"Ganglio_suspicious_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(lymph_suspicious,str):\n",
    "                answer_tipo[\"lymph_suspicious\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"lymph_suspicious\"]=lymph_suspicious.lower()+\".\"\n",
    "\n",
    "            #Benign lymph nodes\n",
    "            lymph_benign=row[\"Ganglio_benign_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(lymph_benign,str):\n",
    "                answer_tipo[\"lymph_benign\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"lymph_benign\"]=lymph_benign.lower()+\".\"\n",
    "\n",
    "            #Ductal ectasia\n",
    "            ductal_ectasia=row[\"Ductal_ectasia_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(ductal_ectasia,str):\n",
    "                answer_tipo[\"ductal_ectasia\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"ductal_ectasia\"]=ductal_ectasia.lower()+\".\"\n",
    "    \n",
    "            #Nodules echo\n",
    "            nodules_echo_num=row[\"Nodules_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(nodules_echo_num,str) and not isinstance(nodules_echo_num,int):\n",
    "                answer_tipo[\"nodules_echo_num\"]=\"no\"+\".\"    \n",
    "            elif isinstance(nodules_echo_num,str) and nodules_echo_num==\"No\":\n",
    "                answer_tipo[\"nodules_echo_num\"]=\"no\"+\".\"  \n",
    "            else:\n",
    "                answer_tipo[\"nodules_echo_num\"]=\"yes\"+\".\"\n",
    "    \n",
    "            #Si existen nódulos se hace las preguntas correspondientes\n",
    "            if answer_tipo[\"nodules_echo_num\"]!=\"no.\":\n",
    "                nodules_echo_description=row[\"Description_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                \n",
    "                answer_tipo[\"nodules_echo_description_1\"]=nodules_echo_description+\".\"\n",
    "                    \n",
    "                nodules_echo_shape=row[f\"Shape_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_echo_shape,str):\n",
    "                    answer_tipo[\"nodules_echo_shape_1\"]=\"unknown\"+\".\"\n",
    "                else:\n",
    "                    answer_tipo[\"nodules_echo_shape_1\"]=nodules_echo_shape.lower()+\".\"\n",
    "\n",
    "                nodules_echo_margin=row[\"Margin_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_echo_margin,str):\n",
    "                    answer_tipo[\"nodules_echo_margin_1\"]=\"unknown\"+\".\"\n",
    "                else:\n",
    "                    answer_tipo[\"nodules_echo_margin_1\"]=nodules_echo_margin.lower()+\".\"\n",
    "\n",
    "                nodules_echo_echogenicity=row[\"Echogenicity_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_echo_echogenicity,str):\n",
    "                    answer_tipo[\"nodules_echo_echogenicity_1\"]=\"unknown\"+\".\"\n",
    "                else:\n",
    "                    answer_tipo[\"nodules_echo_echogenicity_1\"]=nodules_echo_echogenicity.lower()+\".\"\n",
    "\n",
    "                nodules_echo_location=row[f\"Location_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_echo_location,str):\n",
    "                    answer_tipo[\"nodules_echo_location_1\"]=\"unknown\"+\".\"\n",
    "                else:\n",
    "                    answer_tipo[\"nodules_echo_location_1\"]=nodules_echo_location.lower()+\".\"\n",
    "\n",
    "                \n",
    "                #Nodules echo size\n",
    "                nodules_echo_size=row[\"size_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_echo_size,str):\n",
    "                    answer_tipo[\"nodules_echo_size_1\"]=\"unknown\"+\".\"            \n",
    "                else:\n",
    "                    answer_tipo[\"nodules_echo_size_1\"]=nodules_echo_size+\".\"\n",
    "        \n",
    "                #Nodules echo known\n",
    "                nodules_echo_known=row[\"new_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_echo_known,str):\n",
    "                    answer_tipo[\"nodules_echo_known_1\"]=\"unknown\"+\".\"\n",
    "                elif nodules_echo_known==\"No\":\n",
    "                    answer_tipo[\"nodules_echo_known_1\"]=\"yes\"+\".\"            \n",
    "                else:\n",
    "                    answer_tipo[\"nodules_echo_known_1\"]=\"no\"+\".\"\n",
    "    \n",
    "                if answer_tipo[\"nodules_echo_known_1\"]==\"yes.\":\n",
    "                    #Nodules echo stable\n",
    "                    nodules_echo_stable=row[\"Stable_eco_1\"]\n",
    "                    # Verificar si el ejemplo tiene preguntas\n",
    "                    if not isinstance(nodules_echo_stable,str):\n",
    "                        answer_tipo[\"nodules_echo_stable_1\"]=\"unknown\"+\".\"\n",
    "                    else:\n",
    "                        answer_tipo[\"nodules_echo_stable_1\"]=nodules_echo_stable.lower()+\".\"\n",
    "            \n",
    "        for tipo in answer_tipo:\n",
    "            #Si está el tipo en las respuestas que hemos recogido lo metemos a la base de datos.\n",
    "            key_tipo=key+\"_\"+tipo\n",
    "            if key_tipo in flattened_examples:\n",
    "                continue\n",
    "                key_tipo=key_tipo+\"_copy\"\n",
    "            examples_raw[key_tipo]=report\n",
    "            answer=str(answer_tipo[tipo])\n",
    "            \n",
    "    \n",
    "            inputs_tipo = \"Question: \" + question_tipo[tipo]+ \" Context: \" + informe +\" Answer: \"+ str(answer_tipo[tipo])\n",
    "            flattened_examples[key_tipo]=inputs_tipo\n",
    "            targets[key_tipo]=answer\n",
    "            \n",
    "            val_data[key_tipo]=\"Question: \" + question_tipo[tipo]+  \" Context: \" + informe+  \" Answer: \"\n",
    "    return flattened_examples,targets,val_data,examples_raw\n",
    "\n",
    "def flatten_and_filter_dataset(ground_truth,reports):\n",
    "    \"\"\"\n",
    "    Esta función toma un conjunto de datos en el formato original (con estructura jerárquica)\n",
    "    y devuelve un conjunto de datos plano, donde cada entrada tiene un solo `context`, `question` y `answer`.\n",
    "    \n",
    "    Argumentos:\n",
    "        dataset: Un conjunto de datos en formato original (puede ser train, validation, test).\n",
    "    \n",
    "    Retorno:\n",
    "        Un conjunto de datos de Hugging Face en formato plano, con solo ejemplos completos.\n",
    "    \"\"\"\n",
    "    # Lista para almacenar ejemplos en formato plano\n",
    "    flattened_examples = {}\n",
    "    examples_raw={}\n",
    "    targets={}\n",
    "    val_data={}\n",
    "    question_tipo={}\n",
    "    previous_message_answer_tipo={}\n",
    "    options_tipo={}\n",
    "    answers_tipo={}\n",
    "    j=0\n",
    "    \n",
    "    question_tipo[\"tecnica\"]= 'what diagnostic technique was used in the following breast medical report?'\n",
    "    previous_message_answer_tipo[\"tecnica\"]=\"biopsy reports, simple cysts and analysis of lymph or axillary nodes are only seen on ultrasound. On the other hand, if the ACR density is given or parenchymal distortions are analysed, the technique will be a mammogram. Tomosyntesis is a mammography type. The report may include an ultrasound examination, a mammography examination or both.\"\n",
    "    options_tipo[\"tecnica\"]=\"answer with one of the following options: 'only ultrasound study', 'only mammography study' or 'mammography and ultrasound'.\"\n",
    "\n",
    "    for i, report in enumerate(reports[\"informes_ingles\"]):\n",
    "        informe=preprocess_text(report)\n",
    "        key=reports[\"keys\"][i]\n",
    "        \n",
    "        if key not in ground_truth.index:\n",
    "            continue\n",
    "        \n",
    "        row=ground_truth.loc[key]\n",
    "        answer_tipo={}\n",
    "\n",
    "        #TECHNIQUE\n",
    "        tecnica=row[\"Technique\"]\n",
    "        # Verificar si el ejemplo tiene preguntas\n",
    "        if tecnica==\"ultrasound\":\n",
    "            answer_tipo[\"tecnica\"]=\"only ultrasound study\"+\".\"            \n",
    "        elif tecnica==\"mammography\":\n",
    "            answer_tipo[\"tecnica\"]=\"only mammography study\"+\".\"\n",
    "        elif not pd.isna(tecnica):\n",
    "            answer_tipo[\"tecnica\"]=tecnica+\".\"\n",
    "        else:\n",
    "            print(key,report)\n",
    "        for tipo in answer_tipo:\n",
    "            #Si está el tipo en las respuestas que hemos recogido lo metemos a la base de datos.\n",
    "            key_tipo=key+\"_\"+tipo\n",
    "            if key_tipo in flattened_examples:\n",
    "                continue\n",
    "                key_tipo=key_tipo+\"_copy\"\n",
    "            examples_raw[key_tipo]=report\n",
    "            answer=str(answer_tipo[tipo])\n",
    "            \n",
    "    \n",
    "            # inputs_tipo = \"Question: \" + question_tipo[tipo]+ \" Context: \" + informe +\" Answer: \"+ str(answer_tipo[tipo])\n",
    "            inputs_tipo = \"Question: \" + question_tipo[tipo] +\" Context: \" + informe + \" Answer: \"+ str(answer_tipo[tipo])\n",
    "\n",
    "            flattened_examples[key_tipo]=inputs_tipo\n",
    "            targets[key_tipo]=answer\n",
    "            \n",
    "            val_data[key_tipo]= \"Question: \" + question_tipo[tipo] + \" Context: \" + informe +\" Answer: \"\n",
    "    return flattened_examples,targets,val_data,examples_raw\n",
    "\n",
    "    \n",
    "def tokenize_function(inputs):\n",
    "    # Tokenizar el batch completo\n",
    "    model_inputs = tokenizer(\n",
    "        inputs[\"text\"], \n",
    "        max_length=1024, \n",
    "        truncation=True, \n",
    "        padding=\"max_length\", \n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # Crear las labels como una copia de los input_ids\n",
    "    labels = model_inputs[\"input_ids\"].clone()\n",
    "\n",
    "    # Obtener la secuencia de tokens para \"answer:\" (sin el token `<s>`)\n",
    "    answer_colon_tokens = tokenizer(\"Answer:\").input_ids[1:]  # Ahora solo [9412, 20]\n",
    "\n",
    "    # Iterar sobre cada entrada en el batch\n",
    "    for idx in range(labels.shape[0]):  \n",
    "        input_ids = model_inputs[\"input_ids\"][idx].tolist()  # Convertir a lista para iterar\n",
    "        answer_start_idx = -1\n",
    "\n",
    "        # Buscar la secuencia exacta \"answer:\" en input_ids\n",
    "        for i in range(len(input_ids) - len(answer_colon_tokens) + 1):\n",
    "            if input_ids[i : i + len(answer_colon_tokens)] == answer_colon_tokens:\n",
    "                answer_start_idx = i + len(answer_colon_tokens)  # Inicio de la respuesta\n",
    "                break\n",
    "\n",
    "        if answer_start_idx != -1:\n",
    "            labels[idx, :answer_start_idx] = -100  # Enmascarar todo antes de la respuesta\n",
    "        else:\n",
    "            labels[idx, :] = -100  # Si no se encuentra, enmascarar todo\n",
    "\n",
    "    # Enmascarar también los tokens de padding\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "\n",
    "    return {\"input_ids\": model_inputs[\"input_ids\"], \"labels\": labels}\n",
    "\n",
    "def train_save(X,Y,training=True,testing=False,low_beams=False):\n",
    "    random.seed(1)\n",
    "    np.random.seed(1)\n",
    "    predicted=[]\n",
    "    tested=[]\n",
    "    acc_cv=[]\n",
    "    kappa_cv=[]\n",
    "    ind_cv={tipo:[] for tipo in questions}\n",
    "    preds_category_cv={tipo:[] for tipo in questions}\n",
    "    labels_category_cv={tipo:[] for tipo in questions}\n",
    "    accuracies_cv={tipo:[] for tipo in questions}\n",
    "\n",
    "    train = train_clean(X,Y) \n",
    "    del train[\"val_data\"]\n",
    "    print(len(train))\n",
    "    model=AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    train_data = Dataset.from_pandas(train)\n",
    "    train_data = train_data.map(tokenize_function, batched=True)\n",
    "    train_data = train_data.remove_columns([\"text\",\"label\"])\n",
    "    train_data.set_format(\"torch\")\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_data)\n",
    "    if training:\n",
    "        trainer.train()\n",
    "    trainer.save_model(f\"results/{model_name}_second_stage_model_final_tecnica_no_info\")\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "e4f99452-3c39-40fa-894d-85ca7b814cb8",
   "metadata": {},
   "source": [
    "##BIOGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f30e62a5-bd4c-45b3-8ebb-11f7835f492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"microsoft/biogpt\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "inputs,targets,val_data,examples_raw = flatten_and_filter_dataset(ground_truth,report_data)  \n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    # evaluation_strategy=\"epoch\",\n",
    "    learning_rate=1e-5,  # Lower for fine-tuning without losing generalization\n",
    "    per_device_train_batch_size=4,\n",
    "    fp16=True,\n",
    "    gradient_accumulation_steps=4,\n",
    "    \n",
    "    num_train_epochs=7,  # Shorter fine-tuning stage\n",
    "    weight_decay=0.01,  # Lower weight decay to preserve learned features\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91fb5d58-02a6-4a87-8209-44fa71acbfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_final=pd.DataFrame.from_dict(inputs,orient='index')\n",
    "targets=pd.DataFrame.from_dict(targets,orient='index')\n",
    "val_data=pd.DataFrame.from_dict(val_data,orient='index')\n",
    "dataset_final.columns=[\"text\"]\n",
    "targets.columns=[\"label\"]\n",
    "val_data.columns=[\"val_data\"]\n",
    "dataset_final=pd.concat([dataset_final, val_data],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7dfa05b-49f5-49a0-9f5e-e89e5f3c5bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 212/212 [00:01<00:00, 193.01 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='91' max='91' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [91/91 02:22, Epoch 6/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_save(dataset_final,targets,training=True,testing=False,low_beams=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "567656fe-bff3-4b5f-a33d-a1057a1e68de",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions=[\"age\",\"tipo\",\"tecnica\",\"family\",\"history\",\"symtomatic\",\n",
    "           \"prosthesis\",\"birads\",\"density_mammo\",\"calcifications_benign\",\"density_echo\",\"ganglio_mamo\",\"lymph_benign\",\"lymph_suspicious\",\"parenchymal_distortion\",\"simple_cyst\",\"ductal_ectasia\",\n",
    "          \"nodules_echo_num\",\"nodules_echo_description\",\"nodules_echo_shape\",\"nodules_echo_margin\",\"nodules_echo_echogenicity\",\"nodules_echo_location\",\"nodules_echo_size\",\"nodules_echo_known\",\"nodules_echo_stable\"]\n",
    "\n",
    "\n",
    "\n",
    "TIPO=[\"biopsy report\", \"nodal staging ultrasound report\", \"normal control or revision report\"]\n",
    "TECNICA=[\"only ultrasound study\", \"only mammography study\", \"mammography and ultrasound\"]\n",
    "FAMILY=[\"no family history\", \"first degree\", \"second degree\"]\n",
    "PROSTHESIS=[\"no prosthesis\",\"yes prosthesis\"]\n",
    "BIRADS=[\"BI-RADS 0\",\"BI-RADS 1\",\"BI-RADS 2\",\"BI-RADS 3\",\"BI-RADS 4A\",\"BI-RADS 4B\",\"BI-RADS 4C\",\"BI-RADS 5\",\"BI-RADS 6\"]\n",
    "DENSITY_MAMMO=[\"ACR A\",\"ACR B\",\"ACR C\",\"ACR D\",\"unknown density mammo\"]\n",
    "CALCIFICATIONS_BENIGN=[\"no calcifications\",\"yes calcifications\"]\n",
    "GANGLIO_MAMO=[\"no ganglio\",\"yes ganglio\"]\n",
    "DENSITY_ECHO=[\"homogeneous fibroglandular\",\"heterogeneous fibroglandular\",\"fibroglandular and fat\",\"homogeneous fatty\",\"unknown density echo\"]\n",
    "LYMPH_BENIGN=[\"no lymph benign\",\"yes lymph benign\"]\n",
    "LYMPH_SUSPICIOUS=[\"no lymph suspicious\",\"yes lymph suspicious\"]\n",
    "SIMPLE_CYST=[\"no cyst\",\"yes cyst\"]\n",
    "DUCTAL_ECTASIA=[\"no ectasia\",\"yes ectasia\"]\n",
    "NODULES_ECHO=[\"no nodules\", \"yes nodules\"]\n",
    "NODULES_SHAPE=[\"oval\",\"round\",\"lobulated\",\"irregular\",\"unknown shape\"]\n",
    "NODULES_MARGIN=[\"circumscribed\",\"spiculated\",\"indistinct\",\"not circumscribed\",\"unknown margin\"]\n",
    "NODULES_ECHOGENICITY=[\"hypoechoic\", \"isoechoic\", \"heterogeneous\",\"complex cystic and solid\",\"unknown echogenicity\"]\n",
    "NODULES_KNOWN=[\"no known\", \"yes known\"]\n",
    "NODULES_STABLE=[\"grown stable\",\"shrunk stable\", \"yes stable\"]\n",
    "\n",
    "\n",
    "import gc\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "def flatten_and_filter_dataset(ground_truth,reports):\n",
    "    \"\"\"\n",
    "    Esta función toma un conjunto de datos en el formato original (con estructura jerárquica)\n",
    "    y devuelve un conjunto de datos plano, donde cada entrada tiene un solo `context`, `question` y `answer`.\n",
    "    \n",
    "    Argumentos:\n",
    "        dataset: Un conjunto de datos en formato original (puede ser train, validation, test).\n",
    "    \n",
    "    Retorno:\n",
    "        Un conjunto de datos de Hugging Face en formato plano, con solo ejemplos completos.\n",
    "    \"\"\"\n",
    "    # Lista para almacenar ejemplos en formato plano\n",
    "    flattened_examples = {}\n",
    "    examples_raw={}\n",
    "    targets={}\n",
    "    val_data={}\n",
    "    question_tipo={}\n",
    "    previous_message_answer_tipo={}\n",
    "    options_tipo={}\n",
    "    answers_tipo={}\n",
    "    j=0\n",
    "    \n",
    "    question_tipo[\"age\"]= \"does the patient's age appear in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"age\"]=\"search for numbers, but do not mistake it with the age of a familiar. If a number appears without any context between two dots it is surely the age.\"\n",
    "    options_tipo[\"age\"]=\"answer only the age of the patient.\"\n",
    "\n",
    "    question_tipo[\"tipo\"]= 'is the following breast medical report a biopsy report or a nodal staging ultrasound report?'\n",
    "    previous_message_answer_tipo[\"tipo\"]=\"biopsy reports are normally Image-Guided Biopsy and is normally said that they are referred to the hospital for biopsy. Nodal staging ultrasound reports can also be written as 'axilla ultrasound'. If it is any of these it will be written in the beginning of the report, normally in the used technique. These kind of reports are only ultrasound. In these reports no final BI-RADS is given.\"\n",
    "    options_tipo[\"tipo\"]=\"answer with one of the following options: 'biopsy report', 'nodal staging ultrasound report' or 'normal control or revision report'.\"\n",
    "\n",
    "    question_tipo[\"tecnica\"]= 'what diagnostic technique was used in the following breast medical report?'\n",
    "    previous_message_answer_tipo[\"tecnica\"]=\"biopsy reports, simple cysts and analysis of lymph or axillary nodes are only seen on ultrasound. On the other hand, if the ACR density is given or parenchymal distortions are analysed, the technique will be a mammogram. Tomosyntesis is a mammography type. The report may include an ultrasound examination, a mammography examination or both.\"\n",
    "    options_tipo[\"tecnica\"]=\"answer with one of the following options: 'only ultrasound study', 'only mammography study' or 'mammography and ultrasound'.\"\n",
    "\n",
    "    question_tipo[\"family\"]= \"does the patient have any family history in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"family\"]=\"family history of breast cancer is categorized based on the degree of relatives affected: First-degree relatives: Parents, siblings, or children. Second-degree relatives: Grandparents, aunts, uncles, nieces, nephews, or half-siblings. Third-degree relatives: Great-grandparents, great-aunts/uncles, or first cousins.\"\n",
    "    options_tipo[\"family\"]=\"answer with one of the following options: 'first degree', 'second degree', 'third degree' or 'no family history'.\"\n",
    "    \n",
    "    question_tipo[\"history\"]= \"does the patient have any non-familiar history in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"history\"]=\"check for the history at the beginning of the report. Normally it is a previous biopsy result, mastectomy or cancer. It normally starts with 'history of ...'.\"\n",
    "    options_tipo[\"history\"]=\"answer retrieving the information directly from the report or with 'no history was found'.\"\n",
    "    \n",
    "    question_tipo[\"symtomatic\"]= \"is the reason for the consultation that the patient is symptomatic in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"symtomatic\"]=\"the answer is at the beginning of the report, in the reason for consultation. It is normally a palpable lump, lumpectomy or nodule, sometimes painful.\"\n",
    "    options_tipo[\"symtomatic\"]=\"answer retrieving the information directly from the report or with 'non-symptomatic consultation'.\"\n",
    "    \n",
    "    question_tipo[\"prosthesis\"]= \"does the patient have a prosthesis in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"prosthesis\"]=\"it is normally clearly indicated at the beginning of the report. Sometimes it is written as implants instead of prosthesis.\"\n",
    "    options_tipo[\"prosthesis\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "    \n",
    "    question_tipo[\"birads\"]= \"what is the final BI-RADS classification given to the patient in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"birads\"]=\"the final BI-RADS of the patient is given in the conclusions of the report, normally at the end.\"\n",
    "    options_tipo[\"birads\"]=\"answer with one of the following options: 'BI-RADS 0', 'BI-RADS 1', 'BI-RADS 2', 'BI-RADS 3', 'BI-RADS 4A', 'BI-RADS 4B', 'BI-RADS 4C', 'BI-RADS 5' or 'unknown'.\"\n",
    "\n",
    "    question_tipo[\"density_mammo\"]= \"what is the breast density found in the mammography study of the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"density_mammo\"]=\"breast density in mammography is classified into four categories: ACR A (= Almost entirely fatty), ACR B (= Scattered areas of fibroglandular density), ACR C (= Heterogeneously dense), ACR D (= Extremely or very dense breasts). Sometimes it is written as 'density type x'. It can also be written with their real meaning (very dense breasts = C) and not with the A, B, C, D classification. Focus only on density.\"\n",
    "    options_tipo[\"density_mammo\"]=\"answer with one of the following options: 'ACR A', 'ACR B', 'ACR C', ACR D' or 'unknown'.\"\n",
    "   \n",
    "    question_tipo[\"density_echo\"]= \"what is the breast density found in the ultrasound study of the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"density_echo\"]=\"breast composition in ultrasound is classified into three categories: fibroglandular and fat (mixed distribution of fibroglandular and adipose tissue), heterogeneous fibroglandular (predominantly fibroglandular tissue with varying echogenicity and scattered fat areas), homogeneous fatty (uniform fatty tissue with consistent echogenicity and minimal fibroglandular content), and homogeneous fibroglandular (uniform fibroglandular tissue with consistent echogenicity and minimal fat content).\"\n",
    "    options_tipo[\"density_echo\"]=\"answer with one of the following options: 'fibroglandular and fat', 'heterogeneous fibroglandular', 'homogeneous fibroglandular', 'homogeneous fatty' or 'unknown'.\"\n",
    "\n",
    "    question_tipo[\"calcifications_benign\"]= \"does the following breast medical report mention the appearence of benign calcifications in the mammography exam?\"\n",
    "    previous_message_answer_tipo[\"calcifications_benign\"]=\"Consider only benign calcifications in the mammography.\"\n",
    "    options_tipo[\"calcifications_benign\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "    \n",
    "    question_tipo[\"ganglio_mamo\"]= \"does the following breast medical report mention any lymph nodes in the mammography exam?\"\n",
    "    previous_message_answer_tipo[\"ganglio_mamo\"]=\"Consider only lymph nodes that appear in the mammography.\"\n",
    "    options_tipo[\"ganglio_mamo\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "\n",
    "    question_tipo[\"parenchymal_distortion\"]= \"does the following breast medical report mention any parenchymal distortion or asymmetry in the mammography exam?\"\n",
    "    previous_message_answer_tipo[\"parenchymal_distortion\"]=\"If it has any it will appear in the results of the mammography exam using the words distortion, asymmetry or sometimes it can also be surgical changes.\"\n",
    "    options_tipo[\"parenchymal_distortion\"]=\"answer retrieving the information directly from the report or with 'no'\"\n",
    "    \n",
    "    question_tipo[\"lymph_suspicious\"]= \"does the following breast medical report mention any suspicious axillary lymph nodes in the ultrasound exam?\"\n",
    "    previous_message_answer_tipo[\"lymph_suspicious\"]=\"if a lymph node is suspicious the report will recomend a biopsy or Fine Needle Aspiration. A lymph node is considered suspicious when it has eccentric cortical thickening ≥ 3 mm, Short axis >10 mm, round shape, loss of fatty hilum, abnormal vascularity, or irregular margins—especially when associated with known malignancy or progressive enlargement. They can also be classified as UN3, UN4 or UN5. An exam may have both suspicious and benign lymph nodes, answer 'yes' in this case.\"\n",
    "    options_tipo[\"lymph_suspicious\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "\n",
    "    question_tipo[\"lymph_benign\"]= \"does the following breast medical report mention any benign or not suspicious axillary lymph nodes in the ultrasound exam?\"\n",
    "    previous_message_answer_tipo[\"lymph_benign\"]=\"if a lymph node is suspicious the report will recomend a biopsy or Fine Needle Aspiration. A lymph node is considered benign when it has uniform cortex < 3 mm, preserved fatty hilum, oval shape, no abnormal vascularity, no irregular margins and homogeneous internal echo pattern. Benign axillary nodes can be classified as UN1 or UN2. A reactive axillary node is not suspicious. An exam may have both suspicious and benign lymph nodes, answer 'yes' in this case.\"\n",
    "    options_tipo[\"lymph_benign\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "\n",
    "    question_tipo[\"simple_cyst\"]= \"does the following breast medical report mention any simple cysts or microcysts in the ultrasound exam?\"\n",
    "    previous_message_answer_tipo[\"simple_cyst\"]=\"The words symple cysts or microcysts will appear only in the ultrasound exam. Sometimes they can say that some of the cysts have echogenic content, but we still will consider them simple cysts and not nodules.\"\n",
    "    options_tipo[\"simple_cyst\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "\n",
    "    question_tipo[\"ductal_ectasia\"]= \"does the following breast medical report mention any ductal ectasia in the ultrasound exam?\"\n",
    "    previous_message_answer_tipo[\"ductal_ectasia\"]=\"The word ductal ectasia will appear only in the ultrasound exam.\"\n",
    "    options_tipo[\"ductal_ectasia\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "    \n",
    "    question_tipo[\"nodules_echo_num\"]=\"is there any nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"nodules_echo_num\"]=\"do not consider if a nodule is described in the mammography exam or if it is in the axilla. The localization, echogenicity and size of the nodules are normally said.\"\n",
    "    options_tipo[\"nodules_echo_num\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "\n",
    "    \n",
    "    dic_order = {\n",
    "        1: \"first\",\n",
    "        2: \"second\",\n",
    "        3: \"third\",\n",
    "        4: \"fourth\",\n",
    "        5: \"fifth\",\n",
    "        6: \"sixth\",\n",
    "        7: \"seventh\",\n",
    "        8: \"eighth\",\n",
    "        9: \"ninth\",\n",
    "        10: \"tenth\",\n",
    "        11: \"eleventh\",\n",
    "        12: \"twelfth\",\n",
    "        13: \"thirteenth\",\n",
    "        14: \"fourteenth\",\n",
    "        15: \"fifteenth\"\n",
    "    }\n",
    "    for i in range(1,2):\n",
    "        question_tipo[f\"nodules_echo_description_{i}\"]= f\"which is the {dic_order[i]} nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_description_{i}\"]=\"do not consider if a nodule is described in the mammography exam or if it is in the axilla. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "        options_tipo[f\"nodules_echo_description_{i}\"]=\"answer retrieving the information directly from the report.\"\n",
    "        \n",
    "        question_tipo[f\"nodules_echo_shape_{i}\"]= f\"what is the shape of the {dic_order[i]} nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_shape_{i}\"]=\"do not consider if a nodule is described in the mammography exam or if it is in the axilla. Shapes can be 'oval', 'round', 'lobulated' and 'irregular'. Sometimes irregular is also used for the margin, but in this case it is written as 'irregular margin' or 'irregular borders'. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "        options_tipo[f\"nodules_echo_shape_{i}\"]=\"answer with one of the following options: 'oval', 'round', 'lobulated', 'irregular' or 'unknown'.\"\n",
    "        \n",
    "        question_tipo[f\"nodules_echo_margin_{i}\"]= f\"what is the margin of the {dic_order[i]} nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_margin_{i}\"]=\"do not consider if a nodule is described in the mammography exam or if it is in the axilla. Margin can be 'circumscribed' and 'not circumscribed'. Inside the not circumscribed we have 'spiculated', 'angulated', 'microlobulated' or 'indistinc' ('not defined') margins. Sometimes irregular is also used for the margin, but in this case it is written as 'irregular margin' or 'irregular borders', in this case classify it as 'not circumscribed'. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "        options_tipo[f\"nodules_echo_margin_{i}\"]=\"answer with one of the following options: 'circumscribed', 'not circumscribed', 'indefined', 'spiculated', 'angulated', 'microlobulated' or 'unknown'.\"\n",
    "        \n",
    "        question_tipo[f\"nodules_echo_echogenicity_{i}\"]= f\"what is the echogenicity of the {dic_order[i]} nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_echogenicity_{i}\"]=\"do not consider if a nodule is described in the mammography exam or if it is in the axilla. Echogenicity can be 'anechoic', 'hypoechoic', 'heterogeneous' and 'complex cystic and solid'. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\" \n",
    "        options_tipo[f\"nodules_echo_echogenicity_{i}\"]=\"answer with one of the following options: 'hypoechoic', 'heterogeneous', 'anechoic', 'hyperecoic', 'isoechoic', 'complex cystic and solid' or 'unknown'.\"\n",
    "        \n",
    "        question_tipo[f\"nodules_echo_location_{i}\"]= f\"In which location is the {dic_order[i]} nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_location_{i}\"]=\"do not consider if a nodule is described in the mammography exam or if it is in the axilla. If the nodule is mentioned previously in the mammography, the location can be found also there. sometimes the breast location of the tumour may be written in a different part than the quadrant. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "        options_tipo[f\"nodules_echo_location_{i}\"]=\"answer retrieving the information directly from the report or with 'unknown'.\"\n",
    "        \n",
    "        question_tipo[f\"nodules_echo_size_{i}\"]= f\"what is the size of the {dic_order[i]} nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_size_{i}\"]=\"do not consider if a nodule is described in the mammography exam. The localization, echogenicity and size of the nodules are normally said. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "        options_tipo[f\"nodules_echo_size_{i}\"]=\"answer retrieving the information directly from the report (stop after 'mm') or with 'unknown'.\"\n",
    "        \n",
    "        question_tipo[f\"nodules_echo_known_{i}\"]= f\"is the {dic_order[i]} nodule described in the ultrasound exam of the following breast medical report previously known?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_known_{i}\"]=\"do not consider if a nodule is described in the mammography exam. If the nodule is known from before the report, it will say if it it is stable or if it has grown or shrink. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "        options_tipo[f\"nodules_echo_known_{i}\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "        \n",
    "        question_tipo[f\"nodules_echo_stable_{i}\"]= f\"is the {dic_order[i]} known nodule described in the ultrasound exam stable in the following breast medical report?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_stable_{i}\"]=\"do not consider if a nodule is described in the mammography exam. If the nodule is known from before the examination, it will be analysed to see if it is stable or if it got bigger or smaller. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "        options_tipo[f\"nodules_echo_stable_{i}\"]=\"answer with one of the following options: 'yes', 'grown' or 'shrunk.\"\n",
    "    for i, report in enumerate(reports[\"informes_ingles\"]):\n",
    "        informe=preprocess_text(report)\n",
    "        key=reports[\"keys\"][i]\n",
    "        \n",
    "        if key not in ground_truth.index:\n",
    "            continue\n",
    "        \n",
    "        row=ground_truth.loc[key]\n",
    "\n",
    "        #AGE\n",
    "        age=str(row[\"Age\"])\n",
    "        answer_tipo={}\n",
    "        # Verificar si el ejemplo tiene preguntas\n",
    "        if age.isdigit():\n",
    "            answer_tipo[\"age\"]=age+\".\"\n",
    "            \n",
    "        else:\n",
    "            answer_tipo[\"age\"]=\"no\"+\".\"\n",
    "        \n",
    "        #TIPO\n",
    "        if row[\"Biopsy_report\"]==\"Yes\":\n",
    "            answer_tipo[\"tipo\"]=\"biopsy report\"+\".\"\n",
    "            \n",
    "        elif row[\"Ganglio_report\"]==\"Yes\":\n",
    "            answer_tipo[\"tipo\"]=\"nodal staging ultrasound report\"+\".\"\n",
    "        else:\n",
    "            answer_tipo[\"tipo\"]=\"normal control or revision report\"+\".\"\n",
    "        \n",
    "        #TECHNIQUE\n",
    "        tecnica=row[\"Technique\"]\n",
    "        # Verificar si el ejemplo tiene preguntas\n",
    "        if tecnica==\"ultrasound\":\n",
    "            answer_tipo[\"tecnica\"]=\"only ultrasound study\"+\".\"            \n",
    "        elif tecnica==\"mammography\":\n",
    "            answer_tipo[\"tecnica\"]=\"only mammography study\"+\".\"\n",
    "        elif not pd.isna(tecnica):\n",
    "            answer_tipo[\"tecnica\"]=tecnica+\".\"\n",
    "        else:\n",
    "            print(key,report)\n",
    "        \n",
    "        # \n",
    "        # HISTORY\n",
    "        #No consideramos las biopsias o las ecografías de estadificación ganglionar.\n",
    "        if answer_tipo[\"tipo\"]==\"normal control or revision report\"+\".\":\n",
    "            history=row[\"Other_history\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(history,str) or history==\"No\":\n",
    "                answer_tipo[\"history\"]=\"no history was found\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"history\"]=history+\".\" \n",
    "    \n",
    "            # FAMILY\n",
    "            family=row[\"Family_history\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(family,str) or family==\"No\":\n",
    "                answer_tipo[\"family\"]=\"no family history\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"family\"]=family+\".\" \n",
    "    \n",
    "            # SYMTOMATIC\n",
    "            symtomatic=row[\"Syntomatic\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(symtomatic,str) or symtomatic==\"No\" or symtomatic==\"No estoy seguro\":\n",
    "                answer_tipo[\"symtomatic\"]=\"Non-symptomatic consultation\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"symtomatic\"]=symtomatic+\".\" \n",
    "    \n",
    "            # PROSTHESIS\n",
    "            prosthesis=row[\"Prosthesis\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(prosthesis,str) or prosthesis==\"No\":\n",
    "                answer_tipo[\"prosthesis\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"prosthesis\"]=\"yes\"+\".\"\n",
    "    \n",
    "            #BIRADS\n",
    "            birads=row[\"BI-RADS\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(birads,str):\n",
    "                answer_tipo[\"birads\"]=\"unknown\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"birads\"]=birads+\".\"\n",
    "    \n",
    "            #Density mammo\n",
    "            density_mammo=row[\"Density_mamo\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(density_mammo,str):\n",
    "                answer_tipo[\"density_mammo\"]=\"unknown\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"density_mammo\"]=density_mammo+\".\"\n",
    "\n",
    "            #Lymp nodes mammo\n",
    "            ganglio_mamo=row[\"Ganglio_mamo\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(ganglio_mamo,str):\n",
    "                answer_tipo[\"ganglio_mamo\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"ganglio_mamo\"]=ganglio_mamo.lower()+\".\"\n",
    "\n",
    "            #Calcifications benign\n",
    "            calcifications_benign=row[\"Calcifications_benign_mamo\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(calcifications_benign,str):\n",
    "                answer_tipo[\"calcifications_benign\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"calcifications_benign\"]=calcifications_benign.lower()+\".\"\n",
    "\n",
    "            #Parenchymal distortion\n",
    "            parenchymal_distortion=row[\"parenchymal_distortions_asymmetry\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(parenchymal_distortion,str):\n",
    "                answer_tipo[\"parenchymal_distortion\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"parenchymal_distortion\"]=parenchymal_distortion.lower()+\".\"\n",
    "    \n",
    "            #Density echo\n",
    "            density_echo=row[\"Density_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(density_echo,str):\n",
    "                answer_tipo[\"density_echo\"]=\"unknown\"+\".\"            \n",
    "            else:\n",
    "                if density_echo in DENSITY_ECHO:\n",
    "                    answer_tipo[\"density_echo\"]=density_echo+\".\"\n",
    "\n",
    "            #Benign lymph nodes\n",
    "            simple_cyst=row[\"simple_cyst_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(simple_cyst,str):\n",
    "                answer_tipo[\"simple_cyst\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"simple_cyst\"]=simple_cyst.lower()+\".\"\n",
    "            #Suspicious lymph nodes\n",
    "            lymph_suspicious=row[\"Ganglio_suspicious_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(lymph_suspicious,str):\n",
    "                answer_tipo[\"lymph_suspicious\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"lymph_suspicious\"]=lymph_suspicious.lower()+\".\"\n",
    "\n",
    "            #Benign lymph nodes\n",
    "            lymph_benign=row[\"Ganglio_benign_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(lymph_benign,str):\n",
    "                answer_tipo[\"lymph_benign\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"lymph_benign\"]=lymph_benign.lower()+\".\"\n",
    "\n",
    "            #Ductal ectasia\n",
    "            ductal_ectasia=row[\"Ductal_ectasia_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(ductal_ectasia,str):\n",
    "                answer_tipo[\"ductal_ectasia\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"ductal_ectasia\"]=ductal_ectasia.lower()+\".\"\n",
    "    \n",
    "            #Nodules echo\n",
    "            nodules_echo_num=row[\"Nodules_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(nodules_echo_num,str) and not isinstance(nodules_echo_num,int):\n",
    "                answer_tipo[\"nodules_echo_num\"]=\"no\"+\".\"    \n",
    "            elif isinstance(nodules_echo_num,str) and nodules_echo_num==\"No\":\n",
    "                answer_tipo[\"nodules_echo_num\"]=\"no\"+\".\"  \n",
    "            else:\n",
    "                answer_tipo[\"nodules_echo_num\"]=\"yes\"+\".\"\n",
    "    \n",
    "            #Si existen nódulos se hace las preguntas correspondientes\n",
    "            if answer_tipo[\"nodules_echo_num\"]!=\"no.\":\n",
    "                nodules_echo_description=row[\"Description_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                \n",
    "                answer_tipo[\"nodules_echo_description_1\"]=nodules_echo_description+\".\"\n",
    "                    \n",
    "                nodules_echo_shape=row[f\"Shape_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_echo_shape,str):\n",
    "                    answer_tipo[\"nodules_echo_shape_1\"]=\"unknown\"+\".\"\n",
    "                else:\n",
    "                    answer_tipo[\"nodules_echo_shape_1\"]=nodules_echo_shape.lower()+\".\"\n",
    "\n",
    "                nodules_echo_margin=row[\"Margin_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_echo_margin,str):\n",
    "                    answer_tipo[\"nodules_echo_margin_1\"]=\"unknown\"+\".\"\n",
    "                else:\n",
    "                    answer_tipo[\"nodules_echo_margin_1\"]=nodules_echo_margin.lower()+\".\"\n",
    "\n",
    "                nodules_echo_echogenicity=row[\"Echogenicity_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_echo_echogenicity,str):\n",
    "                    answer_tipo[\"nodules_echo_echogenicity_1\"]=\"unknown\"+\".\"\n",
    "                else:\n",
    "                    answer_tipo[\"nodules_echo_echogenicity_1\"]=nodules_echo_echogenicity.lower()+\".\"\n",
    "\n",
    "                nodules_echo_location=row[f\"Location_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_echo_location,str):\n",
    "                    answer_tipo[\"nodules_echo_location_1\"]=\"unknown\"+\".\"\n",
    "                else:\n",
    "                    answer_tipo[\"nodules_echo_location_1\"]=nodules_echo_location.lower()+\".\"\n",
    "\n",
    "                \n",
    "                #Nodules echo size\n",
    "                nodules_echo_size=row[\"size_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_echo_size,str):\n",
    "                    answer_tipo[\"nodules_echo_size_1\"]=\"unknown\"+\".\"            \n",
    "                else:\n",
    "                    answer_tipo[\"nodules_echo_size_1\"]=nodules_echo_size+\".\"\n",
    "        \n",
    "                #Nodules echo known\n",
    "                nodules_echo_known=row[\"new_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_echo_known,str):\n",
    "                    answer_tipo[\"nodules_echo_known_1\"]=\"unknown\"+\".\"\n",
    "                elif nodules_echo_known==\"No\":\n",
    "                    answer_tipo[\"nodules_echo_known_1\"]=\"yes\"+\".\"            \n",
    "                else:\n",
    "                    answer_tipo[\"nodules_echo_known_1\"]=\"no\"+\".\"\n",
    "    \n",
    "                if answer_tipo[\"nodules_echo_known_1\"]==\"yes.\":\n",
    "                    #Nodules echo stable\n",
    "                    nodules_echo_stable=row[\"Stable_eco_1\"]\n",
    "                    # Verificar si el ejemplo tiene preguntas\n",
    "                    if not isinstance(nodules_echo_stable,str):\n",
    "                        answer_tipo[\"nodules_echo_stable_1\"]=\"unknown\"+\".\"\n",
    "                    else:\n",
    "                        answer_tipo[\"nodules_echo_stable_1\"]=nodules_echo_stable.lower()+\".\"\n",
    "            \n",
    "        for tipo in answer_tipo:\n",
    "            #Si está el tipo en las respuestas que hemos recogido lo metemos a la base de datos.\n",
    "            key_tipo=key+\"_\"+tipo\n",
    "            if key_tipo in flattened_examples:\n",
    "                continue\n",
    "                key_tipo=key_tipo+\"_copy\"\n",
    "            examples_raw[key_tipo]=report\n",
    "            answer=str(answer_tipo[tipo])\n",
    "            \n",
    "    \n",
    "            inputs_tipo = \"Question: \" + question_tipo[tipo] + \" Context: \" + informe + \" Answer: \"+ str(answer_tipo[tipo])\n",
    "            flattened_examples[key_tipo]=inputs_tipo\n",
    "            targets[key_tipo]=answer\n",
    "            \n",
    "            val_data[key_tipo]=\"Question: \" + question_tipo[tipo] + \" Context: \" + informe+ \" Answer: \"\n",
    "    return flattened_examples,targets,val_data,examples_raw\n",
    "\n",
    "def tokenize_function(inputs):\n",
    "    # Tokenizar el batch completo\n",
    "    model_inputs = tokenizer(\n",
    "        inputs[\"text\"], \n",
    "        max_length=512, \n",
    "        truncation=True, \n",
    "        padding=\"max_length\", \n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # Crear las labels como una copia de los input_ids\n",
    "    labels = model_inputs[\"input_ids\"].clone()\n",
    "\n",
    "    # Obtener la secuencia de tokens para \"answer:\" (sin el token `<s>`)\n",
    "    answer_colon_tokens = tokenizer(\"Answer:\").input_ids[1:]  # Ahora solo [9412, 20]\n",
    "\n",
    "    # Iterar sobre cada entrada en el batch\n",
    "    for idx in range(labels.shape[0]):  \n",
    "        input_ids = model_inputs[\"input_ids\"][idx].tolist()  # Convertir a lista para iterar\n",
    "        answer_start_idx = -1\n",
    "\n",
    "        # Buscar la secuencia exacta \"answer:\" en input_ids\n",
    "        for i in range(len(input_ids) - len(answer_colon_tokens) + 1):\n",
    "            if input_ids[i : i + len(answer_colon_tokens)] == answer_colon_tokens:\n",
    "                answer_start_idx = i + len(answer_colon_tokens)  # Inicio de la respuesta\n",
    "                break\n",
    "\n",
    "        if answer_start_idx != -1:\n",
    "            labels[idx, :answer_start_idx] = -100  # Enmascarar todo antes de la respuesta\n",
    "        else:\n",
    "            labels[idx, :] = -100  # Si no se encuentra, enmascarar todo\n",
    "\n",
    "    # Enmascarar también los tokens de padding\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "\n",
    "    return {\"input_ids\": model_inputs[\"input_ids\"], \"labels\": labels}\n",
    "\n",
    "def train_save(X,Y,training=True,testing=False,low_beams=False):\n",
    "    random.seed(1)\n",
    "    np.random.seed(1)\n",
    "    predicted=[]\n",
    "    tested=[]\n",
    "    acc_cv=[]\n",
    "    kappa_cv=[]\n",
    "    ind_cv={tipo:[] for tipo in questions}\n",
    "    preds_category_cv={tipo:[] for tipo in questions}\n",
    "    labels_category_cv={tipo:[] for tipo in questions}\n",
    "    accuracies_cv={tipo:[] for tipo in questions}\n",
    "\n",
    "    train = train_clean(X,Y) \n",
    "    del train[\"val_data\"]\n",
    "    print(len(train))\n",
    "    model=AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    train_data = Dataset.from_pandas(train)\n",
    "    train_data = train_data.map(tokenize_function, batched=True)\n",
    "    train_data = train_data.remove_columns([\"text\",\"label\"])\n",
    "    train_data.set_format(\"torch\")\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_data)\n",
    "    if training:\n",
    "        trainer.train()\n",
    "    trainer.save_model(f\"results/{model_name}_second_stage_model_final_no_info\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "160b2a72-9520-4c4b-958a-bc8171975777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4041/4041 [00:15<00:00, 255.29 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='83' max='1771' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  83/1771 00:38 < 13:16, 2.12 it/s, Epoch 0.32/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     11\u001b[39m dataset_final=pd.concat([dataset_final, val_data],axis=\u001b[32m1\u001b[39m)\n\u001b[32m     13\u001b[39m training_args = TrainingArguments(\n\u001b[32m     14\u001b[39m     output_dir=\u001b[33m\"\u001b[39m\u001b[33m./results\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# evaluation_strategy=\"epoch\",\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m \n\u001b[32m     24\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43mtrain_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_final\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mtesting\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mlow_beams\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 481\u001b[39m, in \u001b[36mtrain_save\u001b[39m\u001b[34m(X, Y, training, testing, low_beams)\u001b[39m\n\u001b[32m    476\u001b[39m trainer = Trainer(\n\u001b[32m    477\u001b[39m     model=model,\n\u001b[32m    478\u001b[39m     args=training_args,\n\u001b[32m    479\u001b[39m     train_dataset=train_data)\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[32m--> \u001b[39m\u001b[32m481\u001b[39m     \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    482\u001b[39m trainer.save_model(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mresults/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_second_stage_model_final_no_info\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.13/site-packages/transformers/trainer.py:2241\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2239\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2240\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2242\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2245\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2246\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.13/site-packages/transformers/trainer.py:2548\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2541\u001b[39m context = (\n\u001b[32m   2542\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2543\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2544\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2545\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2546\u001b[39m )\n\u001b[32m   2547\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2548\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2550\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2551\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2552\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2553\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2554\u001b[39m ):\n\u001b[32m   2555\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2556\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.13/site-packages/transformers/trainer.py:3740\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   3737\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type == DistributedType.DEEPSPEED:\n\u001b[32m   3738\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mscale_wrt_gas\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3740\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maccelerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3742\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss.detach()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.13/site-packages/accelerate/accelerator.py:2355\u001b[39m, in \u001b[36mAccelerator.backward\u001b[39m\u001b[34m(self, loss, **kwargs)\u001b[39m\n\u001b[32m   2353\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   2354\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.scaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2355\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2356\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m learning_rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.has_lomo_optimizer:\n\u001b[32m   2357\u001b[39m     \u001b[38;5;28mself\u001b[39m.lomo_backward(loss, learning_rate)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.13/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.13/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.13/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model_name = \"microsoft/biogpt\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "inputs,targets,val_data,examples_raw = flatten_and_filter_dataset(ground_truth,report_data)  \n",
    "dataset_final=pd.DataFrame.from_dict(inputs,orient='index')\n",
    "targets=pd.DataFrame.from_dict(targets,orient='index')\n",
    "val_data=pd.DataFrame.from_dict(val_data,orient='index')\n",
    "dataset_final.columns=[\"text\"]\n",
    "targets.columns=[\"label\"]\n",
    "val_data.columns=[\"val_data\"]\n",
    "dataset_final=pd.concat([dataset_final, val_data],axis=1)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    # evaluation_strategy=\"epoch\",\n",
    "    learning_rate=1e-5,  # Lower for fine-tuning without losing generalization\n",
    "    per_device_train_batch_size=8,\n",
    "    fp16=True,\n",
    "    gradient_accumulation_steps=2,\n",
    "    \n",
    "    num_train_epochs=7,  # Shorter fine-tuning stage\n",
    "    weight_decay=0.01,  # Lower weight decay to preserve learned features\n",
    "    \n",
    ")\n",
    "train_save(dataset_final,targets,training=True,testing=False,low_beams=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ea180e-cae7-4a26-ada9-25a81735f1ab",
   "metadata": {},
   "source": [
    "##CLINICALT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c06e0782-9bf4-4590-a143-70a8c1ec9221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from datasets import Dataset,concatenate_datasets,load_dataset\n",
    "from transformers import AutoTokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "questions=[\"age\",\"tipo\",\"tecnica\",\"family\",\"history\",\"symtomatic\",\n",
    "           \"prosthesis\",\"birads\",\"density_mammo\",\"calcifications_benign\",\"density_echo\",\"ganglio_mamo\",\"lymph_benign\",\"lymph_suspicious\",\"parenchymal_distortion\",\"simple_cyst\",\"ductal_ectasia\",\n",
    "          \"nodules_echo_num\",\"nodules_echo_description\",\"nodules_echo_shape\",\"nodules_echo_margin\",\"nodules_echo_echogenicity\",\"nodules_echo_location\",\"nodules_echo_size\",\"nodules_echo_known\",\"nodules_echo_stable\"]\n",
    "\n",
    "\n",
    "\n",
    "TIPO=[\"biopsy report\", \"nodal staging ultrasound report\", \"normal control or revision report\"]\n",
    "TECNICA=[\"only ultrasound study\", \"only mammography study\", \"mammography and ultrasound\"]\n",
    "FAMILY=[\"no family history\", \"first degree\", \"second degree\"]\n",
    "PROSTHESIS=[\"no prosthesis\",\"yes prosthesis\"]\n",
    "BIRADS=[\"BI-RADS 0\",\"BI-RADS 1\",\"BI-RADS 2\",\"BI-RADS 3\",\"BI-RADS 4A\",\"BI-RADS 4B\",\"BI-RADS 4C\",\"BI-RADS 5\",\"BI-RADS 6\"]\n",
    "DENSITY_MAMMO=[\"ACR A\",\"ACR B\",\"ACR C\",\"ACR D\",\"unknown density mammo\"]\n",
    "CALCIFICATIONS_BENIGN=[\"no calcifications\",\"yes calcifications\"]\n",
    "GANGLIO_MAMO=[\"no ganglio\",\"yes ganglio\"]\n",
    "DENSITY_ECHO=[\"homogeneous fibroglandular\",\"heterogeneous fibroglandular\",\"fibroglandular and fat\",\"homogeneous fatty\",\"unknown density echo\"]\n",
    "LYMPH_BENIGN=[\"no lymph benign\",\"yes lymph benign\"]\n",
    "LYMPH_SUSPICIOUS=[\"no lymph suspicious\",\"yes lymph suspicious\"]\n",
    "SIMPLE_CYST=[\"no cyst\",\"yes cyst\"]\n",
    "DUCTAL_ECTASIA=[\"no ectasia\",\"yes ectasia\"]\n",
    "NODULES_ECHO=[\"no nodules\", \"yes nodules\"]\n",
    "NODULES_SHAPE=[\"oval\",\"round\",\"lobulated\",\"irregular\",\"unknown shape\"]\n",
    "NODULES_MARGIN=[\"circumscribed\",\"spiculated\",\"indistinct\",\"not circumscribed\",\"unknown margin\"]\n",
    "NODULES_ECHOGENICITY=[\"hypoechoic\", \"isoechoic\", \"heterogeneous\",\"complex cystic and solid\",\"unknown echogenicity\"]\n",
    "NODULES_KNOWN=[\"no known\", \"yes known\"]\n",
    "NODULES_STABLE=[\"grown stable\",\"shrunk stable\", \"yes stable\"]\n",
    "\n",
    "\n",
    "import gc\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def train_clean(X,Y):\n",
    "    random.seed(1)\n",
    "    # Agrupar ejemplos originales y sus copias\n",
    "    train = X\n",
    "    # Barajar los datos de entrenamiento para evitar sesgos\n",
    "    train = train.sample(frac=1, random_state=1)\n",
    "    train_y = Y.loc[train.index]\n",
    "    train[\"label\"]=train_y[\"label\"]\n",
    "    return train\n",
    "    \n",
    "def flatten_and_filter_dataset(ground_truth,reports):\n",
    "    \"\"\"\n",
    "    Esta función toma un conjunto de datos en el formato original (con estructura jerárquica)\n",
    "    y devuelve un conjunto de datos plano, donde cada entrada tiene un solo `context`, `question` y `answer`.\n",
    "    \n",
    "    Argumentos:\n",
    "        dataset: Un conjunto de datos en formato original (puede ser train, validation, test).\n",
    "    \n",
    "    Retorno:\n",
    "        Un conjunto de datos de Hugging Face en formato plano, con solo ejemplos completos.\n",
    "    \"\"\"\n",
    "    # Lista para almacenar ejemplos en formato plano\n",
    "    flattened_examples = {}\n",
    "    examples_raw={}\n",
    "    targets={}\n",
    "    val_data={}\n",
    "    question_tipo={}\n",
    "    previous_message_answer_tipo={}\n",
    "    options_tipo={}\n",
    "    answers_tipo={}\n",
    "    j=0\n",
    "    \n",
    "    question_tipo[\"age\"]= \"does the patient's age appear in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"age\"]=\"search for numbers, but do not mistake it with the age of a familiar. If a number appears without any context between two dots it is surely the age.\"\n",
    "    options_tipo[\"age\"]=\"answer only the age of the patient.\"\n",
    "\n",
    "    question_tipo[\"tipo\"]= 'is the following breast medical report a biopsy report or a nodal staging ultrasound report?'\n",
    "    previous_message_answer_tipo[\"tipo\"]=\"biopsy reports are normally Image-Guided Biopsy and is normally said that they are referred to the hospital for biopsy. Nodal staging ultrasound reports can also be written as 'axilla ultrasound'. If it is any of these it will be written in the beginning of the report, normally in the used technique. These kind of reports are only ultrasound. In these reports no final BI-RADS is given.\"\n",
    "    options_tipo[\"tipo\"]=\"answer with one of the following options: 'biopsy report', 'nodal staging ultrasound report' or 'normal control or revision report'.\"\n",
    "\n",
    "    question_tipo[\"tecnica\"]= 'what diagnostic technique was used in the following breast medical report?'\n",
    "    previous_message_answer_tipo[\"tecnica\"]=\"biopsy reports, simple cysts and analysis of lymph or axillary nodes are only seen on ultrasound. On the other hand, if the ACR density is given or parenchymal distortions are analysed, the technique will be a mammogram. Tomosyntesis is a mammography type. The report may include an ultrasound examination, a mammography examination or both.\"\n",
    "    options_tipo[\"tecnica\"]=\"answer with one of the following options: 'only ultrasound study', 'only mammography study' or 'mammography and ultrasound'.\"\n",
    "\n",
    "    question_tipo[\"family\"]= \"does the patient have any family history in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"family\"]=\"family history of breast cancer is categorized based on the degree of relatives affected: First-degree relatives: Parents, siblings, or children. Second-degree relatives: Grandparents, aunts, uncles, nieces, nephews, or half-siblings. Third-degree relatives: Great-grandparents, great-aunts/uncles, or first cousins.\"\n",
    "    options_tipo[\"family\"]=\"answer with one of the following options: 'first degree', 'second degree', 'third degree' or 'no family history'.\"\n",
    "    \n",
    "    question_tipo[\"history\"]= \"does the patient have any non-familiar history in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"history\"]=\"check for the history at the beginning of the report. Normally it is a previous biopsy result, mastectomy or cancer. It normally starts with 'history of ...'.\"\n",
    "    options_tipo[\"history\"]=\"answer retrieving the information directly from the report or with 'no history was found'.\"\n",
    "    \n",
    "    question_tipo[\"symtomatic\"]= \"is the reason for the consultation that the patient is symptomatic in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"symtomatic\"]=\"the answer is at the beginning of the report, in the reason for consultation. It is normally a palpable lump, lumpectomy or nodule, sometimes painful.\"\n",
    "    options_tipo[\"symtomatic\"]=\"answer retrieving the information directly from the report or with 'non-symptomatic consultation'.\"\n",
    "    \n",
    "    question_tipo[\"prosthesis\"]= \"does the patient have a prosthesis in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"prosthesis\"]=\"it is normally clearly indicated at the beginning of the report. Sometimes it is written as implants instead of prosthesis.\"\n",
    "    options_tipo[\"prosthesis\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "    \n",
    "    question_tipo[\"birads\"]= \"what is the final BI-RADS classification given to the patient in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"birads\"]=\"the final BI-RADS of the patient is given in the conclusions of the report, normally at the end.\"\n",
    "    options_tipo[\"birads\"]=\"answer with one of the following options: 'BI-RADS 0', 'BI-RADS 1', 'BI-RADS 2', 'BI-RADS 3', 'BI-RADS 4A', 'BI-RADS 4B', 'BI-RADS 4C', 'BI-RADS 5' or 'unknown'.\"\n",
    "\n",
    "    question_tipo[\"density_mammo\"]= \"what is the breast density found in the mammography study of the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"density_mammo\"]=\"breast density in mammography is classified into four categories: ACR A (= Almost entirely fatty), ACR B (= Scattered areas of fibroglandular density), ACR C (= Heterogeneously dense), ACR D (= Extremely or very dense breasts). Sometimes it is written as 'density type x'. It can also be written with their real meaning (very dense breasts = C) and not with the A, B, C, D classification. Focus only on density.\"\n",
    "    options_tipo[\"density_mammo\"]=\"answer with one of the following options: 'ACR A', 'ACR B', 'ACR C', ACR D' or 'unknown'.\"\n",
    "   \n",
    "    question_tipo[\"density_echo\"]= \"what is the breast density found in the ultrasound study of the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"density_echo\"]=\"breast composition in ultrasound is classified into three categories: fibroglandular and fat (mixed distribution of fibroglandular and adipose tissue), heterogeneous fibroglandular (predominantly fibroglandular tissue with varying echogenicity and scattered fat areas), homogeneous fatty (uniform fatty tissue with consistent echogenicity and minimal fibroglandular content), and homogeneous fibroglandular (uniform fibroglandular tissue with consistent echogenicity and minimal fat content).\"\n",
    "    options_tipo[\"density_echo\"]=\"answer with one of the following options: 'fibroglandular and fat', 'heterogeneous fibroglandular', 'homogeneous fibroglandular', 'homogeneous fatty' or 'unknown'.\"\n",
    "\n",
    "    question_tipo[\"calcifications_benign\"]= \"does the following breast medical report mention the appearence of benign calcifications in the mammography exam?\"\n",
    "    previous_message_answer_tipo[\"calcifications_benign\"]=\"Consider only benign calcifications in the mammography.\"\n",
    "    options_tipo[\"calcifications_benign\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "    \n",
    "    question_tipo[\"ganglio_mamo\"]= \"does the following breast medical report mention any lymph nodes in the mammography exam?\"\n",
    "    previous_message_answer_tipo[\"ganglio_mamo\"]=\"Consider only lymph nodes that appear in the mammography.\"\n",
    "    options_tipo[\"ganglio_mamo\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "\n",
    "    question_tipo[\"parenchymal_distortion\"]= \"does the following breast medical report mention any parenchymal distortion or asymmetry in the mammography exam?\"\n",
    "    previous_message_answer_tipo[\"parenchymal_distortion\"]=\"If it has any it will appear in the results of the mammography exam using the words distortion, asymmetry or sometimes it can also be surgical changes.\"\n",
    "    options_tipo[\"parenchymal_distortion\"]=\"answer retrieving the information directly from the report or with 'no'\"\n",
    "    \n",
    "    question_tipo[\"lymph_suspicious\"]= \"does the following breast medical report mention any suspicious axillary lymph nodes in the ultrasound exam?\"\n",
    "    previous_message_answer_tipo[\"lymph_suspicious\"]=\"if a lymph node is suspicious the report will recomend a biopsy or Fine Needle Aspiration. A lymph node is considered suspicious when it has eccentric cortical thickening ≥ 3 mm, Short axis >10 mm, round shape, loss of fatty hilum, abnormal vascularity, or irregular margins—especially when associated with known malignancy or progressive enlargement. They can also be classified as UN3, UN4 or UN5. An exam may have both suspicious and benign lymph nodes, answer 'yes' in this case.\"\n",
    "    options_tipo[\"lymph_suspicious\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "\n",
    "    question_tipo[\"lymph_benign\"]= \"does the following breast medical report mention any benign or not suspicious axillary lymph nodes in the ultrasound exam?\"\n",
    "    previous_message_answer_tipo[\"lymph_benign\"]=\"if a lymph node is suspicious the report will recomend a biopsy or Fine Needle Aspiration. A lymph node is considered benign when it has uniform cortex < 3 mm, preserved fatty hilum, oval shape, no abnormal vascularity, no irregular margins and homogeneous internal echo pattern. Benign axillary nodes can be classified as UN1 or UN2. A reactive axillary node is not suspicious. An exam may have both suspicious and benign lymph nodes, answer 'yes' in this case.\"\n",
    "    options_tipo[\"lymph_benign\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "\n",
    "    question_tipo[\"simple_cyst\"]= \"does the following breast medical report mention any simple cysts or microcysts in the ultrasound exam?\"\n",
    "    previous_message_answer_tipo[\"simple_cyst\"]=\"The words symple cysts or microcysts will appear only in the ultrasound exam. Sometimes they can say that some of the cysts have echogenic content, but we still will consider them simple cysts and not nodules.\"\n",
    "    options_tipo[\"simple_cyst\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "\n",
    "    question_tipo[\"ductal_ectasia\"]= \"does the following breast medical report mention any ductal ectasia in the ultrasound exam?\"\n",
    "    previous_message_answer_tipo[\"ductal_ectasia\"]=\"The word ductal ectasia will appear only in the ultrasound exam.\"\n",
    "    options_tipo[\"ductal_ectasia\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "    \n",
    "    question_tipo[\"nodules_echo_num\"]=\"is there any nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"nodules_echo_num\"]=\"do not consider if a nodule is described in the mammography exam or if it is in the axilla. The localization, echogenicity and size of the nodules are normally said.\"\n",
    "    options_tipo[\"nodules_echo_num\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "\n",
    "    \n",
    "    dic_order = {\n",
    "        1: \"first\",\n",
    "        2: \"second\",\n",
    "        3: \"third\",\n",
    "        4: \"fourth\",\n",
    "        5: \"fifth\",\n",
    "        6: \"sixth\",\n",
    "        7: \"seventh\",\n",
    "        8: \"eighth\",\n",
    "        9: \"ninth\",\n",
    "        10: \"tenth\",\n",
    "        11: \"eleventh\",\n",
    "        12: \"twelfth\",\n",
    "        13: \"thirteenth\",\n",
    "        14: \"fourteenth\",\n",
    "        15: \"fifteenth\"\n",
    "    }\n",
    "    for i in range(1,2):\n",
    "        question_tipo[f\"nodules_echo_description_{i}\"]= f\"which is the {dic_order[i]} nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_description_{i}\"]=\"do not consider if a nodule is described in the mammography exam or if it is in the axilla. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "        options_tipo[f\"nodules_echo_description_{i}\"]=\"answer retrieving the information directly from the report.\"\n",
    "        \n",
    "        question_tipo[f\"nodules_echo_shape_{i}\"]= f\"what is the shape of the {dic_order[i]} nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_shape_{i}\"]=\"do not consider if a nodule is described in the mammography exam or if it is in the axilla. Shapes can be 'oval', 'round', 'lobulated' and 'irregular'. Sometimes irregular is also used for the margin, but in this case it is written as 'irregular margin' or 'irregular borders'. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "        options_tipo[f\"nodules_echo_shape_{i}\"]=\"answer with one of the following options: 'oval', 'round', 'lobulated', 'irregular' or 'unknown'.\"\n",
    "        \n",
    "        question_tipo[f\"nodules_echo_margin_{i}\"]= f\"what is the margin of the {dic_order[i]} nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_margin_{i}\"]=\"do not consider if a nodule is described in the mammography exam or if it is in the axilla. Margin can be 'circumscribed' and 'not circumscribed'. Inside the not circumscribed we have 'spiculated', 'angulated', 'microlobulated' or 'indistinc' ('not defined') margins. Sometimes irregular is also used for the margin, but in this case it is written as 'irregular margin' or 'irregular borders', in this case classify it as 'not circumscribed'. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "        options_tipo[f\"nodules_echo_margin_{i}\"]=\"answer with one of the following options: 'circumscribed', 'not circumscribed', 'indefined', 'spiculated', 'angulated', 'microlobulated' or 'unknown'.\"\n",
    "        \n",
    "        question_tipo[f\"nodules_echo_echogenicity_{i}\"]= f\"what is the echogenicity of the {dic_order[i]} nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_echogenicity_{i}\"]=\"do not consider if a nodule is described in the mammography exam or if it is in the axilla. Echogenicity can be 'anechoic', 'hypoechoic', 'heterogeneous' and 'complex cystic and solid'. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\" \n",
    "        options_tipo[f\"nodules_echo_echogenicity_{i}\"]=\"answer with one of the following options: 'hypoechoic', 'heterogeneous', 'anechoic', 'hyperecoic', 'isoechoic', 'complex cystic and solid' or 'unknown'.\"\n",
    "        \n",
    "        question_tipo[f\"nodules_echo_location_{i}\"]= f\"In which location is the {dic_order[i]} nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_location_{i}\"]=\"do not consider if a nodule is described in the mammography exam or if it is in the axilla. If the nodule is mentioned previously in the mammography, the location can be found also there. sometimes the breast location of the tumour may be written in a different part than the quadrant. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "        options_tipo[f\"nodules_echo_location_{i}\"]=\"answer retrieving the information directly from the report or with 'unknown'.\"\n",
    "        \n",
    "        question_tipo[f\"nodules_echo_size_{i}\"]= f\"what is the size of the {dic_order[i]} nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_size_{i}\"]=\"do not consider if a nodule is described in the mammography exam. The localization, echogenicity and size of the nodules are normally said. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "        options_tipo[f\"nodules_echo_size_{i}\"]=\"answer retrieving the information directly from the report (stop after 'mm') or with 'unknown'.\"\n",
    "        \n",
    "        question_tipo[f\"nodules_echo_known_{i}\"]= f\"is the {dic_order[i]} nodule described in the ultrasound exam of the following breast medical report previously known?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_known_{i}\"]=\"do not consider if a nodule is described in the mammography exam. If the nodule is known from before the report, it will say if it it is stable or if it has grown or shrink. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "        options_tipo[f\"nodules_echo_known_{i}\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "        \n",
    "        question_tipo[f\"nodules_echo_stable_{i}\"]= f\"is the {dic_order[i]} known nodule described in the ultrasound exam stable in the following breast medical report?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_stable_{i}\"]=\"do not consider if a nodule is described in the mammography exam. If the nodule is known from before the examination, it will be analysed to see if it is stable or if it got bigger or smaller. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "        options_tipo[f\"nodules_echo_stable_{i}\"]=\"answer with one of the following options: 'yes', 'grown' or 'shrunk.\"\n",
    "    for i, report in enumerate(reports[\"informes_ingles\"]):\n",
    "        informe=preprocess_text(report)\n",
    "        key=reports[\"keys\"][i]\n",
    "        \n",
    "        if key not in ground_truth.index:\n",
    "            continue\n",
    "        \n",
    "        row=ground_truth.loc[key]\n",
    "\n",
    "        #AGE\n",
    "        age=str(row[\"Age\"])\n",
    "        answer_tipo={}\n",
    "        # Verificar si el ejemplo tiene preguntas\n",
    "        if age.isdigit():\n",
    "            answer_tipo[\"age\"]=age+\".\"\n",
    "            \n",
    "        else:\n",
    "            answer_tipo[\"age\"]=\"no\"+\".\"\n",
    "        \n",
    "        #TIPO\n",
    "        if row[\"Biopsy_report\"]==\"Yes\":\n",
    "            answer_tipo[\"tipo\"]=\"biopsy report\"+\".\"\n",
    "            \n",
    "        elif row[\"Ganglio_report\"]==\"Yes\":\n",
    "            answer_tipo[\"tipo\"]=\"nodal staging ultrasound report\"+\".\"\n",
    "        else:\n",
    "            answer_tipo[\"tipo\"]=\"normal control or revision report\"+\".\"\n",
    "        \n",
    "        #TECHNIQUE\n",
    "        tecnica=row[\"Technique\"]\n",
    "        # Verificar si el ejemplo tiene preguntas\n",
    "        if tecnica==\"ultrasound\":\n",
    "            answer_tipo[\"tecnica\"]=\"only ultrasound study\"+\".\"            \n",
    "        elif tecnica==\"mammography\":\n",
    "            answer_tipo[\"tecnica\"]=\"only mammography study\"+\".\"\n",
    "        elif not pd.isna(tecnica):\n",
    "            answer_tipo[\"tecnica\"]=tecnica+\".\"\n",
    "        else:\n",
    "            print(key,report)\n",
    "        \n",
    "        # \n",
    "        # HISTORY\n",
    "        #No consideramos las biopsias o las ecografías de estadificación ganglionar.\n",
    "        if answer_tipo[\"tipo\"]==\"normal control or revision report\"+\".\":\n",
    "            history=row[\"Other_history\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(history,str) or history==\"No\":\n",
    "                answer_tipo[\"history\"]=\"no history was found\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"history\"]=history+\".\" \n",
    "    \n",
    "            # FAMILY\n",
    "            family=row[\"Family_history\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(family,str) or family==\"No\":\n",
    "                answer_tipo[\"family\"]=\"no family history\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"family\"]=family+\".\" \n",
    "    \n",
    "            # SYMTOMATIC\n",
    "            symtomatic=row[\"Syntomatic\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(symtomatic,str) or symtomatic==\"No\" or symtomatic==\"No estoy seguro\":\n",
    "                answer_tipo[\"symtomatic\"]=\"Non-symptomatic consultation\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"symtomatic\"]=symtomatic+\".\" \n",
    "    \n",
    "            # PROSTHESIS\n",
    "            prosthesis=row[\"Prosthesis\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(prosthesis,str) or prosthesis==\"No\":\n",
    "                answer_tipo[\"prosthesis\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"prosthesis\"]=\"yes\"+\".\"\n",
    "    \n",
    "            #BIRADS\n",
    "            birads=row[\"BI-RADS\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(birads,str):\n",
    "                answer_tipo[\"birads\"]=\"unknown\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"birads\"]=birads+\".\"\n",
    "    \n",
    "            #Density mammo\n",
    "            density_mammo=row[\"Density_mamo\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(density_mammo,str):\n",
    "                answer_tipo[\"density_mammo\"]=\"unknown\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"density_mammo\"]=density_mammo+\".\"\n",
    "\n",
    "            #Lymp nodes mammo\n",
    "            ganglio_mamo=row[\"Ganglio_mamo\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(ganglio_mamo,str):\n",
    "                answer_tipo[\"ganglio_mamo\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"ganglio_mamo\"]=ganglio_mamo.lower()+\".\"\n",
    "\n",
    "            #Calcifications benign\n",
    "            calcifications_benign=row[\"Calcifications_benign_mamo\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(calcifications_benign,str):\n",
    "                answer_tipo[\"calcifications_benign\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"calcifications_benign\"]=calcifications_benign.lower()+\".\"\n",
    "\n",
    "            #Parenchymal distortion\n",
    "            parenchymal_distortion=row[\"parenchymal_distortions_asymmetry\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(parenchymal_distortion,str):\n",
    "                answer_tipo[\"parenchymal_distortion\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"parenchymal_distortion\"]=parenchymal_distortion.lower()+\".\"\n",
    "    \n",
    "            #Density echo\n",
    "            density_echo=row[\"Density_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(density_echo,str):\n",
    "                answer_tipo[\"density_echo\"]=\"unknown\"+\".\"            \n",
    "            else:\n",
    "                if density_echo in DENSITY_ECHO:\n",
    "                    answer_tipo[\"density_echo\"]=density_echo+\".\"\n",
    "\n",
    "            #Benign lymph nodes\n",
    "            simple_cyst=row[\"simple_cyst_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(simple_cyst,str):\n",
    "                answer_tipo[\"simple_cyst\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"simple_cyst\"]=simple_cyst.lower()+\".\"\n",
    "            #Suspicious lymph nodes\n",
    "            lymph_suspicious=row[\"Ganglio_suspicious_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(lymph_suspicious,str):\n",
    "                answer_tipo[\"lymph_suspicious\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"lymph_suspicious\"]=lymph_suspicious.lower()+\".\"\n",
    "\n",
    "            #Benign lymph nodes\n",
    "            lymph_benign=row[\"Ganglio_benign_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(lymph_benign,str):\n",
    "                answer_tipo[\"lymph_benign\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"lymph_benign\"]=lymph_benign.lower()+\".\"\n",
    "\n",
    "            #Ductal ectasia\n",
    "            ductal_ectasia=row[\"Ductal_ectasia_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(ductal_ectasia,str):\n",
    "                answer_tipo[\"ductal_ectasia\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"ductal_ectasia\"]=ductal_ectasia.lower()+\".\"\n",
    "    \n",
    "            #Nodules echo\n",
    "            nodules_echo_num=row[\"Nodules_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(nodules_echo_num,str) and not isinstance(nodules_echo_num,int):\n",
    "                answer_tipo[\"nodules_echo_num\"]=\"no\"+\".\"    \n",
    "            elif isinstance(nodules_echo_num,str) and nodules_echo_num==\"No\":\n",
    "                answer_tipo[\"nodules_echo_num\"]=\"no\"+\".\"  \n",
    "            else:\n",
    "                answer_tipo[\"nodules_echo_num\"]=\"yes\"+\".\"\n",
    "    \n",
    "            #Si existen nódulos se hace las preguntas correspondientes\n",
    "            if answer_tipo[\"nodules_echo_num\"]!=\"no.\":\n",
    "                nodules_echo_description=row[\"Description_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                \n",
    "                answer_tipo[\"nodules_echo_description_1\"]=nodules_echo_description+\".\"\n",
    "                    \n",
    "                nodules_echo_shape=row[f\"Shape_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_echo_shape,str):\n",
    "                    answer_tipo[\"nodules_echo_shape_1\"]=\"unknown\"+\".\"\n",
    "                else:\n",
    "                    answer_tipo[\"nodules_echo_shape_1\"]=nodules_echo_shape.lower()+\".\"\n",
    "\n",
    "                nodules_echo_margin=row[\"Margin_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_echo_margin,str):\n",
    "                    answer_tipo[\"nodules_echo_margin_1\"]=\"unknown\"+\".\"\n",
    "                else:\n",
    "                    answer_tipo[\"nodules_echo_margin_1\"]=nodules_echo_margin.lower()+\".\"\n",
    "\n",
    "                nodules_echo_echogenicity=row[\"Echogenicity_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_echo_echogenicity,str):\n",
    "                    answer_tipo[\"nodules_echo_echogenicity_1\"]=\"unknown\"+\".\"\n",
    "                else:\n",
    "                    answer_tipo[\"nodules_echo_echogenicity_1\"]=nodules_echo_echogenicity.lower()+\".\"\n",
    "\n",
    "                nodules_echo_location=row[f\"Location_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_echo_location,str):\n",
    "                    answer_tipo[\"nodules_echo_location_1\"]=\"unknown\"+\".\"\n",
    "                else:\n",
    "                    answer_tipo[\"nodules_echo_location_1\"]=nodules_echo_location.lower()+\".\"\n",
    "\n",
    "                \n",
    "                #Nodules echo size\n",
    "                nodules_echo_size=row[\"size_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_echo_size,str):\n",
    "                    answer_tipo[\"nodules_echo_size_1\"]=\"unknown\"+\".\"            \n",
    "                else:\n",
    "                    answer_tipo[\"nodules_echo_size_1\"]=nodules_echo_size+\".\"\n",
    "        \n",
    "                #Nodules echo known\n",
    "                nodules_echo_known=row[\"new_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_echo_known,str):\n",
    "                    answer_tipo[\"nodules_echo_known_1\"]=\"unknown\"+\".\"\n",
    "                elif nodules_echo_known==\"No\":\n",
    "                    answer_tipo[\"nodules_echo_known_1\"]=\"yes\"+\".\"            \n",
    "                else:\n",
    "                    answer_tipo[\"nodules_echo_known_1\"]=\"no\"+\".\"\n",
    "    \n",
    "                if answer_tipo[\"nodules_echo_known_1\"]==\"yes.\":\n",
    "                    #Nodules echo stable\n",
    "                    nodules_echo_stable=row[\"Stable_eco_1\"]\n",
    "                    # Verificar si el ejemplo tiene preguntas\n",
    "                    if not isinstance(nodules_echo_stable,str):\n",
    "                        answer_tipo[\"nodules_echo_stable_1\"]=\"unknown\"+\".\"\n",
    "                    else:\n",
    "                        answer_tipo[\"nodules_echo_stable_1\"]=nodules_echo_stable.lower()+\".\"\n",
    "            \n",
    "        for tipo in answer_tipo:\n",
    "            \n",
    "            #Si está el tipo en las respuestas que hemos recogido lo metemos a la base de datos.\n",
    "            key_tipo=key+\"_\"+tipo\n",
    "            if key_tipo in flattened_examples:\n",
    "                continue\n",
    "                key_tipo=key_tipo+\"_copy\"\n",
    "            examples_raw[key_tipo]=report\n",
    "            answer=str(answer_tipo[tipo])\n",
    "            \n",
    "    \n",
    "            inputs_tipo = \"Question: \" + question_tipo[tipo] +\" Additional information: \"+ previous_message_answer_tipo[tipo]+ \" Context: \" + informe + \"Options:\"+ options_tipo[tipo]\n",
    "            # inputs_tipo = \"question: \" + question_tipo[tipo] +\" context: \" + informe\n",
    "            flattened_examples[key_tipo]=inputs_tipo\n",
    "            targets[key_tipo]=answer\n",
    "            \n",
    "    return flattened_examples,targets\n",
    "\n",
    "\n",
    "def tokenize_function(inputs):\n",
    "    # Tokenize the input text\n",
    "    model_inputs = tokenizer(\n",
    "        inputs[\"text\"], \n",
    "        max_length=1024, \n",
    "        truncation=True, \n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    \n",
    "    # Tokenize the target labels\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            inputs[\"label\"], \n",
    "            max_length=45, \n",
    "            truncation=True, \n",
    "            padding=\"max_length\"\n",
    "        )\n",
    "    \n",
    "    # Replace padding token id's in labels by -100 to ignore in loss\n",
    "    labels[\"input_ids\"] = [\n",
    "        [-100 if token == tokenizer.pad_token_id else token for token in label_seq]\n",
    "        for label_seq in labels[\"input_ids\"]\n",
    "    ]\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    model_inputs[\"decoder_attention_mask\"] = labels[\"attention_mask\"]\n",
    "    \n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "def generate_output(model,test_data, test_attention, tipo, tokens, beams):\n",
    "    outputs = []\n",
    "    for i,data in enumerate(test_data[tipo]):\n",
    "        output = model.generate(\n",
    "            data.unsqueeze(0),  # Shape: (1, sequence_length)\n",
    "            max_new_tokens=tokens,\n",
    "            attention_mask=test_attention[tipo][i].unsqueeze(0),  # Important for reliable results\n",
    "\n",
    "            num_beams=beams,\n",
    "            num_return_sequences=1,\n",
    "            early_stopping=True\n",
    "        ).squeeze(0).cpu()  # Shape: (generated_sequence_length,)\n",
    "        \n",
    "        outputs.append(output)  # Append 1D tensors (no extra dimensions)\n",
    "\n",
    "    # Pad sequences to the longest one in the batch\n",
    "    outputs_padded = pad_sequence(outputs, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    return outputs_padded  # Shape: (batch_size, max_sequence_length)\n",
    "    \n",
    "def train_save(X,Y,training=True,low_beams=False,testing=False):\n",
    "    random.seed(1)\n",
    "    np.random.seed(1)\n",
    "    predicted=[]\n",
    "    tested=[]\n",
    "    acc_cv=[]\n",
    "    kappa_cv=[]\n",
    "    ind_cv={tipo:[] for tipo in questions}\n",
    "    preds_category_cv={tipo:[] for tipo in questions}\n",
    "    labels_category_cv={tipo:[] for tipo in questions}\n",
    "    accuracies_cv={tipo:[] for tipo in questions}\n",
    "   \n",
    "        \n",
    "    train = train_clean(X,Y)\n",
    "\n",
    "    \n",
    "    \n",
    "    # model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_name, from_flax=True)\n",
    "    train_data = Dataset.from_pandas(train)\n",
    "    \n",
    "    train_data = train_data.map(tokenize_function, batched=True)\n",
    "    # train_data = train_data.rename_column(\"label\", \"labels\")\n",
    "    train_data = train_data.remove_columns([\"text\",\"label\"])\n",
    "    train_data.set_format(\"torch\")\n",
    "    \n",
    "    trainer = Trainer(\n",
    "    model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_data,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    trainer.train()\n",
    "    trainer.save_model(f\"results/{model_name}_second_stage_model_final\")\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "573369dc-7ee8-4ac7-99c3-c3ebe5396aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcarrilero/pytorch_env/lib/python3.13/site-packages/transformers/modeling_flax_pytorch_utils.py:455: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
      "  pt_model_dict[flax_key] = torch.from_numpy(flax_tensor)\n",
      "All Flax model weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "Some weights of T5ForConditionalGeneration were not initialized from the Flax model and are newly initialized: ['encoder.embed_tokens.weight', 'lm_head.weight', 'decoder.embed_tokens.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/mcarrilero/pytorch_env/lib/python3.13/site-packages/transformers/tokenization_utils_base.py:3970: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 4041/4041 [00:02<00:00, 1585.75 examples/s]\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1764' max='1764' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1764/1764 31:23, Epoch 6/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.482100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.068200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.040900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cargar modelo y tokenizador\n",
    "model_name = \"luqh/ClinicalT5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "inputs,targets = flatten_and_filter_dataset(ground_truth,report_data)  \n",
    "\n",
    "\n",
    "#ahora estaba a 1e-5 y 7 epoochs\n",
    "training_args = TrainingArguments(\n",
    "    \n",
    "    # evaluation_strategy=\"steps\",\n",
    "    # eval_steps=10,\n",
    "    \n",
    "    learning_rate=7e-5,  # Lower for fine-tuning without losing generalization\n",
    "    fp16=True,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    \n",
    "    num_train_epochs=7,  # Shorter fine-tuning stage\n",
    "    weight_decay=0.05,  # Lower weight decay to preserve learned features\n",
    "    # save_total_limit=2,\n",
    ")\n",
    "dataset_final=pd.DataFrame.from_dict(inputs,orient='index')\n",
    "targets=pd.DataFrame.from_dict(targets,orient='index')\n",
    "dataset_final.columns=[\"text\"]\n",
    "targets.columns=[\"label\"]\n",
    "train_save(dataset_final,targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2aa3db5-0757-4a2c-94ca-68b91e2d2f8b",
   "metadata": {},
   "source": [
    "##BERT RETRIEVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9344241a-9806-444b-beae-145d0edfd7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_r=[\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\",\"dmis-lab/biobert-base-cased-v1.1\",\"bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12\"]\n",
    "\n",
    "BioMedBERT=\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract0.0001816batch\"\n",
    "BlueBERT=\"bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-120.0001716batch\"\n",
    "BioBERT=\"dmis-lab/biobert-base-cased-v1.10.0001416batch\"\n",
    "models= [BioMedBERT, BlueBERT, BioBERT]\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import numpy as np\n",
    "import gc\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2313d0ec-9cbc-434e-a18d-ef18a9063936",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions=[\"age\",\"history\",\"parenchymal_distortion\",\"nodules_echo_size\"]\n",
    "\n",
    "\n",
    "def fix_brackets_spaces(texto):\n",
    "    ''' \n",
    "        Introduce espacios por delante y por detrás de los paréntesis.\n",
    "        Esta medida mejora el tokenizado de Spacy\n",
    "    '''\n",
    "    \n",
    "    texto = re.sub(r'([(\\[¿!])', r' \\1', texto)\n",
    "    texto = re.sub(r'([)\\]?¡])', r'\\1 ', texto)\n",
    "                \n",
    "    return texto\n",
    "    \n",
    "def preprocess_text(text):\n",
    "    text= fix_brackets_spaces(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def flatten_and_filter_dataset(ground_truth,reports):\n",
    "    \"\"\"\n",
    "    Esta función toma un conjunto de datos en el formato original (con estructura jerárquica)\n",
    "    y devuelve un conjunto de datos plano, donde cada entrada tiene un solo `context`, `question` y `answer`.\n",
    "    \n",
    "    Argumentos:\n",
    "        dataset: Un conjunto de datos en formato original (puede ser train, validation, test).\n",
    "    \n",
    "    Retorno:\n",
    "        Un conjunto de datos de Hugging Face en formato plano, con solo ejemplos completos.\n",
    "    \"\"\"\n",
    "    # Lista para almacenar ejemplos en formato plano\n",
    "    flattened_examples = {}\n",
    "    examples_raw={}\n",
    "    targets={}\n",
    "    questions_examples={}\n",
    "    val_data={}\n",
    "    question_tipo={}\n",
    "    previous_message_answer_tipo={}\n",
    "    options_tipo={}\n",
    "    answers_tipo={}\n",
    "    j=0\n",
    "    \n",
    "    question_tipo[\"age\"]= \"does the patient's age appear in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"age\"]=\"search for numbers, but do not mistake it with the age of a familiar. If a number appears without any context between two dots it is surely the age.\"\n",
    "    \n",
    "\n",
    "    question_tipo[\"history\"]= \"does the patient have any non-familiar history in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"history\"]=\"check for the history at the beginning of the report. Normally it is a previous biopsy result, mastectomy or cancer. It normally starts with 'history of ...'.\"\n",
    "\n",
    "    question_tipo[\"parenchymal_distortion\"]= \"does the following breast medical report mention any parenchymal distortion or asymmetry in the mammography exam?\"\n",
    "    previous_message_answer_tipo[\"parenchymal_distortion\"]=\"If it has any it will appear in the results of the mammography exam using the words distortion, asymmetry or sometimes it can also be surgical changes.\"\n",
    "    \n",
    "\n",
    "    # question_tipo[\"nodules_echo_location_1\"]= \"In which location is the first nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "    # previous_message_answer_tipo[\"nodules_echo_location_1\"]=\"do not consider if a nodule is described in the mammography exam or if it is in the axilla. If the nodule is mentioned previously in the mammography, the location can be found also there. sometimes the breast location of the tumour may be written in a different part than the quadrant. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "    \n",
    "    \n",
    "    question_tipo[\"nodules_echo_size_1\"]= \"what is the size of the first nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"nodules_echo_size_1\"]=\"do not consider if a nodule is described in the mammography exam. The localization, echogenicity and size of the nodules are normally said. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "    \n",
    "    # Iterar sobre cada ejemplo en el conjunto de datos original\n",
    "    for i, report in enumerate(reports[\"informes_ingles\"]):\n",
    "        informe=preprocess_text(report)\n",
    "        key=reports[\"keys\"][i]\n",
    "        \n",
    "        if key not in ground_truth.index:\n",
    "            continue\n",
    "        answer_tipo={}\n",
    "        row=ground_truth.loc[key]\n",
    "        age=str(row[\"Age\"])\n",
    "        # Verificar si el ejemplo tiene preguntas\n",
    "        if age.isdigit():\n",
    "            answer_tipo[\"age\"]=age\n",
    "            \n",
    "        else:\n",
    "            answer_tipo[\"age\"]=\"no response\"\n",
    "\n",
    "        if row[\"Biopsy_report\"]!=\"Yes\" and row[\"Ganglio_report\"]!=\"Yes\":\n",
    "            history=row[\"Other_history\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(history,str) or history==\"No\":\n",
    "                answer_tipo[\"history\"]=\"no response\"           \n",
    "            else:\n",
    "                answer_tipo[\"history\"]=history\n",
    "\n",
    "\n",
    "            #Parenchymal distortion\n",
    "            parenchymal_distortion=row[\"parenchymal_distortions_asymmetry\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(parenchymal_distortion,str) or parenchymal_distortion.lower()==\"no\":\n",
    "                answer_tipo[\"parenchymal_distortion\"]=\"no response\"        \n",
    "            else:\n",
    "                answer_tipo[\"parenchymal_distortion\"]=parenchymal_distortion.lower()\n",
    "\n",
    "            #Nodules echo\n",
    "            nodules_echo_num=row[\"Nodules_eco\"]\n",
    "            \n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(nodules_echo_num,str) and not isinstance(nodules_echo_num,int):\n",
    "                nodules=False\n",
    "            elif isinstance(nodules_echo_num,str) and nodules_echo_num==\"No\":\n",
    "                nodules=False\n",
    "            else:\n",
    "                nodules=True\n",
    "            if nodules:\n",
    "                # nodules_echo_location=row[\"Location_eco_1\"]\n",
    "                # # Verificar si el ejemplo tiene preguntas\n",
    "                # if not isinstance(nodules_echo_location,str):\n",
    "                #     answer_tipo[\"nodules_echo_location_1\"]=\"no response\"\n",
    "                # else:\n",
    "                #     answer_tipo[\"nodules_echo_location_1\"]=nodules_echo_location.lower()\n",
    "                #Nodules echo size\n",
    "                nodules_echo_size=row[\"size_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_echo_size,str):\n",
    "                    answer_tipo[\"nodules_echo_size_1\"]=\"no response\"         \n",
    "                else:\n",
    "                    answer_tipo[\"nodules_echo_size_1\"]=nodules_echo_size\n",
    "                \n",
    "\n",
    "            \n",
    "        for tipo in answer_tipo:\n",
    "            #Si está el tipo en las respuestas que hemos recogido lo metemos a la base de datos.\n",
    "            key_tipo=key+\"_\"+tipo\n",
    "            if key_tipo in flattened_examples:\n",
    "                continue\n",
    "                key_tipo=key_tipo+\"_copy\"\n",
    "            examples_raw[key_tipo]=report\n",
    "            answer=str(answer_tipo[tipo])\n",
    "            \n",
    "            questions_examples[key_tipo]=question_tipo[tipo]\n",
    "            inputs_tipo = \" Additional information: \"+ previous_message_answer_tipo[tipo]+ \" Context: \" + informe\n",
    "            flattened_examples[key_tipo]=inputs_tipo\n",
    "            targets[key_tipo]=answer.strip()\n",
    "        \n",
    "        \n",
    "        \n",
    "        # if answer==word_to_idx_out[\"other\"]:\n",
    "        #     for j in range(2):\n",
    "        #         examples_raw[key+\"_copy\"+str(j)]=report\n",
    "        #         flattened_examples[key+\"_copy\"+str(j)]=informe\n",
    "        #         targets[key+\"_copy\"+str(j)]=answer\n",
    "            \n",
    "        \n",
    "            \n",
    "        \n",
    "    # flattened_examples=pd.DataFrame.from_dict(flattened_examples,orient='index')\n",
    "    # targets=pd.DataFrame.from_dict(targets,orient='index')\n",
    "    return flattened_examples,questions_examples,targets,examples_raw\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def visualize_errors(valid_dataset,valid_targets,validation_predictions,keys):\n",
    "    # Crear un DataFrame con los textos originales, las etiquetas reales y las predicciones\n",
    "    results_df = pd.DataFrame({\n",
    "        'key':list(keys),\n",
    "        'Text': list(valid_dataset),  # Usamos los textos originales\n",
    "        'True Label': list(valid_targets),\n",
    "        'Predicted Label': list(validation_predictions)\n",
    "    })\n",
    "    \n",
    "    # Filtrar los ejemplos en los que el modelo falló\n",
    "    errors_df = results_df[results_df['True Label'] != results_df['Predicted Label']]\n",
    "    \n",
    "    for ind,row in errors_df.iterrows():\n",
    "        print(row[\"key\"])\n",
    "        print(\"EJEMPLO\")\n",
    "        print(row[\"Text\"])\n",
    "        print(\"PREDICTED\")\n",
    "        print(row[\"Predicted Label\"])\n",
    "        print(\"TRUE\")\n",
    "        print(row[\"True Label\"])\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\"],\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    context_texts = examples[\"text\"]\n",
    "    answer_texts = examples[\"label\"]\n",
    "    errors=[]\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "\n",
    "        context = context_texts[i]\n",
    "        answer = answer_texts[i]\n",
    "\n",
    "        # Default to CLS for no response\n",
    "        if answer == \"no response\" or answer.strip() == \"\":\n",
    "            start_positions.append(cls_index)\n",
    "            end_positions.append(cls_index)\n",
    "            continue\n",
    "\n",
    "        # Lowercase match to avoid case mismatch\n",
    "        start_char = context.lower().find(answer.lower())\n",
    "        if start_char == -1:\n",
    "            print(i)\n",
    "            errors.append(i)\n",
    "            print(f\"[WARNING] Could not find answer: '{answer}' in context:\\n{context}\")\n",
    "            start_positions.append(cls_index)\n",
    "            end_positions.append(cls_index)\n",
    "            continue\n",
    "\n",
    "        end_char = start_char + len(answer)\n",
    "\n",
    "        # Now find token positions\n",
    "        start_pos = None\n",
    "        end_pos = None\n",
    "        for idx, (start, end) in enumerate(offsets):\n",
    "            if start <= start_char < end and start_pos is None:\n",
    "                start_pos = idx\n",
    "            if start < end_char <= end:\n",
    "                end_pos = idx\n",
    "                break\n",
    "\n",
    "        if start_pos is None or end_pos is None:\n",
    "            # Fallback if something failed\n",
    "            print(f\"[WARNING] Failed to align answer '{answer}' in context\")\n",
    "            start_positions.append(cls_index)\n",
    "            end_positions.append(cls_index)\n",
    "        else:\n",
    "            start_positions.append(start_pos)\n",
    "            end_positions.append(end_pos)\n",
    "        \n",
    "    tokenized_examples[\"start_positions\"] = start_positions\n",
    "    tokenized_examples[\"end_positions\"] = end_positions\n",
    "    return tokenized_examples\n",
    "    \n",
    "def train_clean(X,Y):\n",
    "    random.seed(1)\n",
    "    \n",
    "    train = X\n",
    "\n",
    "    # Barajar los datos de entrenamiento para evitar sesgos\n",
    "    train = train.sample(frac=1, random_state=1)\n",
    "\n",
    "    train_y = Y.loc[train.index]\n",
    "\n",
    "    train[\"label\"]=train_y[\"label\"]\n",
    "    \n",
    "    return train\n",
    "\n",
    "\n",
    "def predict_indexes(pred):\n",
    "\n",
    "    # Extract logits from predictions\n",
    "    start_logits, end_logits = pred.predictions\n",
    "\n",
    "    \n",
    "    # Get the best start and end indices\n",
    "    start_indexes = np.argmax(start_logits, axis=1)\n",
    "    end_indexes = np.argmax(end_logits, axis=1)\n",
    "\n",
    "    \n",
    "    return start_indexes, end_indexes\n",
    "\n",
    "def extract_answer_from_tokens(tokenized_inputs, start_index, end_index):\n",
    "    \"\"\"\n",
    "    Extracts the predicted answer using tokenized input and index positions.\n",
    "    \n",
    "    Args:\n",
    "        tokenized_inputs: The tokenized dataset\n",
    "        start_index: Predicted start position\n",
    "        end_index: Predicted end position\n",
    "    \n",
    "    Returns:\n",
    "        Extracted text or \"No response\" if CLS token is chosen\n",
    "    \"\"\"\n",
    "    # Convert token IDs back to words\n",
    "    tokens = tokenizer.convert_ids_to_tokens(tokenized_inputs[\"input_ids\"])\n",
    "    \n",
    "    \n",
    "    # If CLS token is chosen (indicating no answer)\n",
    "    if start_index == 0 or end_index == 0 or start_index > end_index:\n",
    "        return \"no response\"\n",
    "\n",
    "    # Extract the predicted text\n",
    "    answer_tokens = tokens[start_index:end_index+1]\n",
    "    answer = tokenizer.convert_tokens_to_string(answer_tokens)\n",
    "    \n",
    "\n",
    "    \n",
    "    return answer\n",
    "\n",
    "\n",
    "def train_save(X, Y):\n",
    "    import torch\n",
    "    from transformers import AutoModelForQuestionAnswering, Trainer\n",
    "    from datasets import Dataset\n",
    "    from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "    random.seed(1)\n",
    "    np.random.seed(1)\n",
    "    \n",
    "    predicted = []\n",
    "    tested = []\n",
    "    acc_cv = []\n",
    "    ind_cv={tipo:[] for tipo in questions}\n",
    "    preds_category_cv={tipo:[] for tipo in questions}\n",
    "    labels_category_cv={tipo:[] for tipo in questions}\n",
    "    accuracies_cv={tipo:[] for tipo in questions}\n",
    "\n",
    "    \n",
    "    train = train_clean(X, Y)\n",
    "    print(len(train))\n",
    "\n",
    "    model = AutoModelForQuestionAnswering.from_pretrained(\n",
    "        model_name\n",
    "    )\n",
    "\n",
    "    train_data = Dataset.from_pandas(train)\n",
    "    \n",
    "\n",
    "    # Tokenize datasets\n",
    "\n",
    "    train_data= train_data.map(tokenize_function, batched=True)\n",
    "    train_data = train_data.rename_column(\"label\", \"labels\")\n",
    "    train_data = train_data.remove_columns([\"text\"])\n",
    "    train_data.set_format(\"torch\")\n",
    "\n",
    "\n",
    "        \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_data\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    trainer.save_model(f\"results/{model_name}_model_final2\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fc98e06-ce8e-4f37-a61b-6b76681a447d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666 666 666\n",
      "666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 666/666 [00:02<00:00, 267.50 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='252' max='252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [252/252 08:44, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.944100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.142900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.657400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.565300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.366400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.297300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.265200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.154400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.104700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.171100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.161100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.073400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.232700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.034700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.032200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.031400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.066000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.029500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.017600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.004900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.007200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.003900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.002800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.004100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666 666 666\n",
      "666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 666/666 [00:01<00:00, 558.16 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='252' max='252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [252/252 08:09, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.211600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.582400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.894500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.616300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.455700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.371500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.322200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.179400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.099600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.127100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.170700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.065100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.162500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.056500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.070600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.081000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.060600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.004400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.009100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.020300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.005700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.006000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666 666 666\n",
      "666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 666/666 [00:01<00:00, 568.75 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='294' max='294' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [294/294 10:05, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.708300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.294600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.823300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.882700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.194100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.739400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.613100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.468300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.514600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.345100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.464100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.315900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.188000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.391100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.225100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.163200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.193200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.180600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.268300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.125700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.230300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.132000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.159200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.117800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.089600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.090600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.083100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Mejor con 4 epochs i 5e-5\n",
    "\n",
    "# BioMedBERT=\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract5e-05616batch\"\n",
    "# BioBERT=\"dmis-lab/biobert-base-cased-v1.15e-05616batch\"\n",
    "# BlueBERT=\"bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-120.0001716batch\"\n",
    "# models_r=[\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\",\"dmis-lab/biobert-base-cased-v1.1\",\"bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12\"]\n",
    "for i,model_name in enumerate(models_r):\n",
    "    \n",
    "    if model_name==\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\":\n",
    "        epochs=6\n",
    "        lr=5e-05\n",
    "    if model_name==\"dmis-lab/biobert-base-cased-v1.1\":\n",
    "        epochs=6\n",
    "        lr=5e-05\n",
    "    if model_name==\"bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12\":\n",
    "        epochs=7\n",
    "        lr=0.0001\n",
    "\n",
    "    inputs,questions_examples,targets,examples_raw = flatten_and_filter_dataset(ground_truth,report_data)  \n",
    "    dataset_final=pd.DataFrame.from_dict(inputs,orient='index')\n",
    "    questions_examples=pd.DataFrame.from_dict(questions_examples,orient='index')\n",
    "    \n",
    "    print(len(dataset_final),len(questions_examples),len(targets))\n",
    "    \n",
    "    targets=pd.DataFrame.from_dict(targets,orient='index')\n",
    "    dataset_final.columns=[\"text\"]\n",
    "    \n",
    "    dataset_final[\"question\"]=questions_examples\n",
    "    \n",
    "    targets.columns=[\"label\"]\n",
    "        \n",
    "    training_args= TrainingArguments(\n",
    "        output_dir='./results',          # Carpeta para guardar el modelo\n",
    "        num_train_epochs=epochs,             # Número de épocas\n",
    "        per_device_train_batch_size=8,  # Tamaño del batch\n",
    "        gradient_accumulation_steps=2,\n",
    "        learning_rate=lr, \n",
    "        weight_decay=0.05,              # Decaimiento del peso\n",
    "        logging_dir='./logs',           # Carpeta para los logs\n",
    "        logging_steps=10,\n",
    "    )\n",
    "    train_save(dataset_final,targets)\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a6116a-97eb-4019-b0ff-900d47d118e6",
   "metadata": {},
   "source": [
    "##BERT CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "002c1576-9cf6-40ff-bbe0-60374490a38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['biopsy report', 'nodal staging ultrasound report', 'normal control or revision report', 'mammography and ultrasound', 'only mammography study', 'only ultrasound study', 'first degree', 'no family history', 'second degree', 'no prosthesis', 'yes prosthesis', 'BI-RADS 0', 'BI-RADS 1', 'BI-RADS 2', 'BI-RADS 3', 'BI-RADS 4A', 'BI-RADS 4B', 'BI-RADS 4C', 'BI-RADS 5', 'BI-RADS 6', 'ACR A', 'ACR B', 'ACR C', 'ACR D', 'unknown density mammo', 'no calcifications', 'yes calcifications', 'no ganglio', 'yes ganglio', 'fibroglandular and fat', 'heterogeneous fibroglandular', 'homogeneous fatty', 'homogeneous fibroglandular', 'unknown density echo', 'no lymph benign', 'yes lymph benign', 'no lymph suspicious', 'yes lymph suspicious', 'no cyst', 'yes cyst', 'no ectasia', 'yes ectasia', 'no nodules', 'yes nodules', 'irregular', 'lobulated', 'oval', 'round', 'unknown shape', 'circumscribed', 'indistinct', 'not circumscribed', 'spiculated', 'unknown margin', 'complex cystic and solid', 'heterogeneous', 'hypoechoic', 'isoechoic', 'unknown echogenicity', 'no known', 'yes known', 'grown stable', 'shrunk stable', 'yes stable']\n"
     ]
    }
   ],
   "source": [
    "questions=[\"tipo\",\"tecnica\",\"family\",\n",
    "           \"prosthesis\",\"birads\",\"density_mammo\",\"calcifications_benign\",\"ganglio_mamo\",\"density_echo\",\"lymph_benign\",\"lymph_suspicious\",\"simple_cyst\",\"ductal_ectasia\"]\n",
    "\n",
    "TIPO=[\"biopsy report\", \"nodal staging ultrasound report\", \"normal control or revision report\"]\n",
    "TECNICA=[\"only ultrasound study\", \"only mammography study\", \"mammography and ultrasound\"]\n",
    "FAMILY=[\"no family history\", \"first degree\", \"second degree\"]\n",
    "PROSTHESIS=[\"no prosthesis\",\"yes prosthesis\"]\n",
    "BIRADS=[\"BI-RADS 0\",\"BI-RADS 1\",\"BI-RADS 2\",\"BI-RADS 3\",\"BI-RADS 4A\",\"BI-RADS 4B\",\"BI-RADS 4C\",\"BI-RADS 5\",\"BI-RADS 6\"]\n",
    "DENSITY_MAMMO=[\"ACR A\",\"ACR B\",\"ACR C\",\"ACR D\",\"unknown density mammo\"]\n",
    "CALCIFICATIONS_BENIGN=[\"no calcifications\",\"yes calcifications\"]\n",
    "GANGLIO_MAMO=[\"no ganglio\",\"yes ganglio\"]\n",
    "DENSITY_ECHO=[\"homogeneous fibroglandular\",\"heterogeneous fibroglandular\",\"fibroglandular and fat\",\"homogeneous fatty\",\"unknown density echo\"]\n",
    "LYMPH_BENIGN=[\"no lymph benign\",\"yes lymph benign\"]\n",
    "LYMPH_SUSPICIOUS=[\"no lymph suspicious\",\"yes lymph suspicious\"]\n",
    "SIMPLE_CYST=[\"no cyst\",\"yes cyst\"]\n",
    "DUCTAL_ECTASIA=[\"no ectasia\",\"yes ectasia\"]\n",
    "NODULES_ECHO=[\"no nodules\", \"yes nodules\"]\n",
    "NODULES_SHAPE=[\"oval\",\"round\",\"lobulated\",\"irregular\",\"unknown shape\"]\n",
    "NODULES_MARGIN=[\"circumscribed\",\"spiculated\",\"indistinct\",\"not circumscribed\",\"unknown margin\"]\n",
    "NODULES_ECHOGENICITY=[\"hypoechoic\", \"isoechoic\", \"heterogeneous\",\"complex cystic and solid\",\"unknown echogenicity\"]\n",
    "NODULES_KNOWN=[\"no known\", \"yes known\"]\n",
    "NODULES_STABLE=[\"grown stable\",\"shrunk stable\", \"yes stable\"]\n",
    "\n",
    "\n",
    "TIPO.sort()\n",
    "TECNICA.sort()\n",
    "FAMILY.sort()\n",
    "PROSTHESIS.sort()\n",
    "BIRADS.sort()\n",
    "DENSITY_MAMMO.sort()\n",
    "CALCIFICATIONS_BENIGN.sort()\n",
    "GANGLIO_MAMO.sort()\n",
    "DENSITY_ECHO.sort()\n",
    "LYMPH_BENIGN.sort()\n",
    "SIMPLE_CYST.sort()\n",
    "DUCTAL_ECTASIA.sort()\n",
    "NODULES_ECHO.sort()\n",
    "NODULES_SHAPE.sort()\n",
    "NODULES_MARGIN.sort()\n",
    "NODULES_ECHOGENICITY.sort()\n",
    "NODULES_KNOWN.sort()\n",
    "NODULES_STABLE.sort()\n",
    "\n",
    "\n",
    "word_to_idx_tipo={word:idx for idx,word in enumerate(TIPO)}\n",
    "idx_to_word_tipo={idx:word for idx,word in enumerate(TIPO)}\n",
    "\n",
    "word_to_idx_tecnica={word:idx for idx,word in enumerate(TECNICA)}\n",
    "idx_to_word_tecnica={idx:word for idx,word in enumerate(TECNICA)}\n",
    "\n",
    "word_to_idx_family={word:idx for idx,word in enumerate(FAMILY)}\n",
    "idx_to_word_family={idx:word for idx,word in enumerate(FAMILY)}\n",
    "\n",
    "word_to_idx_prosthesis={word:idx for idx,word in enumerate(PROSTHESIS)}\n",
    "idx_to_word_prosthesis={idx:word for idx,word in enumerate(PROSTHESIS)}\n",
    "\n",
    "word_to_idx_birads={word:idx for idx,word in enumerate(BIRADS)}\n",
    "idx_to_word_birads={idx:word for idx,word in enumerate(BIRADS)}\n",
    "\n",
    "word_to_idx_density_mammo={word:idx for idx,word in enumerate(DENSITY_MAMMO)}\n",
    "idx_to_word_density_mammo={idx:word for idx,word in enumerate(DENSITY_MAMMO)}\n",
    "\n",
    "word_to_idx_calcifications_benign={word:idx for idx,word in enumerate(CALCIFICATIONS_BENIGN)}\n",
    "idx_to_word_calcifications_benign={idx:word for idx,word in enumerate(CALCIFICATIONS_BENIGN)}\n",
    "\n",
    "word_to_idx_ganglio_mamo={word:idx for idx,word in enumerate(GANGLIO_MAMO)}\n",
    "idx_to_word_ganglio_mamo={idx:word for idx,word in enumerate(GANGLIO_MAMO)}\n",
    "\n",
    "word_to_idx_density_echo={word:idx for idx,word in enumerate(DENSITY_ECHO)}\n",
    "idx_to_word_density_echo={idx:word for idx,word in enumerate(DENSITY_ECHO)}\n",
    "\n",
    "word_to_idx_lymph_benign={word:idx for idx,word in enumerate(LYMPH_BENIGN)}\n",
    "idx_to_word_lymph_benign={idx:word for idx,word in enumerate(LYMPH_BENIGN)}\n",
    "\n",
    "word_to_idx_lymph_suspicious={word:idx for idx,word in enumerate(LYMPH_SUSPICIOUS)}\n",
    "idx_to_word_lymph_suspicious={idx:word for idx,word in enumerate(LYMPH_SUSPICIOUS)}\n",
    "\n",
    "word_to_idx_simple_cyst={word:idx for idx,word in enumerate(SIMPLE_CYST)}\n",
    "idx_to_word_simple_cyst={idx:word for idx,word in enumerate(SIMPLE_CYST)}\n",
    "\n",
    "word_to_idx_ductal_ectasia={word:idx for idx,word in enumerate(DUCTAL_ECTASIA)}\n",
    "idx_to_word_ductal_ectasia={idx:word for idx,word in enumerate(DUCTAL_ECTASIA)}\n",
    "DICTIONARY={\"tipo\":TIPO,\"tecnica\":TECNICA,\"family\":FAMILY,\"prosthesis\":PROSTHESIS,\"birads\":BIRADS,\"density_mammo\":DENSITY_MAMMO,\"calcifications_benign\":CALCIFICATIONS_BENIGN,\n",
    "            \"ganglio_mamo\":GANGLIO_MAMO,\"density_echo\":DENSITY_ECHO,\"lymph_benign\":LYMPH_BENIGN,\"lymph_suspicious\":LYMPH_SUSPICIOUS,\"simple_cyst\":SIMPLE_CYST,\"ductal_ectasia\":DUCTAL_ECTASIA,\n",
    "           \"nodules_echo\": NODULES_ECHO,\"nodules_shape\":NODULES_SHAPE,\"nodules_margin\":NODULES_MARGIN, \"nodules_echogenicity\":NODULES_ECHOGENICITY, \"nodules_known\":NODULES_KNOWN, \"nodules_stable\":NODULES_STABLE}\n",
    "\n",
    "\n",
    "outputs=[]\n",
    "for tipo in DICTIONARY.values():\n",
    "    outputs+=tipo\n",
    "print(outputs)\n",
    "\n",
    "word_to_idx_out={word:idx for idx,word in enumerate(outputs)}\n",
    "idx_to_word_out={idx:word for idx,word in enumerate(outputs)}\n",
    "import gc\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def fix_brackets_spaces(texto):\n",
    "    ''' \n",
    "        Introduce espacios por delante y por detrás de los paréntesis.\n",
    "        Esta medida mejora el tokenizado de Spacy\n",
    "    '''\n",
    "    \n",
    "    texto = re.sub(r'([(\\[¿!])', r' \\1', texto)\n",
    "    texto = re.sub(r'([)\\]?¡])', r'\\1 ', texto)\n",
    "                \n",
    "    return texto\n",
    "    \n",
    "def preprocess_text(text):\n",
    "    text= fix_brackets_spaces(text)\n",
    "    # print(text)\n",
    "    \n",
    "    # print(text)\n",
    "    return text\n",
    "\n",
    "    \n",
    "def flatten_and_filter_dataset(ground_truth,reports):\n",
    "    \"\"\"\n",
    "    Esta función toma un conjunto de datos en el formato original (con estructura jerárquica)\n",
    "    y devuelve un conjunto de datos plano, donde cada entrada tiene un solo `context`, `question` y `answer`.\n",
    "    \n",
    "    Argumentos:\n",
    "        dataset: Un conjunto de datos en formato original (puede ser train, validation, test).\n",
    "    \n",
    "    Retorno:\n",
    "        Un conjunto de datos de Hugging Face en formato plano, con solo ejemplos completos.\n",
    "    \"\"\"\n",
    "    # Lista para almacenar ejemplos en formato plano\n",
    "    \n",
    "    j=0\n",
    "    flattened_examples = {}\n",
    "    examples_raw={}\n",
    "    targets={}\n",
    "    val_data={}\n",
    "    question_tipo={}\n",
    "    previous_message_answer_tipo={}\n",
    "    options_tipo={}\n",
    "    answers_tipo={}\n",
    "    j=0\n",
    "    \n",
    "    question_tipo[\"tipo\"]= 'is the following breast medical report a biopsy report or a nodal staging ultrasound report?'\n",
    "    previous_message_answer_tipo[\"tipo\"]=\"biopsy reports are Image-Guided Biopsy or Fine needle aspiration and is normally said that they are referred to the hospital for biopsy. Nodal staging ultrasound reports can also be written as 'axilla ultrasound'. If it is any of these it will be written in the beginning of the report, normally in the used technique. These kind of reports are only ultrasound.\"\n",
    "    \n",
    "\n",
    "    question_tipo[\"tecnica\"]= 'what diagnostic technique was used in the following breast medical report?'\n",
    "    previous_message_answer_tipo[\"tecnica\"]=\"biopsy reports, simple cysts and analysis of lymph or axillary nodes are only seen on ultrasound. On the other hand, if the ACR density is given or parenchymal distortions are analysed, the technique will be a mammogram. Tomosyntesis is a mammography type. The report may include an ultrasound examination, a mammography examination or both.\"\n",
    "    \n",
    "\n",
    "    question_tipo[\"family\"]= \"does the patient have any family history in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"family\"]=\"family history of breast cancer is categorized based on the degree of relatives affected: First-degree relatives: Parents, siblings, or children. Second-degree relatives: Grandparents, aunts, uncles, nieces, nephews, or half-siblings. Third-degree relatives: Great-grandparents, great-aunts/uncles, or first cousins.\"\n",
    "    \n",
    "    question_tipo[\"prosthesis\"]= \"does the patient have a prosthesis in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"prosthesis\"]=\"it is normally clearly indicated at the beginning of the report. Sometimes it is written as implants instead of prosthesis.\"\n",
    "    \n",
    "    question_tipo[\"birads\"]= \"what is the final BI-RADS classification given to the patient in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"birads\"]=\"the final BI-RADS of the patient is given in the conclusions of the report, normally at the end.\"\n",
    "\n",
    "    question_tipo[\"density_mammo\"]= \"what is the breast density found in the mammography study of the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"density_mammo\"]=\"breast density in mammography is classified into four categories: ACR A (= Almost entirely fatty), ACR B (= Scattered areas of fibroglandular density), ACR C (= Heterogeneously dense), ACR D (= Extremely or very dense breasts). Sometimes it is written as 'density type x' or with their real meaning (very dense breasts = C).\"\n",
    "       \n",
    "    question_tipo[\"density_echo\"]= \"what is the breast density found in the ultrasound study of the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"density_echo\"]=\"breast composition in ultrasound is classified into four categories: fibroglandular and fat (mixed distribution of fibroglandular and adipose tissue), heterogeneous fibroglandular (predominantly fibroglandular tissue with varying echogenicity and scattered fat areas), homogeneous fatty (uniform fatty tissue with consistent echogenicity and minimal fibroglandular content), and homogeneous fibroglandular (uniform fibroglandular tissue with consistent echogenicity and minimal fat content).\"\n",
    "    \n",
    "    question_tipo[\"calcifications_benign\"]= \"does the following breast medical report mention the appearence of benign calcifications in the mammography exam?\"\n",
    "    previous_message_answer_tipo[\"calcifications_benign\"]=\"Consider only benign calcifications in the mammography.\"\n",
    "      \n",
    "    question_tipo[\"ganglio_mamo\"]= \"does the following breast medical report mention any lymph nodes in the mammography exam?\"\n",
    "    previous_message_answer_tipo[\"ganglio_mamo\"]=\"Consider only lymph nodes that appear in the mammography.\"\n",
    "    \n",
    "    question_tipo[\"lymph_suspicious\"]= \"does the following breast medical report mention any suspicious axillary lymph nodes in the ultrasound exam?\"\n",
    "    previous_message_answer_tipo[\"lymph_suspicious\"]=\"if a lymph node is suspicious the report will recomend a biopsy or Fine Needle Aspiration. A lymph node is considered suspicious when it has eccentric cortical thickening ≥ 3 mm, Short axis >10 mm, round shape, loss of fatty hilum, abnormal vascularity, or irregular margins—especially when associated with known malignancy or progressive enlargement. They can also be classified as UN3, UN4 or UN5. An exam may have both suspicious and benign lymph nodes.\"\n",
    "\n",
    "    question_tipo[\"lymph_benign\"]= \"does the following breast medical report mention any benign or not suspicious axillary lymph nodes in the ultrasound exam?\"\n",
    "    previous_message_answer_tipo[\"lymph_benign\"]=\"if a lymph node is suspicious the report will recomend a biopsy or Fine Needle Aspiration. A lymph node is considered benign when it has uniform cortex < 3 mm, preserved fatty hilum, oval shape, no abnormal vascularity, no irregular margins and homogeneous internal echo pattern. Benign axillary nodes can be classified as UN1 or UN2. A reactive axillary node is not suspicious. An exam may have both suspicious and benign lymph nodes.\"\n",
    "    \n",
    "    question_tipo[\"simple_cyst\"]= \"does the following breast medical report mention any simple cysts or microcysts in the ultrasound exam?\"\n",
    "    previous_message_answer_tipo[\"simple_cyst\"]=\"The words symple cysts or microcysts will appear only in the ultrasound exam. Sometimes they can say that some of the cysts have echogenic content, but we still will consider them simple cysts and not nodules.\"\n",
    "    \n",
    "    question_tipo[\"ductal_ectasia\"]= \"does the following breast medical report mention any ductal ectasia in the ultrasound exam?\"\n",
    "    previous_message_answer_tipo[\"ductal_ectasia\"]=\"The word ductal ectasia will appear only in the ultrasound exam.\"\n",
    "\n",
    "    question_tipo[\"nodules_echo\"]= \"is there any nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"nodules_echo\"]=\"The localization, echogenicity and size of the nodules are normally said.\"\n",
    "    \n",
    "    question_tipo[\"nodules_shape\"]= \"what is the shape of the first nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"nodules_shape\"]=\"Shapes can be 'oval', 'round', 'lobulated' and 'irregular'. Sometimes irregular is also used for the margin, but in this case it is written as 'irregular margin' or 'irregular borders'. \"\n",
    "    \n",
    "    question_tipo[\"nodules_margin\"]= \"what is the margin of the first nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"nodules_margin\"]=\"Margin can be 'circumscribed' and 'not circumscribed'. Inside the not circumscribed we have 'spiculated', 'angulated', 'microlobulated' or 'indistinc' ('not defined') margins. Sometimes irregular is also used for the margin, but in this case it is written as 'irregular margin' or 'irregular borders', in this case classify it as 'not circumscribed'.\"\n",
    "    \n",
    "    question_tipo[\"nodules_echogenicity\"]= \"what is the echogenicity of the first nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"nodules_echogenicity\"]=\"Echogenicity can be 'anechoic', 'hypoechoic', 'heterogeneous' and 'complex cystic and solid'.\" \n",
    "    \n",
    "    question_tipo[\"nodules_known\"]= \"is the first nodule described in the ultrasound exam of the following breast medical report previously known?\"\n",
    "    previous_message_answer_tipo[\"nodules_known\"]=\"If the nodule is known from before the report, it will say if it it is stable or if it has grown or shrink.\"\n",
    "    \n",
    "    question_tipo[\"nodules_stable\"]= \"is the first known nodule described in the ultrasound exam stable in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"nodules_stable\"]=\"If the nodule is known from before the examination, it will be analysed to see if it is stable or if it got bigger or smaller. \"\n",
    "    \n",
    "    for i, report in enumerate(reports[\"informes_ingles\"]):\n",
    "        informe=preprocess_text(report)\n",
    "        key=reports[\"keys\"][i]\n",
    "        \n",
    "        if key not in ground_truth.index:\n",
    "            continue\n",
    "        if key in flattened_examples:\n",
    "            continue\n",
    "\n",
    "        n_tipo=np.zeros(len(outputs))\n",
    "        n_tecnica=np.zeros(len(outputs))\n",
    "        n_family=np.zeros(len(outputs))\n",
    "        n_prosthesis=np.zeros(len(outputs))\n",
    "        n_birads=np.zeros(len(outputs))\n",
    "        n_density_mammo=np.zeros(len(outputs))\n",
    "        n_calcifications_benign=np.zeros(len(outputs))\n",
    "        n_ganglio_mamo=np.zeros(len(outputs))\n",
    "        n_density_echo=np.zeros(len(outputs))\n",
    "        n_lymph_benign=np.zeros(len(outputs))\n",
    "        n_lymph_suspicious=np.zeros(len(outputs))\n",
    "        n_simple_cyst=np.zeros(len(outputs))\n",
    "        n_ductal_ectasia=np.zeros(len(outputs))\n",
    "        n_nodules_echo=np.zeros(len(outputs))\n",
    "        n_nodules_shape=np.zeros(len(outputs))\n",
    "        n_nodules_margin=np.zeros(len(outputs))\n",
    "        n_nodules_echogenicity=np.zeros(len(outputs))\n",
    "        n_nodules_known=np.zeros(len(outputs))\n",
    "        n_nodules_stable=np.zeros(len(outputs))\n",
    "        row=ground_truth.loc[key]\n",
    "        answer_tipo={}\n",
    "        #TIPO\n",
    "        normal_control=False\n",
    "        if row[\"Biopsy_report\"]==\"Yes\":\n",
    "            n_tipo[word_to_idx_out[\"biopsy report\"]]=1\n",
    "            \n",
    "        elif row[\"Ganglio_report\"]==\"Yes\":\n",
    "            n_tipo[word_to_idx_out[\"nodal staging ultrasound report\"]]=1\n",
    "        else:\n",
    "            normal_control=True\n",
    "            n_tipo[word_to_idx_out[\"normal control or revision report\"]]=1\n",
    "        answer_tipo[\"tipo\"]=n_tipo\n",
    "        #TECHNIQUE\n",
    "        tecnica=row[\"Technique\"]\n",
    "        # Verificar si el ejemplo tiene preguntas\n",
    "        if tecnica==\"ultrasound\":\n",
    "            n_tecnica[word_to_idx_out[\"only ultrasound study\"]]=1          \n",
    "        elif tecnica==\"mammography\":\n",
    "            n_tecnica[word_to_idx_out[\"only mammography study\"]]=1\n",
    "        elif not pd.isna(tecnica):\n",
    "            n_tecnica[word_to_idx_out[tecnica]]=1\n",
    "        else:\n",
    "            print(key,report)\n",
    "        answer_tipo[\"tecnica\"]=n_tecnica\n",
    "        # \n",
    "        # HISTORY\n",
    "        #No consideramos las biopsias o las ecografías de estadificación ganglionar.\n",
    "        if normal_control:\n",
    "            \n",
    "            family=row[\"Family_history\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(family,str) or family==\"No\":\n",
    "                n_family[word_to_idx_out[\"no family history\"]]=1         \n",
    "            else:\n",
    "                n_family[word_to_idx_out[family]]=1\n",
    "            answer_tipo[\"family\"]=n_family    \n",
    "            # PROSTHESIS\n",
    "            prosthesis=row[\"Prosthesis\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(prosthesis,str) or prosthesis==\"No\":\n",
    "                n_prosthesis[word_to_idx_out[\"no prosthesis\"]]=1        \n",
    "            else:\n",
    "                n_prosthesis[word_to_idx_out[\"yes prosthesis\"]]=1\n",
    "            answer_tipo[\"prosthesis\"]=n_prosthesis\n",
    "            #BIRADS\n",
    "            birads=row[\"BI-RADS\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(birads,str):\n",
    "                n_birads[word_to_idx_out[\"unknown BI-RADS\"]]=1           \n",
    "            else:\n",
    "                n_birads[word_to_idx_out[birads]]=1\n",
    "            answer_tipo[\"birads\"]=n_birads\n",
    "            #Density mammo\n",
    "            density_mammo=row[\"Density_mamo\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(density_mammo,str) or density_mammo not in DENSITY_MAMMO:\n",
    "                n_density_mammo[word_to_idx_out[\"unknown density mammo\"]]=1       \n",
    "            else:\n",
    "                n_density_mammo[word_to_idx_out[density_mammo]]=1\n",
    "            answer_tipo[\"density_mammo\"]=n_density_mammo\n",
    "            #Lymp nodes mammo\n",
    "            ganglio_mamo=row[\"Ganglio_mamo\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(ganglio_mamo,str):\n",
    "                n_ganglio_mamo[word_to_idx_out[\"no ganglio\"]]=1            \n",
    "            else:\n",
    "                n_ganglio_mamo[word_to_idx_out[ganglio_mamo.lower()+\" ganglio\"]]=1\n",
    "            answer_tipo[\"ganglio_mamo\"]=n_ganglio_mamo\n",
    "            #Calcifications benign\n",
    "            calcifications_benign=row[\"Calcifications_benign_mamo\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(calcifications_benign,str):\n",
    "                n_calcifications_benign[word_to_idx_out[\"no calcifications\"]]=1       \n",
    "            else:\n",
    "                n_calcifications_benign[word_to_idx_out[calcifications_benign.lower()+ \" calcifications\"]]=1\n",
    "            answer_tipo[\"calcifications_benign\"]=n_calcifications_benign\n",
    "        \n",
    "    \n",
    "            #Density echo\n",
    "            density_echo=row[\"Density_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(density_echo,str)or density_echo not in DENSITY_ECHO:\n",
    "                n_density_echo[word_to_idx_out[\"unknown density echo\"]]=1         \n",
    "            else:\n",
    "                n_density_echo[word_to_idx_out[density_echo]]=1\n",
    "            answer_tipo[\"density_echo\"]=n_density_echo\n",
    "            #Benign lymph nodes\n",
    "            simple_cyst=row[\"simple_cyst_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(simple_cyst,str):\n",
    "                n_simple_cyst[word_to_idx_out[\"no cyst\"]]=1         \n",
    "            else:\n",
    "                n_simple_cyst[word_to_idx_out[simple_cyst.lower()+\" cyst\"]]=1\n",
    "\n",
    "            answer_tipo[\"simple_cyst\"]=n_simple_cyst\n",
    "            #Suspicious lymph nodes\n",
    "            lymph_suspicious=row[\"Ganglio_suspicious_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(lymph_suspicious,str):\n",
    "                n_lymph_suspicious[word_to_idx_out[\"no lymph suspicious\"]]=1         \n",
    "            else:\n",
    "                n_lymph_suspicious[word_to_idx_out[lymph_suspicious.lower()+ \" lymph suspicious\"]]=1\n",
    "            answer_tipo[\"lymph_suspicious\"]=n_lymph_suspicious\n",
    "            #Benign lymph nodes\n",
    "            lymph_benign=row[\"Ganglio_benign_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            \n",
    "            if not isinstance(lymph_benign,str):\n",
    "                n_lymph_benign[word_to_idx_out[\"no lymph benign\"]]=1           \n",
    "            else:\n",
    "                n_lymph_benign[word_to_idx_out[lymph_benign.lower()+ \" lymph benign\"]]=1\n",
    "            answer_tipo[\"lymph_benign\"]=n_lymph_benign\n",
    "            #Ductal ectasia\n",
    "            ductal_ectasia=row[\"Ductal_ectasia_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(ductal_ectasia,str):\n",
    "                n_ductal_ectasia[word_to_idx_out[\"no ectasia\"]]=1    \n",
    "            else:\n",
    "                n_ductal_ectasia[word_to_idx_out[ductal_ectasia.lower()+\" ectasia\"]]=1\n",
    "            answer_tipo[\"ductal_ectasia\"]=n_ductal_ectasia\n",
    "\n",
    "            nodules_echo=row[\"Nodules_eco\"]\n",
    "            nodules_bool=False\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(nodules_echo,str) and not isinstance(nodules_echo,int):\n",
    "                n_nodules_echo[word_to_idx_out[\"no nodules\"]]=1\n",
    "            elif isinstance(nodules_echo,str) and nodules_echo==\"No\":\n",
    "                n_nodules_echo[word_to_idx_out[\"no nodules\"]]=1\n",
    "            else:\n",
    "                nodules_bool=True\n",
    "                n_nodules_echo[word_to_idx_out[\"yes nodules\"]]=1\n",
    "            answer_tipo[\"nodules_echo\"]=n_nodules_echo\n",
    "            if nodules_bool:\n",
    "                #Density echo\n",
    "                nodules_shape=row[\"Shape_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_shape,str)or nodules_shape not in NODULES_SHAPE:\n",
    "                    n_nodules_shape[word_to_idx_out[\"unknown shape\"]]=1         \n",
    "                else:\n",
    "                    n_nodules_shape[word_to_idx_out[nodules_shape]]=1\n",
    "                answer_tipo[\"nodules_shape\"]=n_nodules_shape\n",
    "\n",
    "                nodules_margin=row[\"Margin_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_margin,str)or nodules_margin not in NODULES_MARGIN:\n",
    "                    n_nodules_margin[word_to_idx_out[\"unknown margin\"]]=1         \n",
    "                else:\n",
    "                    n_nodules_margin[word_to_idx_out[nodules_margin]]=1\n",
    "                answer_tipo[\"nodules_margin\"]=n_nodules_margin\n",
    "\n",
    "                nodules_echogenicity=row[\"Echogenicity_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_echogenicity,str)or nodules_echogenicity not in NODULES_ECHOGENICITY:\n",
    "                    n_nodules_echogenicity[word_to_idx_out[\"unknown echogenicity\"]]=1         \n",
    "                else:\n",
    "                    n_nodules_echogenicity[word_to_idx_out[nodules_echogenicity]]=1\n",
    "                answer_tipo[\"nodules_echogenicity\"]=n_nodules_echogenicity\n",
    "\n",
    "                #Nodules echo known\n",
    "                nodules_known=row[\"new_eco_1\"]\n",
    "                known_bool=False\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_known,str):\n",
    "                    n_nodules_known[word_to_idx_out[\"unknown known\"]]=1\n",
    "                elif nodules_known==\"No\":\n",
    "                    known_bool=True\n",
    "                    n_nodules_known[word_to_idx_out[\"yes known\"]]=1    \n",
    "                else:\n",
    "                    n_nodules_known[word_to_idx_out[\"no known\"]]=1\n",
    "                answer_tipo[\"nodules_known\"]=n_nodules_known\n",
    "                if known_bool:\n",
    "                    #Nodules echo stable\n",
    "                    nodules_stable=row[\"Stable_eco_1\"]\n",
    "                    # Verificar si el ejemplo tiene preguntas\n",
    "                    if not isinstance(nodules_stable,str):\n",
    "                        n_nodules_stable[word_to_idx_out[\"unknown stable\"]]=1\n",
    "                    else:\n",
    "                        n_nodules_stable[word_to_idx_out[nodules_stable.lower()+\" stable\"]]=1\n",
    "                    answer_tipo[\"nodules_stable\"]=n_nodules_stable\n",
    "\n",
    "                \n",
    "                \n",
    "\n",
    "        for tipo in answer_tipo:\n",
    "            #Si está el tipo en las respuestas que hemos recogido lo metemos a la base de datos.\n",
    "            key_tipo=key+\"_\"+tipo\n",
    "            if key_tipo in flattened_examples:\n",
    "                continue\n",
    "                key_tipo=key_tipo+\"_copy\"\n",
    "            examples_raw[key_tipo]=report\n",
    "            answer=answer_tipo[tipo]\n",
    "            \n",
    "    \n",
    "            inputs_tipo = \"Question: \" + question_tipo[tipo] +\" Extra information: \"+ previous_message_answer_tipo[tipo]+ \" Context: \" + informe\n",
    "            flattened_examples[key_tipo]=inputs_tipo\n",
    "            targets[key_tipo]=int(np.argmax(answer))\n",
    "    return flattened_examples,targets\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def visualize_errors(valid_dataset,valid_targets,validation_predictions,keys):\n",
    "    # Crear un DataFrame con los textos originales, las etiquetas reales y las predicciones\n",
    "    results_df = pd.DataFrame({\n",
    "        'key':list(keys),\n",
    "        'Text': list(valid_dataset),  # Usamos los textos originales\n",
    "        'True Label': list(valid_targets),\n",
    "        'Predicted Label': list(validation_predictions)\n",
    "    })\n",
    "    \n",
    "    # Filtrar los ejemplos en los que el modelo falló\n",
    "    errors_df = results_df[results_df['True Label'] != results_df['Predicted Label']]\n",
    "    \n",
    "    for ind,row in errors_df.iterrows():\n",
    "        print(row[\"key\"])\n",
    "        print(\"EJEMPLO\")\n",
    "        print(row[\"Text\"])\n",
    "        print(\"PREDICTED\")\n",
    "        print(idx_to_word_out[row[\"Predicted Label\"]])\n",
    "        print(\"TRUE\")\n",
    "        print(idx_to_word_out[row[\"True Label\"]])\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    texts = examples[\"text\"]\n",
    "    \n",
    "    outputs = tokenizer(\n",
    "        texts,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "    # Verificar truncación\n",
    "    for i, text in enumerate(texts):\n",
    "        untruncated = tokenizer(\n",
    "            text,\n",
    "            truncation=False,\n",
    "            add_special_tokens=True\n",
    "        )\n",
    "        if len(untruncated[\"input_ids\"]) > 512:\n",
    "            print(\"⚠️ Truncation occurred!\")\n",
    "            print(f\"Original length: {len(untruncated['input_ids'])}, Truncated to: 512\")\n",
    "            print(\"Sample text:\", text[:200], \"...\\n\")\n",
    "\n",
    "    return outputs\n",
    "def train_clean(X, Y):\n",
    "    random.seed(1)\n",
    "    # Agrupar ejemplos originales y sus copias\n",
    "\n",
    "    \n",
    "    train = X\n",
    "\n",
    "    # Barajar los datos de entrenamiento para evitar sesgos\n",
    "    train = train.sample(frac=1, random_state=1)\n",
    "    print(train)\n",
    "    train_y = Y.loc[train.index]\n",
    "    print(train_y)\n",
    "    train[\"label\"]=train_y[\"label\"]\n",
    "    \n",
    "    # Devolver los conjuntos\n",
    "    train = train.reset_index(drop=True)\n",
    "    \n",
    "    return train\n",
    "\n",
    "def evaluate_per_question(predicted, tested, DICTIONARY):\n",
    "    \"\"\"\n",
    "    Evaluate model predictions per question type.\n",
    "    \n",
    "    Parameters:\n",
    "    - predicted: array of predicted label indices (flattened from all folds)\n",
    "    - tested: array of true label indices (same shape as predicted)\n",
    "    - DICTIONARY: dict mapping each question to its list of class names\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Build global index → (question, class_name) mapping\n",
    "    idx_to_question_value = {}\n",
    "    offset = 0\n",
    "    question_offsets = {}\n",
    "    for question, class_list in DICTIONARY.items():\n",
    "        question_offsets[question] = offset\n",
    "        for i, label in enumerate(class_list):\n",
    "            idx_to_question_value[offset + i] = (question, label)\n",
    "        offset += len(class_list)\n",
    "\n",
    "    # Step 2: Group predictions by question\n",
    "    per_question_true = defaultdict(list)\n",
    "    per_question_pred = defaultdict(list)\n",
    "\n",
    "    for true_idx, pred_idx in zip(tested, predicted):\n",
    "        q_true, _ = idx_to_question_value[true_idx]\n",
    "        # You can check if q_true == q_pred here for safety if needed\n",
    "        per_question_true[q_true].append(true_idx)\n",
    "        per_question_pred[q_true].append(pred_idx)\n",
    "\n",
    "    # Step 3: Classification reports\n",
    "    print(\"\\n🔍 Per-question classification reports:\\n\")\n",
    "    for question, true_labels in per_question_true.items():\n",
    "        pred_labels = per_question_pred[question]\n",
    "        label_names = DICTIONARY[question]\n",
    "        start = question_offsets[question]\n",
    "        end = start + len(label_names)\n",
    "        question_label_ids = list(range(start, end))\n",
    "\n",
    "        print(f\"\\n📘 Question: {question}\")\n",
    "        try:\n",
    "            print(classification_report(true_labels, pred_labels, labels=question_label_ids, target_names=label_names))\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Could not generate report for '{question}': {e}\")\n",
    "\n",
    "    print(\"\\n📊 Accuracy per class and per question:\\n\")\n",
    "    for question in DICTIONARY:\n",
    "        y_true = np.array(per_question_true[question])\n",
    "        y_pred = np.array(per_question_pred[question])\n",
    "        class_list = DICTIONARY[question]\n",
    "        start = question_offsets[question]\n",
    "    \n",
    "        if len(y_true) == 0:\n",
    "            print(f\"\\n❌ {question}: [No data]\")\n",
    "            continue\n",
    "    \n",
    "        print(f\"\\n✅ Accuracy for: {question}\")\n",
    "        # Per-class accuracy\n",
    "        for i, class_name in enumerate(class_list):\n",
    "            global_idx = start + i\n",
    "            mask = y_true == global_idx\n",
    "            if mask.sum() == 0:\n",
    "                print(f\"  {class_name}: [No samples]\")\n",
    "                continue\n",
    "            acc = accuracy_score(y_true[mask], y_pred[mask])\n",
    "            print(f\"  {class_name}: {acc:.4f}\")\n",
    "        \n",
    "        # Overall accuracy for the question\n",
    "        overall_acc = accuracy_score(y_true, y_pred)\n",
    "        print(f\"🎯 Overall accuracy: {overall_acc:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "def train_save(X,Y):\n",
    "    \n",
    "    random.seed(1)\n",
    "    np.random.seed(1)\n",
    "    predicted=[]\n",
    "    tested=[]\n",
    "    acc_cv=[]\n",
    "    kappa_cv=[]\n",
    "    ind_cv=[]\n",
    "    \n",
    "        \n",
    "    train =train_clean(X,Y)\n",
    "    # Diferenciamos el fit cuando el resultado es categorical o no.\n",
    "    print(len(train))\n",
    "    \n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=64 # Cambia según tus clases\n",
    "    )\n",
    "    for param in model.base_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    train_data = Dataset.from_pandas(train)\n",
    "    \n",
    "    train_data = train_data.map(tokenize_function, batched=True)\n",
    "    train_data = train_data.rename_column(\"label\", \"labels\")\n",
    "    train_data = train_data.remove_columns([\"text\"])\n",
    "    train_data.set_format(\"torch\")\n",
    "    \n",
    "    print(train_data)\n",
    "    \n",
    "    if 'token_type_ids' in train_data:\n",
    "        train_data.set_format(type=\"torch\", columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"labels\"])\n",
    "        \n",
    "   \n",
    "    trainer = Trainer(\n",
    "    model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_data,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    for param in model.base_model.parameters():\n",
    "        param.requires_grad = True\n",
    "    trainer = Trainer(\n",
    "    model=model,\n",
    "        args=training_args_all,\n",
    "        train_dataset=train_data,\n",
    "    )\n",
    "    trainer.train()\n",
    "    trainer.save_model(f\"results/{model_name}_model_final_classification\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98501ee8-8d03-4f13-9cb3-ca6b6ec82555",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs,targets = flatten_and_filter_dataset(ground_truth,report_data)   \n",
    "\n",
    "dataset_final=pd.DataFrame.from_dict(inputs,orient='index')\n",
    "targets=pd.DataFrame.from_dict(targets,orient='index')\n",
    "dataset_final.columns=[\"text\"]\n",
    "targets.columns=[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b5b0c57-309c-481e-b5b6-a69f930a0abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs,targets = flatten_and_filter_dataset(ground_truth,report_data)   \n",
    "model_name=\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\"\n",
    "dataset_final=pd.DataFrame.from_dict(inputs,orient='index')\n",
    "targets=pd.DataFrame.from_dict(targets,orient='index')\n",
    "dataset_final.columns=[\"text\"]\n",
    "targets.columns=[\"label\"]\n",
    "training_args = TrainingArguments(\n",
    "    \n",
    "    num_train_epochs=5,             # Número de épocas\n",
    "    per_device_train_batch_size=16,  # Tamaño del batch\n",
    "    \n",
    "    learning_rate=0.01, \n",
    "    weight_decay=0.05,              # Decaimiento del peso\n",
    "    \n",
    ")\n",
    "\n",
    "training_args_all= TrainingArguments(\n",
    "    output_dir='./results',          # Carpeta para guardar el modelo\n",
    "    num_train_epochs=8,             # Número de épocas\n",
    "    per_device_train_batch_size=16,  # Tamaño del batch\n",
    "    \n",
    "    learning_rate=0.00005, \n",
    "    weight_decay=0.05,              # Decaimiento del peso\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76e4ea3d-3a0d-450b-aeca-c2aa84591e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                text\n",
      "440-748-565-20240513-154602_calcifications_benign  Question: does the following breast medical re...\n",
      "985-654-561-20211122-124654_lymph_suspicious       Question: does the following breast medical re...\n",
      "247-463-290-20211115-104332_tecnica                Question: what diagnostic technique was used i...\n",
      "295-535-636-20230808-175646.440_tipo               Question: is the following breast medical repo...\n",
      "420-655-077-20220627-121530.906_prosthesis         Question: does the patient have a prosthesis i...\n",
      "...                                                                                              ...\n",
      "887-991-783-20221121-120438_nodules_echo           Question: is there any nodule described in the...\n",
      "192-795-083-20220524-151803_tipo                   Question: is the following breast medical repo...\n",
      "236-259-310-20230522-091930_family                 Question: does the patient have any family his...\n",
      "039-107-431-20230717-112910_ductal_ectasia         Question: does the following breast medical re...\n",
      "227-053-436-20230714-113137_nodules_known          Question: is the first nodule described in the...\n",
      "\n",
      "[3027 rows x 1 columns]\n",
      "                                                   label\n",
      "440-748-565-20240513-154602_calcifications_benign     25\n",
      "985-654-561-20211122-124654_lymph_suspicious          36\n",
      "247-463-290-20211115-104332_tecnica                    3\n",
      "295-535-636-20230808-175646.440_tipo                   2\n",
      "420-655-077-20220627-121530.906_prosthesis             9\n",
      "...                                                  ...\n",
      "887-991-783-20221121-120438_nodules_echo              42\n",
      "192-795-083-20220524-151803_tipo                       2\n",
      "236-259-310-20230522-091930_family                     7\n",
      "039-107-431-20230717-112910_ductal_ectasia            40\n",
      "227-053-436-20230714-113137_nodules_known             59\n",
      "\n",
      "[3027 rows x 1 columns]\n",
      "3027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map:   0%|          | 0/3027 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Truncation occurred!\n",
      "Original length: 533, Truncated to: 512\n",
      "Sample text: Question: what is the margin of the first nodule described in the ultrasound exam of the following breast medical report? Extra information: Margin can be 'circumscribed' and 'not circumscribed'. Insi ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 536, Truncated to: 512\n",
      "Sample text: Question: does the following breast medical report mention any suspicious axillary lymph nodes in the ultrasound exam? Extra information: if a lymph node is suspicious the report will recomend a biops ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 520, Truncated to: 512\n",
      "Sample text: Question: what is the breast density found in the mammography study of the following breast medical report? Extra information: breast density in mammography is classified into four categories: ACR A ( ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  66%|██████▌   | 2000/3027 [00:05<00:02, 344.03 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Truncation occurred!\n",
      "Original length: 514, Truncated to: 512\n",
      "Sample text: Question: is the following breast medical report a biopsy report or a nodal staging ultrasound report? Extra information: biopsy reports are Image-Guided Biopsy or Fine needle aspiration and is normal ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 540, Truncated to: 512\n",
      "Sample text: Question: what is the breast density found in the ultrasound study of the following breast medical report? Extra information: breast composition in ultrasound is classified into four categories: fibro ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 533, Truncated to: 512\n",
      "Sample text: Question: does the following breast medical report mention any benign or not suspicious axillary lymph nodes in the ultrasound exam? Extra information: if a lymph node is suspicious the report will re ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 520, Truncated to: 512\n",
      "Sample text: Question: does the patient have any family history in the following breast medical report? Extra information: family history of breast cancer is categorized based on the degree of relatives affected:  ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3027/3027 [00:08<00:00, 337.33 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 3027\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='950' max='950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [950/950 05:37, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.417400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1520' max='1520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1520/1520 27:37, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.388700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.098400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.017400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_save(dataset_final,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "daeab0a4-662e-4fa7-aec4-76b676cb4f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                text\n",
      "440-748-565-20240513-154602_calcifications_benign  Question: does the following breast medical re...\n",
      "985-654-561-20211122-124654_lymph_suspicious       Question: does the following breast medical re...\n",
      "247-463-290-20211115-104332_tecnica                Question: what diagnostic technique was used i...\n",
      "295-535-636-20230808-175646.440_tipo               Question: is the following breast medical repo...\n",
      "420-655-077-20220627-121530.906_prosthesis         Question: does the patient have a prosthesis i...\n",
      "...                                                                                              ...\n",
      "887-991-783-20221121-120438_nodules_echo           Question: is there any nodule described in the...\n",
      "192-795-083-20220524-151803_tipo                   Question: is the following breast medical repo...\n",
      "236-259-310-20230522-091930_family                 Question: does the patient have any family his...\n",
      "039-107-431-20230717-112910_ductal_ectasia         Question: does the following breast medical re...\n",
      "227-053-436-20230714-113137_nodules_known          Question: is the first nodule described in the...\n",
      "\n",
      "[3027 rows x 1 columns]\n",
      "                                                   label\n",
      "440-748-565-20240513-154602_calcifications_benign     25\n",
      "985-654-561-20211122-124654_lymph_suspicious          36\n",
      "247-463-290-20211115-104332_tecnica                    3\n",
      "295-535-636-20230808-175646.440_tipo                   2\n",
      "420-655-077-20220627-121530.906_prosthesis             9\n",
      "...                                                  ...\n",
      "887-991-783-20221121-120438_nodules_echo              42\n",
      "192-795-083-20220524-151803_tipo                       2\n",
      "236-259-310-20230522-091930_family                     7\n",
      "039-107-431-20230717-112910_ductal_ectasia            40\n",
      "227-053-436-20230714-113137_nodules_known             59\n",
      "\n",
      "[3027 rows x 1 columns]\n",
      "3027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map:   0%|          | 0/3027 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Truncation occurred!\n",
      "Original length: 595, Truncated to: 512\n",
      "Sample text: Question: what is the shape of the first nodule described in the ultrasound exam of the following breast medical report? Extra information: Shapes can be 'oval', 'round', 'lobulated' and 'irregular'.  ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 649, Truncated to: 512\n",
      "Sample text: Question: what is the margin of the first nodule described in the ultrasound exam of the following breast medical report? Extra information: Margin can be 'circumscribed' and 'not circumscribed'. Insi ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 576, Truncated to: 512\n",
      "Sample text: Question: is the first known nodule described in the ultrasound exam stable in the following breast medical report? Extra information: If the nodule is known from before the examination, it will be an ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 535, Truncated to: 512\n",
      "Sample text: Question: what is the breast density found in the ultrasound study of the following breast medical report? Extra information: breast composition in ultrasound is classified into four categories: fibro ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 530, Truncated to: 512\n",
      "Sample text: Question: what diagnostic technique was used in the following breast medical report? Extra information: biopsy reports, simple cysts and analysis of lymph or axillary nodes are only seen on ultrasound ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 541, Truncated to: 512\n",
      "Sample text: Question: does the following breast medical report mention any suspicious axillary lymph nodes in the ultrasound exam? Extra information: if a lymph node is suspicious the report will recomend a biops ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 543, Truncated to: 512\n",
      "Sample text: Question: is the following breast medical report a biopsy report or a nodal staging ultrasound report? Extra information: biopsy reports are Image-Guided Biopsy or Fine needle aspiration and is normal ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 535, Truncated to: 512\n",
      "Sample text: Question: does the following breast medical report mention any benign or not suspicious axillary lymph nodes in the ultrasound exam? Extra information: if a lymph node is suspicious the report will re ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 565, Truncated to: 512\n",
      "Sample text: Question: does the patient have a prosthesis in the following breast medical report? Extra information: it is normally clearly indicated at the beginning of the report. Sometimes it is written as impl ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 536, Truncated to: 512\n",
      "Sample text: Question: does the following breast medical report mention any suspicious axillary lymph nodes in the ultrasound exam? Extra information: if a lymph node is suspicious the report will recomend a biops ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 655, Truncated to: 512\n",
      "Sample text: Question: does the following breast medical report mention any suspicious axillary lymph nodes in the ultrasound exam? Extra information: if a lymph node is suspicious the report will recomend a biops ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 633, Truncated to: 512\n",
      "Sample text: Question: what is the breast density found in the mammography study of the following breast medical report? Extra information: breast density in mammography is classified into four categories: ACR A ( ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 530, Truncated to: 512\n",
      "Sample text: Question: what is the margin of the first nodule described in the ultrasound exam of the following breast medical report? Extra information: Margin can be 'circumscribed' and 'not circumscribed'. Insi ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 565, Truncated to: 512\n",
      "Sample text: Question: does the following breast medical report mention the appearence of benign calcifications in the mammography exam? Extra information: Consider only benign calcifications in the mammography. C ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 528, Truncated to: 512\n",
      "Sample text: Question: is the following breast medical report a biopsy report or a nodal staging ultrasound report? Extra information: biopsy reports are Image-Guided Biopsy or Fine needle aspiration and is normal ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 599, Truncated to: 512\n",
      "Sample text: Question: does the following breast medical report mention any simple cysts or microcysts in the ultrasound exam? Extra information: The words symple cysts or microcysts will appear only in the ultras ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  33%|███▎      | 1000/3027 [00:02<00:05, 345.57 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Truncation occurred!\n",
      "Original length: 572, Truncated to: 512\n",
      "Sample text: Question: is the first nodule described in the ultrasound exam of the following breast medical report previously known? Extra information: If the nodule is known from before the report, it will say if ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 519, Truncated to: 512\n",
      "Sample text: Question: what is the breast density found in the mammography study of the following breast medical report? Extra information: breast density in mammography is classified into four categories: ACR A ( ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 574, Truncated to: 512\n",
      "Sample text: Question: what diagnostic technique was used in the following breast medical report? Extra information: biopsy reports, simple cysts and analysis of lymph or axillary nodes are only seen on ultrasound ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 535, Truncated to: 512\n",
      "Sample text: Question: what is the margin of the first nodule described in the ultrasound exam of the following breast medical report? Extra information: Margin can be 'circumscribed' and 'not circumscribed'. Insi ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 568, Truncated to: 512\n",
      "Sample text: Question: what is the final BI-RADS classification given to the patient in the following breast medical report? Extra information: the final BI-RADS of the patient is given in the conclusions of the r ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  66%|██████▌   | 2000/3027 [00:06<00:03, 328.82 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Truncation occurred!\n",
      "Original length: 556, Truncated to: 512\n",
      "Sample text: Question: does the following breast medical report mention any lymph nodes in the mammography exam? Extra information: Consider only lymph nodes that appear in the mammography. Context: REPORT: Result ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 572, Truncated to: 512\n",
      "Sample text: Question: is the following breast medical report a biopsy report or a nodal staging ultrasound report? Extra information: biopsy reports are Image-Guided Biopsy or Fine needle aspiration and is normal ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 626, Truncated to: 512\n",
      "Sample text: Question: what diagnostic technique was used in the following breast medical report? Extra information: biopsy reports, simple cysts and analysis of lymph or axillary nodes are only seen on ultrasound ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 514, Truncated to: 512\n",
      "Sample text: Question: what is the breast density found in the mammography study of the following breast medical report? Extra information: breast density in mammography is classified into four categories: ACR A ( ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 624, Truncated to: 512\n",
      "Sample text: Question: is the following breast medical report a biopsy report or a nodal staging ultrasound report? Extra information: biopsy reports are Image-Guided Biopsy or Fine needle aspiration and is normal ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 545, Truncated to: 512\n",
      "Sample text: Question: what diagnostic technique was used in the following breast medical report? Extra information: biopsy reports, simple cysts and analysis of lymph or axillary nodes are only seen on ultrasound ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 560, Truncated to: 512\n",
      "Sample text: Question: is there any nodule described in the ultrasound exam of the following breast medical report? Extra information: The localization, echogenicity and size of the nodules are normally said. Cont ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 587, Truncated to: 512\n",
      "Sample text: Question: what diagnostic technique was used in the following breast medical report? Extra information: biopsy reports, simple cysts and analysis of lymph or axillary nodes are only seen on ultrasound ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 654, Truncated to: 512\n",
      "Sample text: Question: what is the breast density found in the ultrasound study of the following breast medical report? Extra information: breast composition in ultrasound is classified into four categories: fibro ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 540, Truncated to: 512\n",
      "Sample text: Question: what is the breast density found in the ultrasound study of the following breast medical report? Extra information: breast composition in ultrasound is classified into four categories: fibro ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 654, Truncated to: 512\n",
      "Sample text: Question: does the following breast medical report mention any benign or not suspicious axillary lymph nodes in the ultrasound exam? Extra information: if a lymph node is suspicious the report will re ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 540, Truncated to: 512\n",
      "Sample text: Question: does the following breast medical report mention any benign or not suspicious axillary lymph nodes in the ultrasound exam? Extra information: if a lymph node is suspicious the report will re ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 585, Truncated to: 512\n",
      "Sample text: Question: is the following breast medical report a biopsy report or a nodal staging ultrasound report? Extra information: biopsy reports are Image-Guided Biopsy or Fine needle aspiration and is normal ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 586, Truncated to: 512\n",
      "Sample text: Question: what is the echogenicity of the first nodule described in the ultrasound exam of the following breast medical report? Extra information: Echogenicity can be 'anechoic', 'hypoechoic', 'hetero ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 611, Truncated to: 512\n",
      "Sample text: Question: does the patient have any family history in the following breast medical report? Extra information: family history of breast cancer is categorized based on the degree of relatives affected:  ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 562, Truncated to: 512\n",
      "Sample text: Question: does the following breast medical report mention any ductal ectasia in the ultrasound exam? Extra information: The word ductal ectasia will appear only in the ultrasound exam. Context: REPOR ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3027/3027 [00:09<00:00, 321.43 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 3027\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='950' max='950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [950/950 05:43, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.446400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.538100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.376900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.950200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.784600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>4.240700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>4.345300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>4.187400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>4.375600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.234500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.815600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.757400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>4.107400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.835900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>4.101600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>4.238300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3.969100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.933800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3.542200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.501200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3.394300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>3.498100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>3.732400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>3.422900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>4.091600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>3.706400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>3.372700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>3.532500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>3.436700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.550500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>3.328800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>3.391900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>3.185900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>3.340500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.273900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>3.315400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>3.190200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>3.322800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>2.755100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>3.216400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>2.961200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>3.353000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>3.005500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.912600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>3.168600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>3.024700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>2.817000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>2.646100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.880200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>2.972400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>2.645400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>2.719800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>2.696200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>3.016500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>2.760300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>2.554200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>2.691000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>2.594300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.736400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>2.781600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>2.411600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>2.551800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>2.382400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.577000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>2.639700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>2.642800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>2.749600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>2.653500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.673700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>2.616900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>2.626600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>2.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>2.463300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.129100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>2.451800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>2.283300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>2.439300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>2.388300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.373600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>2.199900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>2.142200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>2.422200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>2.262300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.448200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>2.224900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>2.305300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>2.097100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>2.156300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.240300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>2.148500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>2.224600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>2.155300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>2.364100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.122800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='950' max='950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [950/950 17:36, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.404100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs,targets = flatten_and_filter_dataset(ground_truth,report_data)   \n",
    "model_name=\"dmis-lab/biobert-base-cased-v1.1\"\n",
    "dataset_final=pd.DataFrame.from_dict(inputs,orient='index')\n",
    "targets=pd.DataFrame.from_dict(targets,orient='index')\n",
    "dataset_final.columns=[\"text\"]\n",
    "targets.columns=[\"label\"]\n",
    "training_args = TrainingArguments(\n",
    "    \n",
    "    num_train_epochs=5,             # Número de épocas\n",
    "    per_device_train_batch_size=16,  # Tamaño del batch\n",
    "    \n",
    "    learning_rate=0.01, \n",
    "    weight_decay=0.05,              # Decaimiento del peso\n",
    "    logging_dir='./logs',           # Carpeta para los logs\n",
    "    logging_steps=10,\n",
    "    \n",
    ")\n",
    "\n",
    "training_args_all= TrainingArguments(\n",
    "   \n",
    "    num_train_epochs=5,             # Número de épocas\n",
    "    per_device_train_batch_size=16,  # Tamaño del batch\n",
    "   \n",
    "    learning_rate=0.00005, \n",
    "    weight_decay=0.05,              # Decaimiento del peso\n",
    "    \n",
    ")\n",
    "train_save(dataset_final,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57f21ed3-4176-4fd7-92e7-ca34ced44814",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                text\n",
      "440-748-565-20240513-154602_calcifications_benign  Question: does the following breast medical re...\n",
      "985-654-561-20211122-124654_lymph_suspicious       Question: does the following breast medical re...\n",
      "247-463-290-20211115-104332_tecnica                Question: what diagnostic technique was used i...\n",
      "295-535-636-20230808-175646.440_tipo               Question: is the following breast medical repo...\n",
      "420-655-077-20220627-121530.906_prosthesis         Question: does the patient have a prosthesis i...\n",
      "...                                                                                              ...\n",
      "887-991-783-20221121-120438_nodules_echo           Question: is there any nodule described in the...\n",
      "192-795-083-20220524-151803_tipo                   Question: is the following breast medical repo...\n",
      "236-259-310-20230522-091930_family                 Question: does the patient have any family his...\n",
      "039-107-431-20230717-112910_ductal_ectasia         Question: does the following breast medical re...\n",
      "227-053-436-20230714-113137_nodules_known          Question: is the first nodule described in the...\n",
      "\n",
      "[3027 rows x 1 columns]\n",
      "                                                   label\n",
      "440-748-565-20240513-154602_calcifications_benign     25\n",
      "985-654-561-20211122-124654_lymph_suspicious          36\n",
      "247-463-290-20211115-104332_tecnica                    3\n",
      "295-535-636-20230808-175646.440_tipo                   2\n",
      "420-655-077-20220627-121530.906_prosthesis             9\n",
      "...                                                  ...\n",
      "887-991-783-20221121-120438_nodules_echo              42\n",
      "192-795-083-20220524-151803_tipo                       2\n",
      "236-259-310-20230522-091930_family                     7\n",
      "039-107-431-20230717-112910_ductal_ectasia            40\n",
      "227-053-436-20230714-113137_nodules_known             59\n",
      "\n",
      "[3027 rows x 1 columns]\n",
      "3027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map:   0%|          | 0/3027 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Truncation occurred!\n",
      "Original length: 565, Truncated to: 512\n",
      "Sample text: Question: what is the shape of the first nodule described in the ultrasound exam of the following breast medical report? Extra information: Shapes can be 'oval', 'round', 'lobulated' and 'irregular'.  ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 625, Truncated to: 512\n",
      "Sample text: Question: what is the margin of the first nodule described in the ultrasound exam of the following breast medical report? Extra information: Margin can be 'circumscribed' and 'not circumscribed'. Insi ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 546, Truncated to: 512\n",
      "Sample text: Question: is the first known nodule described in the ultrasound exam stable in the following breast medical report? Extra information: If the nodule is known from before the examination, it will be an ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 513, Truncated to: 512\n",
      "Sample text: Question: what is the breast density found in the ultrasound study of the following breast medical report? Extra information: breast composition in ultrasound is classified into four categories: fibro ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 520, Truncated to: 512\n",
      "Sample text: Question: does the following breast medical report mention any suspicious axillary lymph nodes in the ultrasound exam? Extra information: if a lymph node is suspicious the report will recomend a biops ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 514, Truncated to: 512\n",
      "Sample text: Question: is the following breast medical report a biopsy report or a nodal staging ultrasound report? Extra information: biopsy reports are Image-Guided Biopsy or Fine needle aspiration and is normal ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 513, Truncated to: 512\n",
      "Sample text: Question: does the following breast medical report mention any benign or not suspicious axillary lymph nodes in the ultrasound exam? Extra information: if a lymph node is suspicious the report will re ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 536, Truncated to: 512\n",
      "Sample text: Question: does the patient have a prosthesis in the following breast medical report? Extra information: it is normally clearly indicated at the beginning of the report. Sometimes it is written as impl ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 519, Truncated to: 512\n",
      "Sample text: Question: does the following breast medical report mention any suspicious axillary lymph nodes in the ultrasound exam? Extra information: if a lymph node is suspicious the report will recomend a biops ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 626, Truncated to: 512\n",
      "Sample text: Question: does the following breast medical report mention any suspicious axillary lymph nodes in the ultrasound exam? Extra information: if a lymph node is suspicious the report will recomend a biops ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 601, Truncated to: 512\n",
      "Sample text: Question: what is the breast density found in the mammography study of the following breast medical report? Extra information: breast density in mammography is classified into four categories: ACR A ( ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 518, Truncated to: 512\n",
      "Sample text: Question: what is the margin of the first nodule described in the ultrasound exam of the following breast medical report? Extra information: Margin can be 'circumscribed' and 'not circumscribed'. Insi ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 532, Truncated to: 512\n",
      "Sample text: Question: does the following breast medical report mention the appearence of benign calcifications in the mammography exam? Extra information: Consider only benign calcifications in the mammography. C ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 563, Truncated to: 512\n",
      "Sample text: Question: does the following breast medical report mention any simple cysts or microcysts in the ultrasound exam? Extra information: The words symple cysts or microcysts will appear only in the ultras ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  33%|███▎      | 1000/3027 [00:02<00:04, 445.20 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Truncation occurred!\n",
      "Original length: 542, Truncated to: 512\n",
      "Sample text: Question: is the first nodule described in the ultrasound exam of the following breast medical report previously known? Extra information: If the nodule is known from before the report, it will say if ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 542, Truncated to: 512\n",
      "Sample text: Question: what diagnostic technique was used in the following breast medical report? Extra information: biopsy reports, simple cysts and analysis of lymph or axillary nodes are only seen on ultrasound ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 519, Truncated to: 512\n",
      "Sample text: Question: what is the margin of the first nodule described in the ultrasound exam of the following breast medical report? Extra information: Margin can be 'circumscribed' and 'not circumscribed'. Insi ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 539, Truncated to: 512\n",
      "Sample text: Question: what is the final BI-RADS classification given to the patient in the following breast medical report? Extra information: the final BI-RADS of the patient is given in the conclusions of the r ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  66%|██████▌   | 2000/3027 [00:04<00:02, 399.46 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Truncation occurred!\n",
      "Original length: 529, Truncated to: 512\n",
      "Sample text: Question: does the following breast medical report mention any lymph nodes in the mammography exam? Extra information: Consider only lymph nodes that appear in the mammography. Context: REPORT: Result ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 538, Truncated to: 512\n",
      "Sample text: Question: is the following breast medical report a biopsy report or a nodal staging ultrasound report? Extra information: biopsy reports are Image-Guided Biopsy or Fine needle aspiration and is normal ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 594, Truncated to: 512\n",
      "Sample text: Question: what diagnostic technique was used in the following breast medical report? Extra information: biopsy reports, simple cysts and analysis of lymph or axillary nodes are only seen on ultrasound ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 590, Truncated to: 512\n",
      "Sample text: Question: is the following breast medical report a biopsy report or a nodal staging ultrasound report? Extra information: biopsy reports are Image-Guided Biopsy or Fine needle aspiration and is normal ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 518, Truncated to: 512\n",
      "Sample text: Question: what diagnostic technique was used in the following breast medical report? Extra information: biopsy reports, simple cysts and analysis of lymph or axillary nodes are only seen on ultrasound ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 530, Truncated to: 512\n",
      "Sample text: Question: is there any nodule described in the ultrasound exam of the following breast medical report? Extra information: The localization, echogenicity and size of the nodules are normally said. Cont ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 550, Truncated to: 512\n",
      "Sample text: Question: what diagnostic technique was used in the following breast medical report? Extra information: biopsy reports, simple cysts and analysis of lymph or axillary nodes are only seen on ultrasound ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 620, Truncated to: 512\n",
      "Sample text: Question: what is the breast density found in the ultrasound study of the following breast medical report? Extra information: breast composition in ultrasound is classified into four categories: fibro ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 514, Truncated to: 512\n",
      "Sample text: Question: what is the breast density found in the ultrasound study of the following breast medical report? Extra information: breast composition in ultrasound is classified into four categories: fibro ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 620, Truncated to: 512\n",
      "Sample text: Question: does the following breast medical report mention any benign or not suspicious axillary lymph nodes in the ultrasound exam? Extra information: if a lymph node is suspicious the report will re ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 514, Truncated to: 512\n",
      "Sample text: Question: does the following breast medical report mention any benign or not suspicious axillary lymph nodes in the ultrasound exam? Extra information: if a lymph node is suspicious the report will re ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 546, Truncated to: 512\n",
      "Sample text: Question: is the following breast medical report a biopsy report or a nodal staging ultrasound report? Extra information: biopsy reports are Image-Guided Biopsy or Fine needle aspiration and is normal ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 553, Truncated to: 512\n",
      "Sample text: Question: what is the echogenicity of the first nodule described in the ultrasound exam of the following breast medical report? Extra information: Echogenicity can be 'anechoic', 'hypoechoic', 'hetero ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 580, Truncated to: 512\n",
      "Sample text: Question: does the patient have any family history in the following breast medical report? Extra information: family history of breast cancer is categorized based on the degree of relatives affected:  ...\n",
      "\n",
      "⚠️ Truncation occurred!\n",
      "Original length: 529, Truncated to: 512\n",
      "Sample text: Question: does the following breast medical report mention any ductal ectasia in the ultrasound exam? Extra information: The word ductal ectasia will appear only in the ultrasound exam. Context: REPOR ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3027/3027 [00:08<00:00, 347.06 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 3027\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='950' max='950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [950/950 03:21, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.895200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1520' max='1520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1520/1520 25:20, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.627900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.224200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.065700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs,targets = flatten_and_filter_dataset(ground_truth,report_data)   \n",
    "model_name=\"bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12\"\n",
    "dataset_final=pd.DataFrame.from_dict(inputs,orient='index')\n",
    "targets=pd.DataFrame.from_dict(targets,orient='index')\n",
    "dataset_final.columns=[\"text\"]\n",
    "targets.columns=[\"label\"]\n",
    "training_args = TrainingArguments(\n",
    "    \n",
    "    num_train_epochs=5,             # Número de épocas\n",
    "    per_device_train_batch_size=16,  # Tamaño del batch\n",
    "    \n",
    "    learning_rate=0.01, \n",
    "    weight_decay=0.05,              # Decaimiento del peso\n",
    "    \n",
    ")\n",
    "\n",
    "training_args_all= TrainingArguments(\n",
    "    \n",
    "    num_train_epochs=8,             # Número de épocas\n",
    "    per_device_train_batch_size=16,  # Tamaño del batch\n",
    "    \n",
    "    learning_rate=0.00005, \n",
    "    weight_decay=0.05,              # Decaimiento del peso\n",
    "    \n",
    ")\n",
    "train_save(dataset_final,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24bfb360-d624-4cc6-8499-f87f4f25bf54",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43ma\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
