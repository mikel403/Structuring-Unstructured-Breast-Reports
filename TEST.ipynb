{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dad264-f3da-4f4e-9c8a-b5036bdb76d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gpu_device = 2    # número identificador del device puede ser: 0, 1, 2, o 3\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpu_device)\n",
    "from numba import cuda\n",
    "cuda.select_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ad9de0-364b-4442-863e-e966f6ca9405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from datasets import Dataset,concatenate_datasets,load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08e19e6-b962-4f71-a8d1-a7b67d2a9bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "ground_truth=pd.read_excel(\"data/data_test.xlsx\",index_col=\"Report\")\n",
    "ground_truth=ground_truth[ground_truth[\"Eliminar\"]!=\"Yes\"]\n",
    "\n",
    "with open(\"data/report_data_test_ingles_v2.pkl\", 'rb') as file:  # 'rb' mode is for reading binary files\n",
    "    report_data = pickle.load(file)\n",
    "\n",
    "def fix_brackets_spaces(texto):\n",
    "    ''' \n",
    "        Introduce espacios por delante y por detrás de los paréntesis.\n",
    "        Esta medida mejora el tokenizado de Spacy\n",
    "    '''\n",
    "    \n",
    "    texto = re.sub(r'([(\\[¿!])', r' \\1', texto)\n",
    "    texto = re.sub(r'([)\\]?¡])', r'\\1 ', texto)\n",
    "                \n",
    "    return texto\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text= fix_brackets_spaces(text)\n",
    "    return text\n",
    "\n",
    "def visualize_errors(valid_dataset,valid_targets,validation_predictions,keys):\n",
    "    # Crear un DataFrame con los textos originales, las etiquetas reales y las predicciones\n",
    "    results_df = pd.DataFrame({\n",
    "        'key':list(keys),\n",
    "        'Text': list(valid_dataset),  # Usamos los textos originales\n",
    "        'True Label': list(valid_targets),\n",
    "        'Predicted Label': list(validation_predictions)\n",
    "    })\n",
    "    \n",
    "    # Filtrar los ejemplos en los que el modelo falló\n",
    "    errors_df = results_df[results_df['True Label'] != results_df['Predicted Label']]\n",
    "    \n",
    "    for ind,row in errors_df.iterrows():\n",
    "        print(row[\"key\"])\n",
    "        print(\"EJEMPLO\")\n",
    "        print(row[\"Text\"])\n",
    "        print(\"PREDICTED\")\n",
    "        print(row[\"Predicted Label\"])\n",
    "        print(\"TRUE\")\n",
    "        print(row[\"True Label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b5cd37-8970-45a9-a0e2-9144a644430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b817842-5b35-4bbc-a9e9-b066c320f9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for question in questions:\n",
    "    os.mkdir(f\"test_results/results_dic_{question}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080260b4-4130-490d-aea2-9b8da6ab4fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions=[\"age\",\"tipo\",\"tecnica\",\"family\",\"history\",\"symtomatic\",\n",
    "           \"prosthesis\",\"birads\",\"density_mammo\",\"calcifications_benign\",\"density_echo\",\"ganglio_mamo\",\"lymph_benign\",\"lymph_suspicious\",\"parenchymal_distortion\",\"simple_cyst\",\"ductal_ectasia\",\n",
    "          \"nodules_echo_num\",\"nodules_echo_description\",\"nodules_echo_shape\",\"nodules_echo_margin\",\"nodules_echo_echogenicity\",\"nodules_echo_location\",\"nodules_echo_size\",\"nodules_echo_known\",\"nodules_echo_stable\"]\n",
    "\n",
    "\n",
    "\n",
    "TIPO=[\"biopsy report\", \"nodal staging ultrasound report\", \"normal control or revision report\"]\n",
    "TECNICA=[\"only ultrasound study\", \"only mammography study\", \"mammography and ultrasound\"]\n",
    "FAMILY=[\"no family history\", \"first degree\", \"second degree\",\"third degree\"]\n",
    "PROSTHESIS=[\"no prosthesis\",\"yes prosthesis\"]\n",
    "BIRADS=[\"BI-RADS 0\",\"BI-RADS 1\",\"BI-RADS 2\",\"BI-RADS 3\",\"BI-RADS 4A\",\"BI-RADS 4B\",\"BI-RADS 4C\",\"BI-RADS 5\",\"BI-RADS 6\"]\n",
    "DENSITY_MAMMO=[\"ACR A\",\"ACR B\",\"ACR C\",\"ACR D\",\"unknown density mammo\"]\n",
    "CALCIFICATIONS_BENIGN=[\"no calcifications\",\"yes calcifications\"]\n",
    "GANGLIO_MAMO=[\"no ganglio\",\"yes ganglio\"]\n",
    "DENSITY_ECHO=[\"homogeneous fibroglandular\",\"heterogeneous fibroglandular\",\"fibroglandular and fat\",\"homogeneous fatty\",\"unknown density echo\"]\n",
    "LYMPH_BENIGN=[\"no lymph benign\",\"yes lymph benign\"]\n",
    "LYMPH_SUSPICIOUS=[\"no lymph suspicious\",\"yes lymph suspicious\"]\n",
    "SIMPLE_CYST=[\"no cyst\",\"yes cyst\"]\n",
    "DUCTAL_ECTASIA=[\"no ectasia\",\"yes ectasia\"]\n",
    "NODULES_ECHO=[\"no nodules\", \"yes nodules\"]\n",
    "NODULES_SHAPE=[\"oval\",\"round\",\"lobulated\",\"irregular\",\"unknown shape\"]\n",
    "NODULES_MARGIN=[\"circumscribed\",\"spiculated\",\"indistinct\",\"not circumscribed\",\"unknown margin\"]\n",
    "NODULES_ECHOGENICITY=[\"hypoechoic\", \"isoechoic\", \"heterogeneous\",\"complex cystic and solid\",\"unknown echogenicity\"]\n",
    "NODULES_KNOWN=[\"no known\", \"yes known\"]\n",
    "NODULES_STABLE=[\"grown stable\",\"shrunk stable\", \"yes stable\"]\n",
    "\n",
    "\n",
    "import gc\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "def flatten_and_filter_dataset(ground_truth,reports):\n",
    "    \"\"\"\n",
    "    Esta función toma un conjunto de datos en el formato original (con estructura jerárquica)\n",
    "    y devuelve un conjunto de datos plano, donde cada entrada tiene un solo `context`, `question` y `answer`.\n",
    "    \n",
    "    Argumentos:\n",
    "        dataset: Un conjunto de datos en formato original (puede ser train, validation, test).\n",
    "    \n",
    "    Retorno:\n",
    "        Un conjunto de datos de Hugging Face en formato plano, con solo ejemplos completos.\n",
    "    \"\"\"\n",
    "    # Lista para almacenar ejemplos en formato plano\n",
    "    flattened_examples = {}\n",
    "    examples_raw={}\n",
    "    targets={}\n",
    "    val_data={}\n",
    "    question_tipo={}\n",
    "    previous_message_answer_tipo={}\n",
    "    options_tipo={}\n",
    "    answers_tipo={}\n",
    "    j=0\n",
    "    \n",
    "    question_tipo[\"age\"]= \"does the patient's age appear in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"age\"]=\"search for numbers, but do not mistake it with the age of a familiar. If a number appears without any context between two dots it is surely the age.\"\n",
    "    options_tipo[\"age\"]=\"answer only the age of the patient.\"\n",
    "\n",
    "    question_tipo[\"tipo\"]= 'is the following breast medical report a biopsy report or a nodal staging ultrasound report?'\n",
    "    previous_message_answer_tipo[\"tipo\"]=\"biopsy reports are normally Image-Guided Biopsy and is normally said that they are referred to the hospital for biopsy. Nodal staging ultrasound reports can also be written as 'axilla ultrasound'. If it is any of these it will be written in the beginning of the report, normally in the used technique. These kind of reports are only ultrasound. In these reports no final BI-RADS is given.\"\n",
    "    options_tipo[\"tipo\"]=\"answer with one of the following options: 'biopsy report', 'nodal staging ultrasound report' or 'normal control or revision report'.\"\n",
    "\n",
    "    question_tipo[\"tecnica\"]= 'what diagnostic technique was used in the following breast medical report?'\n",
    "    previous_message_answer_tipo[\"tecnica\"]=\"biopsy reports, simple cysts and analysis of lymph or axillary nodes are only seen on ultrasound. On the other hand, if the ACR density is given or parenchymal distortions are analysed, the technique will be a mammogram. Tomosyntesis is a mammography type. The report may include an ultrasound examination, a mammography examination or both.\"\n",
    "    options_tipo[\"tecnica\"]=\"answer with one of the following options: 'only ultrasound study', 'only mammography study' or 'mammography and ultrasound'.\"\n",
    "\n",
    "    question_tipo[\"family\"]= \"does the patient have any family history in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"family\"]=\"family history of breast cancer is categorized based on the degree of relatives affected: First-degree relatives: Parents, siblings, or children. Second-degree relatives: Grandparents, aunts, uncles, nieces, nephews, or half-siblings. Third-degree relatives: Great-grandparents, great-aunts/uncles, or first cousins.\"\n",
    "    options_tipo[\"family\"]=\"answer with one of the following options: 'first degree', 'second degree', 'third degree' or 'no family history'.\"\n",
    "    \n",
    "    question_tipo[\"history\"]= \"does the patient have any non-familiar history in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"history\"]=\"check for the history at the beginning of the report. Normally it is a previous biopsy result, mastectomy or cancer. It normally starts with 'history of ...'.\"\n",
    "    options_tipo[\"history\"]=\"answer retrieving the information directly from the report or with 'no history was found'.\"\n",
    "    \n",
    "    question_tipo[\"symtomatic\"]= \"is the reason for the consultation that the patient is symptomatic in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"symtomatic\"]=\"the answer is at the beginning of the report, in the reason for consultation. It is normally a palpable lump, lumpectomy or nodule, sometimes painful.\"\n",
    "    options_tipo[\"symtomatic\"]=\"answer retrieving the information directly from the report or with 'non-symptomatic consultation'.\"\n",
    "    \n",
    "    question_tipo[\"prosthesis\"]= \"does the patient have a prosthesis in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"prosthesis\"]=\"it is normally clearly indicated at the beginning of the report. Sometimes it is written as implants instead of prosthesis.\"\n",
    "    options_tipo[\"prosthesis\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "    \n",
    "    question_tipo[\"birads\"]= \"what is the final BI-RADS classification given to the patient in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"birads\"]=\"the final BI-RADS of the patient is given in the conclusions of the report, normally at the end.\"\n",
    "    options_tipo[\"birads\"]=\"answer with one of the following options: 'BI-RADS 0', 'BI-RADS 1', 'BI-RADS 2', 'BI-RADS 3', 'BI-RADS 4A', 'BI-RADS 4B', 'BI-RADS 4C', 'BI-RADS 5' or 'unknown'.\"\n",
    "\n",
    "    question_tipo[\"density_mammo\"]= \"what is the breast density found in the mammography study of the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"density_mammo\"]=\"breast density in mammography is classified into four categories: ACR A (= Almost entirely fatty), ACR B (= Scattered areas of fibroglandular density), ACR C (= Heterogeneously dense), ACR D (= Extremely or very dense breasts). Sometimes it is written as 'density type x'. It can also be written with their real meaning (very dense breasts = C) and not with the A, B, C, D classification. Focus only on density.\"\n",
    "    options_tipo[\"density_mammo\"]=\"answer with one of the following options: 'ACR A', 'ACR B', 'ACR C', ACR D' or 'unknown'.\"\n",
    "   \n",
    "    question_tipo[\"density_echo\"]= \"what is the breast density found in the ultrasound study of the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"density_echo\"]=\"breast composition in ultrasound is classified into three categories: fibroglandular and fat (mixed distribution of fibroglandular and adipose tissue), heterogeneous fibroglandular (predominantly fibroglandular tissue with varying echogenicity and scattered fat areas), homogeneous fatty (uniform fatty tissue with consistent echogenicity and minimal fibroglandular content), and homogeneous fibroglandular (uniform fibroglandular tissue with consistent echogenicity and minimal fat content).\"\n",
    "    options_tipo[\"density_echo\"]=\"answer with one of the following options: 'fibroglandular and fat', 'heterogeneous fibroglandular', 'homogeneous fibroglandular', 'homogeneous fatty' or 'unknown'.\"\n",
    "\n",
    "    question_tipo[\"calcifications_benign\"]= \"does the following breast medical report mention the appearence of benign calcifications in the mammography exam?\"\n",
    "    previous_message_answer_tipo[\"calcifications_benign\"]=\"Consider only benign calcifications in the mammography.\"\n",
    "    options_tipo[\"calcifications_benign\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "    \n",
    "    question_tipo[\"ganglio_mamo\"]= \"does the following breast medical report mention any lymph nodes in the mammography exam?\"\n",
    "    previous_message_answer_tipo[\"ganglio_mamo\"]=\"Consider only lymph nodes that appear in the mammography.\"\n",
    "    options_tipo[\"ganglio_mamo\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "\n",
    "    question_tipo[\"parenchymal_distortion\"]= \"does the following breast medical report mention any parenchymal distortion or asymmetry in the mammography exam?\"\n",
    "    previous_message_answer_tipo[\"parenchymal_distortion\"]=\"If it has any it will appear in the results of the mammography exam using the words distortion, asymmetry or sometimes it can also be surgical changes.\"\n",
    "    options_tipo[\"parenchymal_distortion\"]=\"answer retrieving the information directly from the report or with 'no'\"\n",
    "    \n",
    "    question_tipo[\"lymph_suspicious\"]= \"does the following breast medical report mention any suspicious axillary lymph nodes in the ultrasound exam?\"\n",
    "    previous_message_answer_tipo[\"lymph_suspicious\"]=\"if a lymph node is suspicious the report will recomend a biopsy or Fine Needle Aspiration. A lymph node is considered suspicious when it has eccentric cortical thickening ≥ 3 mm, Short axis >10 mm, round shape, loss of fatty hilum, abnormal vascularity, or irregular margins—especially when associated with known malignancy or progressive enlargement. They can also be classified as UN3, UN4 or UN5. An exam may have both suspicious and benign lymph nodes, answer 'yes' in this case.\"\n",
    "    options_tipo[\"lymph_suspicious\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "\n",
    "    question_tipo[\"lymph_benign\"]= \"does the following breast medical report mention any benign or not suspicious axillary lymph nodes in the ultrasound exam?\"\n",
    "    previous_message_answer_tipo[\"lymph_benign\"]=\"if a lymph node is suspicious the report will recomend a biopsy or Fine Needle Aspiration. A lymph node is considered benign when it has uniform cortex < 3 mm, preserved fatty hilum, oval shape, no abnormal vascularity, no irregular margins and homogeneous internal echo pattern. Benign axillary nodes can be classified as UN1 or UN2. A reactive axillary node is not suspicious. An exam may have both suspicious and benign lymph nodes, answer 'yes' in this case.\"\n",
    "    options_tipo[\"lymph_benign\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "\n",
    "    question_tipo[\"simple_cyst\"]= \"does the following breast medical report mention any simple cysts or microcysts in the ultrasound exam?\"\n",
    "    previous_message_answer_tipo[\"simple_cyst\"]=\"The words symple cysts or microcysts will appear only in the ultrasound exam. Sometimes they can say that some of the cysts have echogenic content, but we still will consider them simple cysts and not nodules.\"\n",
    "    options_tipo[\"simple_cyst\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "\n",
    "    question_tipo[\"ductal_ectasia\"]= \"does the following breast medical report mention any ductal ectasia in the ultrasound exam?\"\n",
    "    previous_message_answer_tipo[\"ductal_ectasia\"]=\"The word ductal ectasia will appear only in the ultrasound exam.\"\n",
    "    options_tipo[\"ductal_ectasia\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "    \n",
    "    question_tipo[\"nodules_echo_num\"]=\"is there any nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"nodules_echo_num\"]=\"do not consider if a nodule is described in the mammography exam or if it is in the axilla. The localization, echogenicity and size of the nodules are normally said.\"\n",
    "    options_tipo[\"nodules_echo_num\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "\n",
    "    \n",
    "    dic_order = {\n",
    "        1: \"first\",\n",
    "        2: \"second\",\n",
    "        3: \"third\",\n",
    "        4: \"fourth\",\n",
    "        5: \"fifth\",\n",
    "        6: \"sixth\",\n",
    "        7: \"seventh\",\n",
    "        8: \"eighth\",\n",
    "        9: \"ninth\",\n",
    "        10: \"tenth\",\n",
    "        11: \"eleventh\",\n",
    "        12: \"twelfth\",\n",
    "        13: \"thirteenth\",\n",
    "        14: \"fourteenth\",\n",
    "        15: \"fifteenth\"\n",
    "    }\n",
    "    for i in range(1,2):\n",
    "        question_tipo[f\"nodules_echo_description_{i}\"]= f\"which is the {dic_order[i]} nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_description_{i}\"]=\"do not consider if a nodule is described in the mammography exam or if it is in the axilla. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "        options_tipo[f\"nodules_echo_description_{i}\"]=\"answer retrieving the information directly from the report.\"\n",
    "        \n",
    "        question_tipo[f\"nodules_echo_shape_{i}\"]= f\"what is the shape of the {dic_order[i]} nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_shape_{i}\"]=\"do not consider if a nodule is described in the mammography exam or if it is in the axilla. Shapes can be 'oval', 'round', 'lobulated' and 'irregular'. Sometimes irregular is also used for the margin, but in this case it is written as 'irregular margin' or 'irregular borders'. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "        options_tipo[f\"nodules_echo_shape_{i}\"]=\"answer with one of the following options: 'oval', 'round', 'lobulated', 'irregular' or 'unknown'.\"\n",
    "        \n",
    "        question_tipo[f\"nodules_echo_margin_{i}\"]= f\"what is the margin of the {dic_order[i]} nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_margin_{i}\"]=\"do not consider if a nodule is described in the mammography exam or if it is in the axilla. Margin can be 'circumscribed' and 'not circumscribed'. Inside the not circumscribed we have 'spiculated', 'angulated', 'microlobulated' or 'indistinc' ('not defined') margins. Sometimes irregular is also used for the margin, but in this case it is written as 'irregular margin' or 'irregular borders', in this case classify it as 'not circumscribed'. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "        options_tipo[f\"nodules_echo_margin_{i}\"]=\"answer with one of the following options: 'circumscribed', 'not circumscribed', 'indefined', 'spiculated', 'angulated', 'microlobulated' or 'unknown'.\"\n",
    "        \n",
    "        question_tipo[f\"nodules_echo_echogenicity_{i}\"]= f\"what is the echogenicity of the {dic_order[i]} nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_echogenicity_{i}\"]=\"do not consider if a nodule is described in the mammography exam or if it is in the axilla. Echogenicity can be 'anechoic', 'hypoechoic', 'heterogeneous' and 'complex cystic and solid'. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\" \n",
    "        options_tipo[f\"nodules_echo_echogenicity_{i}\"]=\"answer with one of the following options: 'hypoechoic', 'heterogeneous', 'anechoic', 'hyperecoic', 'isoechoic', 'complex cystic and solid' or 'unknown'.\"\n",
    "        \n",
    "        question_tipo[f\"nodules_echo_location_{i}\"]= f\"In which location is the {dic_order[i]} nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_location_{i}\"]=\"do not consider if a nodule is described in the mammography exam or if it is in the axilla. If the nodule is mentioned previously in the mammography, the location can be found also there. sometimes the breast location of the tumour may be written in a different part than the quadrant. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "        options_tipo[f\"nodules_echo_location_{i}\"]=\"answer retrieving the information directly from the report or with 'unknown'.\"\n",
    "        \n",
    "        question_tipo[f\"nodules_echo_size_{i}\"]= f\"what is the size of the {dic_order[i]} nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_size_{i}\"]=\"do not consider if a nodule is described in the mammography exam. The localization, echogenicity and size of the nodules are normally said. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "        options_tipo[f\"nodules_echo_size_{i}\"]=\"answer retrieving the information directly from the report (stop after 'mm') or with 'unknown'.\"\n",
    "        \n",
    "        question_tipo[f\"nodules_echo_known_{i}\"]= f\"is the {dic_order[i]} nodule described in the ultrasound exam of the following breast medical report previously known?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_known_{i}\"]=\"do not consider if a nodule is described in the mammography exam. If the nodule is known from before the report, it will say if it it is stable or if it has grown or shrink. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "        options_tipo[f\"nodules_echo_known_{i}\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "        \n",
    "        question_tipo[f\"nodules_echo_stable_{i}\"]= f\"is the {dic_order[i]} known nodule described in the ultrasound exam stable in the following breast medical report?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_stable_{i}\"]=\"do not consider if a nodule is described in the mammography exam. If the nodule is known from before the examination, it will be analysed to see if it is stable or if it got bigger or smaller. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "        options_tipo[f\"nodules_echo_stable_{i}\"]=\"answer with one of the following options: 'yes', 'grown' or 'shrunk.\"\n",
    "    for i, report in enumerate(reports[\"informes_ingles\"]):\n",
    "        informe=preprocess_text(report)\n",
    "        key=reports[\"keys\"][i]\n",
    "        \n",
    "        if key not in ground_truth.index:\n",
    "            continue\n",
    "        \n",
    "        row=ground_truth.loc[key]\n",
    "\n",
    "        #AGE\n",
    "        age=str(row[\"Age\"])\n",
    "        answer_tipo={}\n",
    "        # Verificar si el ejemplo tiene preguntas\n",
    "        if age.isdigit():\n",
    "            answer_tipo[\"age\"]=age+\".\"\n",
    "            \n",
    "        else:\n",
    "            answer_tipo[\"age\"]=\"no\"+\".\"\n",
    "        \n",
    "        #TIPO\n",
    "        if row[\"Biopsy_report\"].lower()==\"yes\":\n",
    "            answer_tipo[\"tipo\"]=\"biopsy report\"+\".\"\n",
    "            \n",
    "        elif row[\"Ganglio_report\"].lower()==\"yes\":\n",
    "            answer_tipo[\"tipo\"]=\"nodal staging ultrasound report\"+\".\"\n",
    "        else:\n",
    "            answer_tipo[\"tipo\"]=\"normal control or revision report\"+\".\"\n",
    "        \n",
    "        #TECHNIQUE\n",
    "        tecnica=row[\"Technique\"]\n",
    "        # Verificar si el ejemplo tiene preguntas\n",
    "        if tecnica==\"ultrasound\":\n",
    "            answer_tipo[\"tecnica\"]=\"only ultrasound study\"+\".\"            \n",
    "        elif tecnica==\"mammography\":\n",
    "            answer_tipo[\"tecnica\"]=\"only mammography study\"+\".\"\n",
    "        elif not pd.isna(tecnica):\n",
    "            answer_tipo[\"tecnica\"]=tecnica+\".\"\n",
    "        else:\n",
    "            print(key,report)\n",
    "        \n",
    "        # \n",
    "        # HISTORY\n",
    "        #No consideramos las biopsias o las ecografías de estadificación ganglionar.\n",
    "        if answer_tipo[\"tipo\"]==\"normal control or revision report\"+\".\":\n",
    "            history=row[\"Other_history\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(history,str) or history==\"No\":\n",
    "                answer_tipo[\"history\"]=\"no history was found\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"history\"]=history+\".\" \n",
    "    \n",
    "            # FAMILY\n",
    "            family=row[\"Family_history\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(family,str) or family==\"No\":\n",
    "                answer_tipo[\"family\"]=\"no family history\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"family\"]=family+\".\" \n",
    "    \n",
    "            # SYMTOMATIC\n",
    "            symtomatic=row[\"Syntomatic\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(symtomatic,str) or symtomatic==\"No\" or symtomatic==\"No estoy seguro\":\n",
    "                answer_tipo[\"symtomatic\"]=\"Non-symptomatic consultation\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"symtomatic\"]=symtomatic+\".\" \n",
    "    \n",
    "            # PROSTHESIS\n",
    "            prosthesis=row[\"Prosthesis\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(prosthesis,str) or prosthesis.lower()==\"no\":\n",
    "                answer_tipo[\"prosthesis\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"prosthesis\"]=\"yes\"+\".\"\n",
    "    \n",
    "            #BIRADS\n",
    "            birads=row[\"BI-RADS\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(birads,str):\n",
    "                answer_tipo[\"birads\"]=\"unknown\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"birads\"]=birads+\".\"\n",
    "    \n",
    "            #Density mammo\n",
    "            density_mammo=row[\"Density_mamo\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(density_mammo,str):\n",
    "                answer_tipo[\"density_mammo\"]=\"unknown\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"density_mammo\"]=density_mammo+\".\"\n",
    "\n",
    "            #Lymp nodes mammo\n",
    "            ganglio_mamo=row[\"Ganglio_mamo\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(ganglio_mamo,str):\n",
    "                answer_tipo[\"ganglio_mamo\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"ganglio_mamo\"]=ganglio_mamo.lower()+\".\"\n",
    "\n",
    "            #Calcifications benign\n",
    "            calcifications_benign=row[\"Calcifications_benign_mamo\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(calcifications_benign,str):\n",
    "                answer_tipo[\"calcifications_benign\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"calcifications_benign\"]=calcifications_benign.lower()+\".\"\n",
    "\n",
    "            #Parenchymal distortion\n",
    "            parenchymal_distortion=row[\"parenchymal_distortions_asymmetry\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(parenchymal_distortion,str):\n",
    "                answer_tipo[\"parenchymal_distortion\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"parenchymal_distortion\"]=parenchymal_distortion.lower()+\".\"\n",
    "    \n",
    "            #Density echo\n",
    "            density_echo=row[\"Density_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(density_echo,str):\n",
    "                answer_tipo[\"density_echo\"]=\"unknown\"+\".\"            \n",
    "            else:\n",
    "                \n",
    "                answer_tipo[\"density_echo\"]=density_echo+\".\"\n",
    "\n",
    "            #Benign lymph nodes\n",
    "            simple_cyst=row[\"simple_cyst_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(simple_cyst,str):\n",
    "                answer_tipo[\"simple_cyst\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"simple_cyst\"]=simple_cyst.lower()+\".\"\n",
    "            #Suspicious lymph nodes\n",
    "            lymph_suspicious=row[\"Ganglio_suspicious_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(lymph_suspicious,str):\n",
    "                answer_tipo[\"lymph_suspicious\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"lymph_suspicious\"]=lymph_suspicious.lower()+\".\"\n",
    "\n",
    "            #Benign lymph nodes\n",
    "            lymph_benign=row[\"Ganglio_benign_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(lymph_benign,str):\n",
    "                answer_tipo[\"lymph_benign\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"lymph_benign\"]=lymph_benign.lower()+\".\"\n",
    "\n",
    "            #Ductal ectasia\n",
    "            ductal_ectasia=row[\"Ductal_ectasia_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(ductal_ectasia,str):\n",
    "                answer_tipo[\"ductal_ectasia\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"ductal_ectasia\"]=ductal_ectasia.lower()+\".\"\n",
    "    \n",
    "            #Nodules echo\n",
    "            nodules_echo_num=row[\"Nodules_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(nodules_echo_num,str) and not isinstance(nodules_echo_num,int):\n",
    "                answer_tipo[\"nodules_echo_num\"]=\"no\"+\".\"    \n",
    "            elif isinstance(nodules_echo_num,str) and nodules_echo_num.lower()==\"no\":\n",
    "                answer_tipo[\"nodules_echo_num\"]=\"no\"+\".\"  \n",
    "            else:\n",
    "                answer_tipo[\"nodules_echo_num\"]=\"yes\"+\".\"\n",
    "    \n",
    "            #Si existen nódulos se hace las preguntas correspondientes\n",
    "            if answer_tipo[\"nodules_echo_num\"]!=\"no.\":\n",
    "                nodules_echo_description=row[\"Description_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                \n",
    "                answer_tipo[\"nodules_echo_description_1\"]=nodules_echo_description+\".\"\n",
    "                    \n",
    "                nodules_echo_shape=row[f\"Shape_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_echo_shape,str):\n",
    "                    answer_tipo[\"nodules_echo_shape_1\"]=\"unknown\"+\".\"\n",
    "                else:\n",
    "                    answer_tipo[\"nodules_echo_shape_1\"]=nodules_echo_shape.lower()+\".\"\n",
    "\n",
    "                nodules_echo_margin=row[\"Margin_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_echo_margin,str):\n",
    "                    answer_tipo[\"nodules_echo_margin_1\"]=\"unknown\"+\".\"\n",
    "                else:\n",
    "                    answer_tipo[\"nodules_echo_margin_1\"]=nodules_echo_margin.lower()+\".\"\n",
    "\n",
    "                nodules_echo_echogenicity=row[\"Echogenicity_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_echo_echogenicity,str):\n",
    "                    answer_tipo[\"nodules_echo_echogenicity_1\"]=\"unknown\"+\".\"\n",
    "                else:\n",
    "                    answer_tipo[\"nodules_echo_echogenicity_1\"]=nodules_echo_echogenicity.lower()+\".\"\n",
    "\n",
    "                nodules_echo_location=row[f\"Location_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_echo_location,str):\n",
    "                    answer_tipo[\"nodules_echo_location_1\"]=\"unknown\"+\".\"\n",
    "                else:\n",
    "                    answer_tipo[\"nodules_echo_location_1\"]=nodules_echo_location.lower()+\".\"\n",
    "\n",
    "                \n",
    "                #Nodules echo size\n",
    "                nodules_echo_size=row[\"size_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_echo_size,str):\n",
    "                    answer_tipo[\"nodules_echo_size_1\"]=\"unknown\"+\".\"            \n",
    "                else:\n",
    "                    answer_tipo[\"nodules_echo_size_1\"]=nodules_echo_size+\".\"\n",
    "        \n",
    "                #Nodules echo known\n",
    "                nodules_echo_known=row[\"new_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_echo_known,str):\n",
    "                    answer_tipo[\"nodules_echo_known_1\"]=\"unknown\"+\".\"\n",
    "                elif nodules_echo_known.lower()==\"no\":\n",
    "                    answer_tipo[\"nodules_echo_known_1\"]=\"yes\"+\".\"            \n",
    "                else:\n",
    "                    answer_tipo[\"nodules_echo_known_1\"]=\"no\"+\".\"\n",
    "    \n",
    "                if answer_tipo[\"nodules_echo_known_1\"]==\"yes.\":\n",
    "                    #Nodules echo stable\n",
    "                    nodules_echo_stable=row[\"Stable_eco_1\"]\n",
    "                    # Verificar si el ejemplo tiene preguntas\n",
    "                    if not isinstance(nodules_echo_stable,str):\n",
    "                        answer_tipo[\"nodules_echo_stable_1\"]=\"unknown\"+\".\"\n",
    "                    else:\n",
    "                        answer_tipo[\"nodules_echo_stable_1\"]=nodules_echo_stable.lower()+\".\"\n",
    "            \n",
    "        for tipo in answer_tipo:\n",
    "            #Si está el tipo en las respuestas que hemos recogido lo metemos a la base de datos.\n",
    "            key_tipo=key+\"_\"+tipo\n",
    "            if key_tipo in flattened_examples:\n",
    "                continue\n",
    "                key_tipo=key_tipo+\"_copy\"\n",
    "            examples_raw[key_tipo]=report\n",
    "            answer=str(answer_tipo[tipo])\n",
    "            \n",
    "    \n",
    "            inputs_tipo = \"Question: \" + question_tipo[tipo] +\" Additional information: \"+ previous_message_answer_tipo[tipo]+ \" Context: \" + informe + \"Options:\"+ options_tipo[tipo]+\" Answer: \"+ str(answer_tipo[tipo])\n",
    "            flattened_examples[key_tipo]=inputs_tipo\n",
    "            targets[key_tipo]=answer\n",
    "            \n",
    "            val_data[key_tipo]=\"Question: \" + question_tipo[tipo] +\" Additional information: \"+ previous_message_answer_tipo[tipo]+ \" Context: \" + informe+ \"Options:\"+ options_tipo[tipo] + \" Answer: \"\n",
    "\n",
    "            # inputs_tipo = \"Question: \" + question_tipo[tipo] +\" Context: \" + informe +\" Answer: \"+ str(answer_tipo[tipo])\n",
    "            # flattened_examples[key_tipo]=inputs_tipo\n",
    "            # targets[key_tipo]=answer\n",
    "            \n",
    "            # val_data[key_tipo]=\"Question: \" + question_tipo[tipo] + \" Context: \" + informe + \" Answer: \"\n",
    "    return flattened_examples,targets,val_data,examples_raw\n",
    "\n",
    "\n",
    "\n",
    "def tokenize_function_test(inputs):\n",
    "    print(inputs[\"text\"])\n",
    "    model_inputs = tokenizer(inputs[\"text\"], max_length=1024, padding_side='left',truncation=True,padding=\"max_length\",return_tensors=\"pt\")\n",
    "    return model_inputs\n",
    "\n",
    "def train_clean(X,Y):\n",
    "    random.seed(1)\n",
    "    # Agrupar ejemplos originales y sus copias\n",
    "    train = X\n",
    "    # Barajar los datos de entrenamiento para evitar sesgos\n",
    "    train = train.sample(frac=1, random_state=1)\n",
    "    train_y = Y.loc[train.index]\n",
    "    train[\"label\"]=train_y[\"label\"]\n",
    "    return train\n",
    "\n",
    "def generative_test(X, Y, model_name,low_beams=False):\n",
    "    \n",
    "    \n",
    "    test=X\n",
    "    test_y=Y.loc[test.index]\n",
    "    test[\"label\"]=test_y[\"label\"]\n",
    "    print(test)\n",
    "    del test[\"text\"]\n",
    "    \n",
    "    test.columns=[\"text\",\"label\"]\n",
    "    print(test)\n",
    "    ind=list(test.index)\n",
    "    \n",
    "    # model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "    model=AutoModelForCausalLM.from_pretrained(f\"results/{model_name}_second_stage_model_final\")\n",
    "\n",
    "    test_data=Dataset.from_pandas(test)\n",
    "    test_data_all = test_data.map(tokenize_function_test, batched=True)\n",
    "    test_data_all = test_data_all.remove_columns([\"text\",\"label\"])\n",
    "    test_data_all.set_format(\"torch\")\n",
    "\n",
    "\n",
    "    test_data={}\n",
    "    test_label={}\n",
    "    test_attention={}\n",
    "    \n",
    "    for tipo in questions:\n",
    "        #Primero creamos la lista y luego vemos que no esté vacía para hacer el stack\n",
    "        data=[output for j,output in enumerate(test_data_all[\"input_ids\"].to(\"cuda\")) if re.search(rf\"_{tipo}(_\\d+)?$\", ind[j])]\n",
    "        attention_masks=[output for j,output in enumerate(test_data_all[\"attention_mask\"].to(\"cuda\")) if re.search(rf\"_{tipo}(_\\d+)?$\", ind[j])]\n",
    "        \n",
    "        if data:\n",
    "            test_data[tipo]=torch.stack(data)\n",
    "            test_attention[tipo]=torch.stack(attention_masks)\n",
    "            del data\n",
    "            del attention_masks\n",
    "\n",
    "        labels=[output for j,output in enumerate(test[\"label\"])  if re.search(rf\"_{tipo}(_\\d+)?$\", ind[j])]\n",
    "        if labels:\n",
    "            test_label[tipo]=labels\n",
    "    \n",
    "    def generate_output(test_data, test_attention, tipo, tokens, beams):\n",
    "        outputs = []\n",
    "        for i,data in enumerate(test_data[tipo]):\n",
    "            output = model.generate(\n",
    "                data.unsqueeze(0),  # Shape: (1, sequence_length)\n",
    "                max_new_tokens=tokens,\n",
    "                attention_mask=test_attention[tipo][i].unsqueeze(0),  # Important for reliable results\n",
    "\n",
    "                num_beams=beams,\n",
    "                num_return_sequences=1,\n",
    "                early_stopping=True\n",
    "            ).squeeze(0).cpu()  # Shape: (generated_sequence_length,)\n",
    "            \n",
    "            outputs.append(output)  # Append 1D tensors (no extra dimensions)\n",
    "    \n",
    "        # Pad sequences to the longest one in the batch\n",
    "        outputs_padded = pad_sequence(outputs, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "        return outputs_padded  # Shape: (batch_size, max_sequence_length)\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "    model=model.to(\"cuda\")\n",
    "    outputs={}\n",
    "    \n",
    "    print(test_data.keys())\n",
    "    if \"age\" in test_data:\n",
    "        outputs[\"age\"]=generate_output(test_data, test_attention,\"age\",tokens=2,beams=1)\n",
    "        # outputs[\"age\"]=generate_output(test_data,\"age\",tokens=10,beams=3)\n",
    "        \n",
    "            \n",
    "    if \"tipo\" in test_data:\n",
    "        # outputs[\"tipo\"]=generate_output(test_data,\"tipo\",tokens=5,beams=1)\n",
    "        if low_beams:\n",
    "            outputs[\"tipo\"]=generate_output(test_data, test_attention,\"tipo\",tokens=6,beams=1)\n",
    "        else:\n",
    "            outputs[\"tipo\"]=generate_output(test_data, test_attention,\"tipo\",tokens=6,beams=5)\n",
    "        \n",
    "\n",
    "    if \"tecnica\" in test_data:\n",
    "        if low_beams:\n",
    "            outputs[\"tecnica\"]=generate_output(test_data, test_attention,\"tecnica\",tokens=4,beams=1)\n",
    "        else:\n",
    "            \n",
    "            outputs[\"tecnica\"]=generate_output(test_data, test_attention,\"tecnica\",tokens=4,beams=5)\n",
    "        # outputs[\"tecnica\"]=generate_output(test_data,\"tecnica\",tokens=15,beams=3)\n",
    "        \n",
    "    if \"history\" in test_data:\n",
    "        if low_beams:\n",
    "            outputs[\"history\"]=generate_output(test_data, test_attention,\"history\",tokens=29,beams=1)\n",
    "        else:\n",
    "            outputs[\"history\"]=generate_output(test_data, test_attention,\"history\",tokens=29,beams=5)\n",
    "        \n",
    "    if \"family\" in test_data:\n",
    "        if low_beams:\n",
    "            outputs[\"family\"]=generate_output(test_data, test_attention,\"family\",tokens=4,beams=1)\n",
    "        else:\n",
    "            outputs[\"family\"]=generate_output(test_data, test_attention,\"family\",tokens=4,beams=5)\n",
    "        # outputs[\"family\"]=generate_output(test_data,\"family\",tokens=15,beams=3)\n",
    "        \n",
    "    if \"symtomatic\" in test_data:\n",
    "        if low_beams:\n",
    "            outputs[\"symtomatic\"]=generate_output(test_data, test_attention,\"symtomatic\",tokens=7,beams=1)\n",
    "        else:\n",
    "            outputs[\"symtomatic\"]=generate_output(test_data, test_attention,\"symtomatic\",tokens=7,beams=5)\n",
    "        \n",
    "    if \"prosthesis\" in test_data:\n",
    "        outputs[\"prosthesis\"]=generate_output(test_data, test_attention,\"prosthesis\",tokens=2,beams=1)\n",
    "    if \"birads\" in test_data:\n",
    "        if low_beams:\n",
    "            outputs[\"birads\"]=generate_output(test_data, test_attention,\"birads\",tokens=5,beams=1)\n",
    "        else:\n",
    "            outputs[\"birads\"]=generate_output(test_data, test_attention,\"birads\",tokens=5,beams=5)\n",
    "        # outputs[\"birads\"]=generate_output(test_data,\"birads\",tokens=20,beams=3)\n",
    "        \n",
    "    if \"density_mammo\" in test_data:\n",
    "        if low_beams:\n",
    "            outputs[\"density_mammo\"]=generate_output(test_data, test_attention,\"density_mammo\",tokens=2,beams=1)\n",
    "        else:\n",
    "            outputs[\"density_mammo\"]=generate_output(test_data, test_attention,\"density_mammo\",tokens=2,beams=5)\n",
    "    if \"parenchymal_distortion\" in test_data:\n",
    "        if low_beams:\n",
    "            outputs[\"parenchymal_distortion\"]=generate_output(test_data, test_attention,\"parenchymal_distortion\",tokens=32,beams=1)\n",
    "        else:\n",
    "            outputs[\"parenchymal_distortion\"]=generate_output(test_data, test_attention,\"parenchymal_distortion\",tokens=32,beams=5)\n",
    "\n",
    "    if \"calcifications_benign\" in test_data:\n",
    "        outputs[\"calcifications_benign\"]=generate_output(test_data, test_attention,\"calcifications_benign\",tokens=2,beams=1)\n",
    "\n",
    "    if \"ganglio_mamo\" in test_data:\n",
    "        outputs[\"ganglio_mamo\"]=generate_output(test_data, test_attention,\"ganglio_mamo\",tokens=2,beams=1)\n",
    "        \n",
    "    if \"density_echo\" in test_data:\n",
    "        if low_beams:\n",
    "            outputs[\"density_echo\"]=generate_output(test_data, test_attention,\"density_echo\",tokens=5,beams=1)\n",
    "        else:\n",
    "            outputs[\"density_echo\"]=generate_output(test_data, test_attention,\"density_echo\",tokens=5,beams=5)\n",
    "        \n",
    "    if \"lymph_suspicious\" in test_data:\n",
    "        outputs[\"lymph_suspicious\"]=generate_output(test_data, test_attention,\"lymph_suspicious\",tokens=2,beams=1)\n",
    "    if \"lymph_benign\" in test_data:\n",
    "        outputs[\"lymph_benign\"]=generate_output(test_data, test_attention,\"lymph_benign\",tokens=2,beams=1)\n",
    "\n",
    "    if \"simple_cyst\" in test_data:\n",
    "        outputs[\"simple_cyst\"]=generate_output(test_data, test_attention,\"simple_cyst\",tokens=2,beams=1)\n",
    "\n",
    "    if \"ductal_ectasia\" in test_data:\n",
    "        outputs[\"ductal_ectasia\"]=generate_output(test_data, test_attention,\"ductal_ectasia\",tokens=2,beams=1)\n",
    "        \n",
    "    if \"nodules_echo_num\" in test_data:\n",
    "        outputs[\"nodules_echo_num\"]=generate_output(test_data, test_attention,\"nodules_echo_num\",tokens=2,beams=3)\n",
    "\n",
    "    if \"nodules_echo_description\" in test_data:\n",
    "        if low_beams:\n",
    "            outputs[\"nodules_echo_description\"]=generate_output(test_data, test_attention,\"nodules_echo_description\",tokens=60,beams=1)\n",
    "            \n",
    "        else:\n",
    "            outputs[\"nodules_echo_description\"]=generate_output(test_data, test_attention,\"nodules_echo_description\",tokens=60,beams=5)\n",
    "        \n",
    "    if \"nodules_echo_shape\" in test_data:\n",
    "        if low_beams:\n",
    "            outputs[\"nodules_echo_shape\"]=generate_output(test_data, test_attention,\"nodules_echo_shape\",tokens=3,beams=1)\n",
    "        else:\n",
    "            outputs[\"nodules_echo_shape\"]=generate_output(test_data, test_attention,\"nodules_echo_shape\",tokens=3,beams=3)\n",
    "\n",
    "    if \"nodules_echo_margin\" in test_data:\n",
    "        if low_beams:\n",
    "            outputs[\"nodules_echo_margin\"]=generate_output(test_data, test_attention,\"nodules_echo_margin\",tokens=4,beams=1)\n",
    "        else:\n",
    "            outputs[\"nodules_echo_margin\"]=generate_output(test_data, test_attention,\"nodules_echo_margin\",tokens=4,beams=3)\n",
    "\n",
    "    if \"nodules_echo_echogenicity\" in test_data:\n",
    "        if low_beams:\n",
    "            outputs[\"nodules_echo_echogenicity\"]=generate_output(test_data, test_attention,\"nodules_echo_echogenicity\",tokens=5,beams=1)\n",
    "        else:\n",
    "            outputs[\"nodules_echo_echogenicity\"]=generate_output(test_data, test_attention,\"nodules_echo_echogenicity\",tokens=5,beams=3)\n",
    "    if \"nodules_echo_location\" in test_data:\n",
    "        if low_beams:\n",
    "            outputs[\"nodules_echo_location\"]=generate_output(test_data, test_attention,\"nodules_echo_location\",tokens=15,beams=1)\n",
    "        else:\n",
    "            outputs[\"nodules_echo_location\"]=generate_output(test_data, test_attention,\"nodules_echo_location\",tokens=15,beams=5)\n",
    "    if \"nodules_echo_size\" in test_data:\n",
    "        if low_beams:\n",
    "            outputs[\"nodules_echo_size\"]=generate_output(test_data, test_attention,\"nodules_echo_size\",tokens=7,beams=1)\n",
    "        else:\n",
    "            outputs[\"nodules_echo_size\"]=generate_output(test_data, test_attention,\"nodules_echo_size\",tokens=7,beams=3)\n",
    "        \n",
    "    if \"nodules_echo_known\" in test_data:\n",
    "        outputs[\"nodules_echo_known\"]=generate_output(test_data, test_attention,\"nodules_echo_known\",tokens=2,beams=1)\n",
    "        \n",
    "    if \"nodules_echo_stable\" in test_data:\n",
    "        if low_beams:\n",
    "            outputs[\"nodules_echo_stable\"]=generate_output(test_data, test_attention,\"nodules_echo_stable\",tokens=2,beams=1)\n",
    "        else:\n",
    "            outputs[\"nodules_echo_stable\"]=generate_output(test_data, test_attention,\"nodules_echo_stable\",tokens=2,beams=3)\n",
    "        \n",
    "\n",
    "    text_out={}\n",
    "    for tipo in questions:\n",
    "        if tipo in outputs:\n",
    "            text_out[tipo]=[re.search(r\"Answer: (.+)\", texto).group(1) if re.search(r\"Answer: (.+)\", texto) else \"\" for texto in tokenizer.batch_decode(outputs[tipo], skip_special_tokens=True)]\n",
    "            print(f\"{tipo} outputs\")\n",
    "            print(text_out[tipo])\n",
    "            print(f\"{tipo} labels\")\n",
    "            print(test_label[tipo])\n",
    "            \n",
    "    \n",
    "   \n",
    "    \n",
    "    ind_fold={tipo: [key for key in ind if re.search(rf\"_{tipo}(_\\d+)?$\", key)] for tipo in questions}\n",
    "    \n",
    "    \n",
    "    \n",
    "    for tipo in questions:\n",
    "        if tipo in text_out:\n",
    "            print(f\"{tipo} errors\")\n",
    "            # visualize_errors(valid_dataset[tipo],test_label[tipo],text_out[tipo],ind_fold[tipo])\n",
    "        else:\n",
    "            print(f\"{tipo} does not appear in this fold\")\n",
    "    \n",
    "\n",
    "\n",
    "            # Diccionario para almacenar accuracies por categoría\n",
    "    output_dic={}\n",
    "    output_dic_t={}\n",
    "    for tipo in questions:\n",
    "        if tipo in text_out:\n",
    "            print(tipo)\n",
    "            acc = accuracy_score(test_label[tipo], text_out[tipo])\n",
    "            print(len(test_label[tipo]))\n",
    "            print(f\"Accuracy for {tipo}: {acc:.4f}\")\n",
    "            output_dic_t[tipo]={ind:test_label[tipo][i] for i, ind in enumerate(ind_fold[tipo])}\n",
    "            with open(f\"test_results/truth_dic/{tipo}.pkl\", \"wb\") as file:\n",
    "                pickle.dump(output_dic_t[tipo], file)\n",
    "            output_dic[tipo]={ind:text_out[tipo][i] for i, ind in enumerate(ind_fold[tipo])}\n",
    "    \n",
    "    for tipo in questions:\n",
    "        print(tipo)\n",
    "        with open(f\"test_results/results_dic_{tipo}/biogpt_prueba.pkl\", \"wb\") as file:\n",
    "            pickle.dump(output_dic[tipo], file)\n",
    "   \n",
    "            \n",
    "    \n",
    "\n",
    "def truth(X, Y, model_name,low_beams=False):\n",
    "    \n",
    "    test=X\n",
    "    test_y=Y.loc[test.index]\n",
    "    test[\"label\"]=test_y[\"label\"]\n",
    "    print(test)\n",
    "    del test[\"text\"]\n",
    "    \n",
    "    test.columns=[\"text\",\"label\"]\n",
    "    print(test)\n",
    "    ind=list(test.index)\n",
    "    \n",
    "    # model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "    model=AutoModelForCausalLM.from_pretrained(f\"results/{model_name}_second_stage_model_final\")\n",
    "\n",
    "    test_data=Dataset.from_pandas(test)\n",
    "    test_data_all = test_data.map(tokenize_function_test, batched=True)\n",
    "    test_data_all = test_data_all.remove_columns([\"text\",\"label\"])\n",
    "    test_data_all.set_format(\"torch\")\n",
    "\n",
    "\n",
    "    test_data={}\n",
    "    test_label={}\n",
    "    test_attention={}\n",
    "    \n",
    "    for tipo in questions:\n",
    "        #Primero creamos la lista y luego vemos que no esté vacía para hacer el stack\n",
    "        data=[output for j,output in enumerate(test_data_all[\"input_ids\"].to(\"cuda\")) if re.search(rf\"_{tipo}(_\\d+)?$\", ind[j])]\n",
    "        print(tipo)\n",
    "        print(data)\n",
    "        attention_masks=[output for j,output in enumerate(test_data_all[\"attention_mask\"].to(\"cuda\")) if re.search(rf\"_{tipo}(_\\d+)?$\", ind[j])]\n",
    "        \n",
    "        if data:\n",
    "            test_data[tipo]=torch.stack(data)\n",
    "            test_attention[tipo]=torch.stack(attention_masks)\n",
    "            del data\n",
    "            del attention_masks\n",
    "\n",
    "        labels=[output for j,output in enumerate(test[\"label\"])  if re.search(rf\"_{tipo}(_\\d+)?$\", ind[j])]\n",
    "        if labels:\n",
    "            test_label[tipo]=labels\n",
    "    \n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "    ind_fold={tipo: [key for key in ind if re.search(rf\"_{tipo}(_\\d+)?$\", key)] for tipo in questions}\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "            # Diccionario para almacenar accuracies por categoría\n",
    "    output_dic_t={}\n",
    "    for tipo in questions:\n",
    "        \n",
    "            \n",
    "        output_dic_t[tipo]={ind:test_label[tipo][i] for i, ind in enumerate(ind_fold[tipo])}\n",
    "        with open(f\"test_results/truth_dic/{tipo}.pkl\", \"wb\") as file:\n",
    "            pickle.dump(output_dic_t[tipo], file)\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27989bf-8fe7-427c-873a-918d73336a4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#no tengo que tocar nada para mañana\n",
    "model_name = \"microsoft/biogpt\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "inputs,targets,val_data,examples_raw = flatten_and_filter_dataset(ground_truth,report_data)  \n",
    "\n",
    "\n",
    "dataset_final=pd.DataFrame.from_dict(inputs,orient='index')\n",
    "targets=pd.DataFrame.from_dict(targets,orient='index')\n",
    "val_data=pd.DataFrame.from_dict(val_data,orient='index')\n",
    "dataset_final.columns=[\"text\"]\n",
    "targets.columns=[\"label\"]\n",
    "val_data.columns=[\"val_data\"]\n",
    "dataset_final=pd.concat([dataset_final, val_data],axis=1)\n",
    "\n",
    "generative_test(dataset_final, targets, model_name,low_beams=False)\n",
    " # Calcular accuracies por categoría\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1bccaf-bcdb-4029-80d8-f87af3b978e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from datasets import Dataset,concatenate_datasets,load_dataset\n",
    "from transformers import AutoTokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "import torch\n",
    "def flatten_and_filter_dataset(ground_truth,reports):\n",
    "    \"\"\"\n",
    "    Esta función toma un conjunto de datos en el formato original (con estructura jerárquica)\n",
    "    y devuelve un conjunto de datos plano, donde cada entrada tiene un solo `context`, `question` y `answer`.\n",
    "    \n",
    "    Argumentos:\n",
    "        dataset: Un conjunto de datos en formato original (puede ser train, validation, test).\n",
    "    \n",
    "    Retorno:\n",
    "        Un conjunto de datos de Hugging Face en formato plano, con solo ejemplos completos.\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    Esta función toma un conjunto de datos en el formato original (con estructura jerárquica)\n",
    "    y devuelve un conjunto de datos plano, donde cada entrada tiene un solo `context`, `question` y `answer`.\n",
    "    \n",
    "    Argumentos:\n",
    "        dataset: Un conjunto de datos en formato original (puede ser train, validation, test).\n",
    "    \n",
    "    Retorno:\n",
    "        Un conjunto de datos de Hugging Face en formato plano, con solo ejemplos completos.\n",
    "    \"\"\"\n",
    "    # Lista para almacenar ejemplos en formato plano\n",
    "    flattened_examples = {}\n",
    "    examples_raw={}\n",
    "    targets={}\n",
    "    val_data={}\n",
    "    question_tipo={}\n",
    "    previous_message_answer_tipo={}\n",
    "    options_tipo={}\n",
    "    answers_tipo={}\n",
    "    j=0\n",
    "    \n",
    "    question_tipo[\"age\"]= \"does the patient's age appear in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"age\"]=\"search for numbers, but do not mistake it with the age of a familiar. If a number appears without any context between two dots it is surely the age.\"\n",
    "    options_tipo[\"age\"]=\"answer only the age of the patient.\"\n",
    "\n",
    "    question_tipo[\"tipo\"]= 'is the following breast medical report a biopsy report or a nodal staging ultrasound report?'\n",
    "    previous_message_answer_tipo[\"tipo\"]=\"biopsy reports are normally Image-Guided Biopsy and is normally said that they are referred to the hospital for biopsy. Nodal staging ultrasound reports can also be written as 'axilla ultrasound'. If it is any of these it will be written in the beginning of the report, normally in the used technique. These kind of reports are only ultrasound. In these reports no final BI-RADS is given.\"\n",
    "    options_tipo[\"tipo\"]=\"answer with one of the following options: 'biopsy report', 'nodal staging ultrasound report' or 'normal control or revision report'.\"\n",
    "\n",
    "    question_tipo[\"tecnica\"]= 'what diagnostic technique was used in the following breast medical report?'\n",
    "    previous_message_answer_tipo[\"tecnica\"]=\"biopsy reports, simple cysts and analysis of lymph or axillary nodes are only seen on ultrasound. On the other hand, if the ACR density is given or parenchymal distortions are analysed, the technique will be a mammogram. Tomosyntesis is a mammography type. The report may include an ultrasound examination, a mammography examination or both.\"\n",
    "    options_tipo[\"tecnica\"]=\"answer with one of the following options: 'only ultrasound study', 'only mammography study' or 'mammography and ultrasound'.\"\n",
    "\n",
    "    question_tipo[\"family\"]= \"does the patient have any family history in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"family\"]=\"family history of breast cancer is categorized based on the degree of relatives affected: First-degree relatives: Parents, siblings, or children. Second-degree relatives: Grandparents, aunts, uncles, nieces, nephews, or half-siblings. Third-degree relatives: Great-grandparents, great-aunts/uncles, or first cousins.\"\n",
    "    options_tipo[\"family\"]=\"answer with one of the following options: 'first degree', 'second degree', 'third degree' or 'no family history'.\"\n",
    "    \n",
    "    question_tipo[\"history\"]= \"does the patient have any non-familiar history in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"history\"]=\"check for the history at the beginning of the report. Normally it is a previous biopsy result, mastectomy or cancer. It normally starts with 'history of ...'.\"\n",
    "    options_tipo[\"history\"]=\"answer retrieving the information directly from the report or with 'no history was found'.\"\n",
    "    \n",
    "    question_tipo[\"symtomatic\"]= \"is the reason for the consultation that the patient is symptomatic in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"symtomatic\"]=\"the answer is at the beginning of the report, in the reason for consultation. It is normally a palpable lump, lumpectomy or nodule, sometimes painful.\"\n",
    "    options_tipo[\"symtomatic\"]=\"answer retrieving the information directly from the report or with 'non-symptomatic consultation'.\"\n",
    "    \n",
    "    question_tipo[\"prosthesis\"]= \"does the patient have a prosthesis in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"prosthesis\"]=\"it is normally clearly indicated at the beginning of the report. Sometimes it is written as implants instead of prosthesis.\"\n",
    "    options_tipo[\"prosthesis\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "    \n",
    "    question_tipo[\"birads\"]= \"what is the final BI-RADS classification given to the patient in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"birads\"]=\"the final BI-RADS of the patient is given in the conclusions of the report, normally at the end.\"\n",
    "    options_tipo[\"birads\"]=\"answer with one of the following options: 'BI-RADS 0', 'BI-RADS 1', 'BI-RADS 2', 'BI-RADS 3', 'BI-RADS 4A', 'BI-RADS 4B', 'BI-RADS 4C', 'BI-RADS 5' or 'unknown'.\"\n",
    "\n",
    "    question_tipo[\"density_mammo\"]= \"what is the breast density found in the mammography study of the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"density_mammo\"]=\"breast density in mammography is classified into four categories: ACR A (= Almost entirely fatty), ACR B (= Scattered areas of fibroglandular density), ACR C (= Heterogeneously dense), ACR D (= Extremely or very dense breasts). Sometimes it is written as 'density type x'. It can also be written with their real meaning (very dense breasts = C) and not with the A, B, C, D classification. Focus only on density.\"\n",
    "    options_tipo[\"density_mammo\"]=\"answer with one of the following options: 'ACR A', 'ACR B', 'ACR C', ACR D' or 'unknown'.\"\n",
    "   \n",
    "    question_tipo[\"density_echo\"]= \"what is the breast density found in the ultrasound study of the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"density_echo\"]=\"breast composition in ultrasound is classified into three categories: fibroglandular and fat (mixed distribution of fibroglandular and adipose tissue), heterogeneous fibroglandular (predominantly fibroglandular tissue with varying echogenicity and scattered fat areas), homogeneous fatty (uniform fatty tissue with consistent echogenicity and minimal fibroglandular content), and homogeneous fibroglandular (uniform fibroglandular tissue with consistent echogenicity and minimal fat content).\"\n",
    "    options_tipo[\"density_echo\"]=\"answer with one of the following options: 'fibroglandular and fat', 'heterogeneous fibroglandular', 'homogeneous fibroglandular', 'homogeneous fatty' or 'unknown'.\"\n",
    "\n",
    "    question_tipo[\"calcifications_benign\"]= \"does the following breast medical report mention the appearence of benign calcifications in the mammography exam?\"\n",
    "    previous_message_answer_tipo[\"calcifications_benign\"]=\"Consider only benign calcifications in the mammography.\"\n",
    "    options_tipo[\"calcifications_benign\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "    \n",
    "    question_tipo[\"ganglio_mamo\"]= \"does the following breast medical report mention any lymph nodes in the mammography exam?\"\n",
    "    previous_message_answer_tipo[\"ganglio_mamo\"]=\"Consider only lymph nodes that appear in the mammography.\"\n",
    "    options_tipo[\"ganglio_mamo\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "\n",
    "    question_tipo[\"parenchymal_distortion\"]= \"does the following breast medical report mention any parenchymal distortion or asymmetry in the mammography exam?\"\n",
    "    previous_message_answer_tipo[\"parenchymal_distortion\"]=\"If it has any it will appear in the results of the mammography exam using the words distortion, asymmetry or sometimes it can also be surgical changes.\"\n",
    "    options_tipo[\"parenchymal_distortion\"]=\"answer retrieving the information directly from the report or with 'no'\"\n",
    "    \n",
    "    question_tipo[\"lymph_suspicious\"]= \"does the following breast medical report mention any suspicious axillary lymph nodes in the ultrasound exam?\"\n",
    "    previous_message_answer_tipo[\"lymph_suspicious\"]=\"if a lymph node is suspicious the report will recomend a biopsy or Fine Needle Aspiration. A lymph node is considered suspicious when it has eccentric cortical thickening ≥ 3 mm, Short axis >10 mm, round shape, loss of fatty hilum, abnormal vascularity, or irregular margins—especially when associated with known malignancy or progressive enlargement. They can also be classified as UN3, UN4 or UN5. An exam may have both suspicious and benign lymph nodes, answer 'yes' in this case.\"\n",
    "    options_tipo[\"lymph_suspicious\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "\n",
    "    question_tipo[\"lymph_benign\"]= \"does the following breast medical report mention any benign or not suspicious axillary lymph nodes in the ultrasound exam?\"\n",
    "    previous_message_answer_tipo[\"lymph_benign\"]=\"if a lymph node is suspicious the report will recomend a biopsy or Fine Needle Aspiration. A lymph node is considered benign when it has uniform cortex < 3 mm, preserved fatty hilum, oval shape, no abnormal vascularity, no irregular margins and homogeneous internal echo pattern. Benign axillary nodes can be classified as UN1 or UN2. A reactive axillary node is not suspicious. An exam may have both suspicious and benign lymph nodes, answer 'yes' in this case.\"\n",
    "    options_tipo[\"lymph_benign\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "\n",
    "    question_tipo[\"simple_cyst\"]= \"does the following breast medical report mention any simple cysts or microcysts in the ultrasound exam?\"\n",
    "    previous_message_answer_tipo[\"simple_cyst\"]=\"The words symple cysts or microcysts will appear only in the ultrasound exam. Sometimes they can say that some of the cysts have echogenic content, but we still will consider them simple cysts and not nodules.\"\n",
    "    options_tipo[\"simple_cyst\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "\n",
    "    question_tipo[\"ductal_ectasia\"]= \"does the following breast medical report mention any ductal ectasia in the ultrasound exam?\"\n",
    "    previous_message_answer_tipo[\"ductal_ectasia\"]=\"The word ductal ectasia will appear only in the ultrasound exam.\"\n",
    "    options_tipo[\"ductal_ectasia\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "    \n",
    "    question_tipo[\"nodules_echo_num\"]=\"is there any nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"nodules_echo_num\"]=\"do not consider if a nodule is described in the mammography exam or if it is in the axilla. The localization, echogenicity and size of the nodules are normally said.\"\n",
    "    options_tipo[\"nodules_echo_num\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "\n",
    "    \n",
    "    dic_order = {\n",
    "        1: \"first\",\n",
    "        2: \"second\",\n",
    "        3: \"third\",\n",
    "        4: \"fourth\",\n",
    "        5: \"fifth\",\n",
    "        6: \"sixth\",\n",
    "        7: \"seventh\",\n",
    "        8: \"eighth\",\n",
    "        9: \"ninth\",\n",
    "        10: \"tenth\",\n",
    "        11: \"eleventh\",\n",
    "        12: \"twelfth\",\n",
    "        13: \"thirteenth\",\n",
    "        14: \"fourteenth\",\n",
    "        15: \"fifteenth\"\n",
    "    }\n",
    "    for i in range(1,2):\n",
    "        question_tipo[f\"nodules_echo_description_{i}\"]= f\"which is the {dic_order[i]} nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_description_{i}\"]=\"do not consider if a nodule is described in the mammography exam or if it is in the axilla. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "        options_tipo[f\"nodules_echo_description_{i}\"]=\"answer retrieving the information directly from the report.\"\n",
    "        \n",
    "        question_tipo[f\"nodules_echo_shape_{i}\"]= f\"what is the shape of the {dic_order[i]} nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_shape_{i}\"]=\"do not consider if a nodule is described in the mammography exam or if it is in the axilla. Shapes can be 'oval', 'round', 'lobulated' and 'irregular'. Sometimes irregular is also used for the margin, but in this case it is written as 'irregular margin' or 'irregular borders'. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "        options_tipo[f\"nodules_echo_shape_{i}\"]=\"answer with one of the following options: 'oval', 'round', 'lobulated', 'irregular' or 'unknown'.\"\n",
    "        \n",
    "        question_tipo[f\"nodules_echo_margin_{i}\"]= f\"what is the margin of the {dic_order[i]} nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_margin_{i}\"]=\"do not consider if a nodule is described in the mammography exam or if it is in the axilla. Margin can be 'circumscribed' and 'not circumscribed'. Inside the not circumscribed we have 'spiculated', 'angulated', 'microlobulated' or 'indistinc' ('not defined') margins. Sometimes irregular is also used for the margin, but in this case it is written as 'irregular margin' or 'irregular borders', in this case classify it as 'not circumscribed'. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "        options_tipo[f\"nodules_echo_margin_{i}\"]=\"answer with one of the following options: 'circumscribed', 'not circumscribed', 'indefined', 'spiculated', 'angulated', 'microlobulated' or 'unknown'.\"\n",
    "        \n",
    "        question_tipo[f\"nodules_echo_echogenicity_{i}\"]= f\"what is the echogenicity of the {dic_order[i]} nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_echogenicity_{i}\"]=\"do not consider if a nodule is described in the mammography exam or if it is in the axilla. Echogenicity can be 'anechoic', 'hypoechoic', 'heterogeneous' and 'complex cystic and solid'. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\" \n",
    "        options_tipo[f\"nodules_echo_echogenicity_{i}\"]=\"answer with one of the following options: 'hypoechoic', 'heterogeneous', 'anechoic', 'hyperecoic', 'isoechoic', 'complex cystic and solid' or 'unknown'.\"\n",
    "        \n",
    "        question_tipo[f\"nodules_echo_location_{i}\"]= f\"In which location is the {dic_order[i]} nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_location_{i}\"]=\"do not consider if a nodule is described in the mammography exam or if it is in the axilla. If the nodule is mentioned previously in the mammography, the location can be found also there. sometimes the breast location of the tumour may be written in a different part than the quadrant. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "        options_tipo[f\"nodules_echo_location_{i}\"]=\"answer retrieving the information directly from the report or with 'unknown'.\"\n",
    "        \n",
    "        question_tipo[f\"nodules_echo_size_{i}\"]= f\"what is the size of the {dic_order[i]} nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_size_{i}\"]=\"do not consider if a nodule is described in the mammography exam. The localization, echogenicity and size of the nodules are normally said. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "        options_tipo[f\"nodules_echo_size_{i}\"]=\"answer retrieving the information directly from the report (stop after 'mm') or with 'unknown'.\"\n",
    "        \n",
    "        question_tipo[f\"nodules_echo_known_{i}\"]= f\"is the {dic_order[i]} nodule described in the ultrasound exam of the following breast medical report previously known?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_known_{i}\"]=\"do not consider if a nodule is described in the mammography exam. If the nodule is known from before the report, it will say if it it is stable or if it has grown or shrink. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "        options_tipo[f\"nodules_echo_known_{i}\"]=\"answer with one of the following options: 'yes' or 'no'.\"\n",
    "        \n",
    "        question_tipo[f\"nodules_echo_stable_{i}\"]= f\"is the {dic_order[i]} known nodule described in the ultrasound exam stable in the following breast medical report?\"\n",
    "        previous_message_answer_tipo[f\"nodules_echo_stable_{i}\"]=\"do not consider if a nodule is described in the mammography exam. If the nodule is known from before the examination, it will be analysed to see if it is stable or if it got bigger or smaller. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "        options_tipo[f\"nodules_echo_stable_{i}\"]=\"answer with one of the following options: 'yes', 'grown' or 'shrunk.\"\n",
    "    for i, report in enumerate(reports[\"informes_ingles\"]):\n",
    "        informe=preprocess_text(report)\n",
    "        key=reports[\"keys\"][i]\n",
    "        \n",
    "        if key not in ground_truth.index:\n",
    "            continue\n",
    "        \n",
    "        row=ground_truth.loc[key]\n",
    "\n",
    "        #AGE\n",
    "        age=str(row[\"Age\"])\n",
    "        answer_tipo={}\n",
    "        # Verificar si el ejemplo tiene preguntas\n",
    "        if age.isdigit():\n",
    "            answer_tipo[\"age\"]=age+\".\"\n",
    "            \n",
    "        else:\n",
    "            answer_tipo[\"age\"]=\"no\"+\".\"\n",
    "        \n",
    "        #TIPO\n",
    "        if row[\"Biopsy_report\"].lower()==\"yes\":\n",
    "            answer_tipo[\"tipo\"]=\"biopsy report\"+\".\"\n",
    "            \n",
    "        elif row[\"Ganglio_report\"].lower()==\"yes\":\n",
    "            answer_tipo[\"tipo\"]=\"nodal staging ultrasound report\"+\".\"\n",
    "        else:\n",
    "            answer_tipo[\"tipo\"]=\"normal control or revision report\"+\".\"\n",
    "        \n",
    "        #TECHNIQUE\n",
    "        tecnica=row[\"Technique\"]\n",
    "        # Verificar si el ejemplo tiene preguntas\n",
    "        if tecnica==\"ultrasound\":\n",
    "            answer_tipo[\"tecnica\"]=\"only ultrasound study\"+\".\"            \n",
    "        elif tecnica==\"mammography\":\n",
    "            answer_tipo[\"tecnica\"]=\"only mammography study\"+\".\"\n",
    "        elif not pd.isna(tecnica):\n",
    "            answer_tipo[\"tecnica\"]=tecnica+\".\"\n",
    "        else:\n",
    "            print(key,report)\n",
    "        \n",
    "        # \n",
    "        # HISTORY\n",
    "        #No consideramos las biopsias o las ecografías de estadificación ganglionar.\n",
    "        if answer_tipo[\"tipo\"]==\"normal control or revision report\"+\".\":\n",
    "            history=row[\"Other_history\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(history,str) or history==\"No\":\n",
    "                answer_tipo[\"history\"]=\"no history was found\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"history\"]=history+\".\" \n",
    "    \n",
    "            # FAMILY\n",
    "            family=row[\"Family_history\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(family,str) or family==\"No\":\n",
    "                answer_tipo[\"family\"]=\"no family history\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"family\"]=family+\".\" \n",
    "    \n",
    "            # SYMTOMATIC\n",
    "            symtomatic=row[\"Syntomatic\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(symtomatic,str) or symtomatic==\"No\" or symtomatic==\"No estoy seguro\":\n",
    "                answer_tipo[\"symtomatic\"]=\"Non-symptomatic consultation\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"symtomatic\"]=symtomatic+\".\" \n",
    "    \n",
    "            # PROSTHESIS\n",
    "            prosthesis=row[\"Prosthesis\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(prosthesis,str) or prosthesis==\"No\":\n",
    "                answer_tipo[\"prosthesis\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"prosthesis\"]=\"yes\"+\".\"\n",
    "    \n",
    "            #BIRADS\n",
    "            birads=row[\"BI-RADS\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(birads,str):\n",
    "                answer_tipo[\"birads\"]=\"unknown\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"birads\"]=birads+\".\"\n",
    "    \n",
    "            #Density mammo\n",
    "            density_mammo=row[\"Density_mamo\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(density_mammo,str):\n",
    "                answer_tipo[\"density_mammo\"]=\"unknown\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"density_mammo\"]=density_mammo+\".\"\n",
    "\n",
    "            #Lymp nodes mammo\n",
    "            ganglio_mamo=row[\"Ganglio_mamo\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(ganglio_mamo,str):\n",
    "                answer_tipo[\"ganglio_mamo\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"ganglio_mamo\"]=ganglio_mamo.lower()+\".\"\n",
    "\n",
    "            #Calcifications benign\n",
    "            calcifications_benign=row[\"Calcifications_benign_mamo\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(calcifications_benign,str):\n",
    "                answer_tipo[\"calcifications_benign\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"calcifications_benign\"]=calcifications_benign.lower()+\".\"\n",
    "\n",
    "            #Parenchymal distortion\n",
    "            parenchymal_distortion=row[\"parenchymal_distortions_asymmetry\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(parenchymal_distortion,str):\n",
    "                answer_tipo[\"parenchymal_distortion\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"parenchymal_distortion\"]=parenchymal_distortion.lower()+\".\"\n",
    "    \n",
    "            #Density echo\n",
    "            density_echo=row[\"Density_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(density_echo,str):\n",
    "                answer_tipo[\"density_echo\"]=\"unknown\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"density_echo\"]=density_echo+\".\"\n",
    "\n",
    "            #Benign lymph nodes\n",
    "            simple_cyst=row[\"simple_cyst_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(simple_cyst,str):\n",
    "                answer_tipo[\"simple_cyst\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"simple_cyst\"]=simple_cyst.lower()+\".\"\n",
    "            #Suspicious lymph nodes\n",
    "            lymph_suspicious=row[\"Ganglio_suspicious_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(lymph_suspicious,str):\n",
    "                answer_tipo[\"lymph_suspicious\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"lymph_suspicious\"]=lymph_suspicious.lower()+\".\"\n",
    "\n",
    "            #Benign lymph nodes\n",
    "            lymph_benign=row[\"Ganglio_benign_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(lymph_benign,str):\n",
    "                answer_tipo[\"lymph_benign\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"lymph_benign\"]=lymph_benign.lower()+\".\"\n",
    "\n",
    "            #Ductal ectasia\n",
    "            ductal_ectasia=row[\"Ductal_ectasia_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(ductal_ectasia,str):\n",
    "                answer_tipo[\"ductal_ectasia\"]=\"no\"+\".\"            \n",
    "            else:\n",
    "                answer_tipo[\"ductal_ectasia\"]=ductal_ectasia.lower()+\".\"\n",
    "    \n",
    "            #Nodules echo\n",
    "            nodules_echo_num=row[\"Nodules_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(nodules_echo_num,str) and not isinstance(nodules_echo_num,int):\n",
    "                answer_tipo[\"nodules_echo_num\"]=\"no\"+\".\"    \n",
    "            elif isinstance(nodules_echo_num,str) and nodules_echo_num.lower()==\"no\":\n",
    "                answer_tipo[\"nodules_echo_num\"]=\"no\"+\".\"  \n",
    "            else:\n",
    "                answer_tipo[\"nodules_echo_num\"]=\"yes\"+\".\"\n",
    "    \n",
    "            #Si existen nódulos se hace las preguntas correspondientes\n",
    "            if answer_tipo[\"nodules_echo_num\"]!=\"no.\":\n",
    "                \n",
    "                nodules_echo_description=row[\"Description_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "\n",
    "                answer_tipo[\"nodules_echo_description_1\"]=nodules_echo_description+\".\"\n",
    "                    \n",
    "                nodules_echo_shape=row[f\"Shape_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_echo_shape,str):\n",
    "                    answer_tipo[\"nodules_echo_shape_1\"]=\"unknown\"+\".\"\n",
    "                else:\n",
    "                    answer_tipo[\"nodules_echo_shape_1\"]=nodules_echo_shape.lower()+\".\"\n",
    "\n",
    "                nodules_echo_margin=row[\"Margin_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_echo_margin,str):\n",
    "                    answer_tipo[\"nodules_echo_margin_1\"]=\"unknown\"+\".\"\n",
    "                else:\n",
    "                    answer_tipo[\"nodules_echo_margin_1\"]=nodules_echo_margin.lower()+\".\"\n",
    "\n",
    "                nodules_echo_echogenicity=row[\"Echogenicity_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_echo_echogenicity,str):\n",
    "                    answer_tipo[\"nodules_echo_echogenicity_1\"]=\"unknown\"+\".\"\n",
    "                else:\n",
    "                    answer_tipo[\"nodules_echo_echogenicity_1\"]=nodules_echo_echogenicity.lower()+\".\"\n",
    "\n",
    "                nodules_echo_location=row[f\"Location_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_echo_location,str):\n",
    "                    answer_tipo[\"nodules_echo_location_1\"]=\"unknown\"+\".\"\n",
    "                else:\n",
    "                    answer_tipo[\"nodules_echo_location_1\"]=nodules_echo_location.lower()+\".\"\n",
    "\n",
    "                \n",
    "                #Nodules echo size\n",
    "                nodules_echo_size=row[\"size_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_echo_size,str):\n",
    "                    answer_tipo[\"nodules_echo_size_1\"]=\"unknown\"+\".\"            \n",
    "                else:\n",
    "                    answer_tipo[\"nodules_echo_size_1\"]=nodules_echo_size+\".\"\n",
    "        \n",
    "                #Nodules echo known\n",
    "                nodules_echo_known=row[\"new_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_echo_known,str):\n",
    "                    answer_tipo[\"nodules_echo_known_1\"]=\"unknown\"+\".\"\n",
    "                elif nodules_echo_known.lower()==\"no\":\n",
    "                    answer_tipo[\"nodules_echo_known_1\"]=\"yes\"+\".\"            \n",
    "                else:\n",
    "                    answer_tipo[\"nodules_echo_known_1\"]=\"no\"+\".\"\n",
    "\n",
    "                if answer_tipo[\"nodules_echo_known_1\"]==\"yes.\":\n",
    "                    #Nodules echo stable\n",
    "                    nodules_echo_stable=row[\"Stable_eco_1\"]\n",
    "                    # Verificar si el ejemplo tiene preguntas\n",
    "                    if not isinstance(nodules_echo_stable,str):\n",
    "                        answer_tipo[\"nodules_echo_stable_1\"]=\"unknown\"+\".\"\n",
    "                    else:\n",
    "                        answer_tipo[\"nodules_echo_stable_1\"]=nodules_echo_stable.lower()+\".\"\n",
    "            \n",
    "        for tipo in answer_tipo:\n",
    "            \n",
    "            #Si está el tipo en las respuestas que hemos recogido lo metemos a la base de datos.\n",
    "            key_tipo=key+\"_\"+tipo\n",
    "            if key_tipo in flattened_examples:\n",
    "                continue\n",
    "                key_tipo=key_tipo+\"_copy\"\n",
    "            examples_raw[key_tipo]=report\n",
    "            answer=str(answer_tipo[tipo])\n",
    "            \n",
    "    \n",
    "            inputs_tipo = \"Question: \" + question_tipo[tipo] +\" Additional information: \"+ previous_message_answer_tipo[tipo]+ \" Context: \" + informe + \"Options:\"+ options_tipo[tipo]+ \" Answer: \"\n",
    "            # inputs_tipo = \"question: \" + question_tipo[tipo] +\" context: \" + informe\n",
    "            flattened_examples[key_tipo]=inputs_tipo\n",
    "            targets[key_tipo]=answer\n",
    "            \n",
    "    return flattened_examples,targets\n",
    "\n",
    "\n",
    "def tokenize_function_test(inputs):\n",
    "    model_inputs = tokenizer(inputs[\"text\"], max_length=1024,truncation=True,padding=\"max_length\")\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "def generate_output(model,test_data, test_attention, tipo, tokens, beams):\n",
    "    outputs = []\n",
    "    for i,data in enumerate(test_data[tipo]):\n",
    "        output = model.generate(\n",
    "            data.unsqueeze(0),  # Shape: (1, sequence_length)\n",
    "            max_new_tokens=tokens,\n",
    "            attention_mask=test_attention[tipo][i].unsqueeze(0),  # Important for reliable results\n",
    "\n",
    "            num_beams=beams,\n",
    "            num_return_sequences=1,\n",
    "            early_stopping=True\n",
    "        ).squeeze(0).cpu()  # Shape: (generated_sequence_length,)\n",
    "        \n",
    "        outputs.append(output)  # Append 1D tensors (no extra dimensions)\n",
    "\n",
    "    # Pad sequences to the longest one in the batch\n",
    "    outputs_padded = pad_sequence(outputs, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    return outputs_padded  # Shape: (batch_size, max_sequence_length)\n",
    "    \n",
    "def generative_test(X, Y, model_name,low_beams=False):\n",
    "    \n",
    "    \n",
    "    test=X\n",
    "    test_y=Y.loc[test.index]\n",
    "    test[\"label\"]=test_y[\"label\"]\n",
    "    test.columns=[\"text\",\"label\"]\n",
    "    print(test)\n",
    "    ind=list(test.index)\n",
    "    \n",
    "    # model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "    model=T5ForConditionalGeneration.from_pretrained(f\"results/{model_name}_second_stage_model_final\", from_flax=True)\n",
    "\n",
    "    test_data=Dataset.from_pandas(test)\n",
    "    test_data_all = test_data.map(tokenize_function_test, batched=True)\n",
    "    test_data_all = test_data_all.remove_columns([\"text\",\"label\"])\n",
    "    test_data_all.set_format(\"torch\")\n",
    "\n",
    "\n",
    "    test_data={}\n",
    "    test_label={}\n",
    "    test_attention={}\n",
    "        \n",
    "    for tipo in questions:\n",
    "        #Primero creamos la lista y luego vemos que no esté vacía para hacer el stack\n",
    "        data=[output for j,output in enumerate(test_data_all[\"input_ids\"].to(\"cuda\")) if re.search(rf\"_{tipo}(_\\d+)?$\", ind[j])]\n",
    "        attention_masks=[output for j,output in enumerate(test_data_all[\"attention_mask\"].to(\"cuda\")) if re.search(rf\"_{tipo}(_\\d+)?$\", ind[j])]\n",
    "        \n",
    "        if data:\n",
    "            test_data[tipo]=torch.stack(data)\n",
    "            test_attention[tipo]=torch.stack(attention_masks)\n",
    "            del data\n",
    "            del attention_masks\n",
    "\n",
    "        labels=[output for j,output in enumerate(test[\"label\"])  if re.search(rf\"_{tipo}(_\\d+)?$\", ind[j])]\n",
    "        if labels:\n",
    "            test_label[tipo]=labels\n",
    "    \n",
    "\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    model=model.to(\"cuda\")\n",
    "    outputs={}\n",
    "    \n",
    "        \n",
    "    if \"age\" in test_data:\n",
    "        outputs[\"age\"]=generate_output(model,test_data, test_attention,\"age\",tokens=6,beams=1)\n",
    "        # outputs[\"age\"]=generate_output(test_data,\"age\",tokens=10,beams=3)\n",
    "        \n",
    "            \n",
    "    if \"tipo\" in test_data:\n",
    "        # outputs[\"tipo\"]=generate_output(test_data,\"tipo\",tokens=5,beams=1)\n",
    "        if low_beams:\n",
    "            outputs[\"tipo\"]=generate_output(model,test_data, test_attention,\"tipo\",tokens=15,beams=1)\n",
    "        else:\n",
    "            outputs[\"tipo\"]=generate_output(model,test_data, test_attention,\"tipo\",tokens=15,beams=5)\n",
    "        \n",
    "\n",
    "    if \"tecnica\" in test_data:\n",
    "        if low_beams:\n",
    "            outputs[\"tecnica\"]=generate_output(model,test_data, test_attention,\"tecnica\",tokens=8,beams=1)\n",
    "        else:\n",
    "            \n",
    "            outputs[\"tecnica\"]=generate_output(model,test_data, test_attention,\"tecnica\",tokens=8,beams=5)\n",
    "        # outputs[\"tecnica\"]=generate_output(test_data,\"tecnica\",tokens=15,beams=3)\n",
    "        \n",
    "    if \"history\" in test_data:\n",
    "        if low_beams:\n",
    "            outputs[\"history\"]=generate_output(model,test_data, test_attention,\"history\",tokens=45,beams=1)\n",
    "        else:\n",
    "            outputs[\"history\"]=generate_output(model,test_data, test_attention,\"history\",tokens=45,beams=5)\n",
    "        \n",
    "    if \"family\" in test_data:\n",
    "        if low_beams:\n",
    "            outputs[\"family\"]=generate_output(model,test_data, test_attention,\"family\",tokens=8,beams=1)\n",
    "        else:\n",
    "            outputs[\"family\"]=generate_output(model,test_data, test_attention,\"family\",tokens=8,beams=5)\n",
    "        # outputs[\"family\"]=generate_output(test_data,\"family\",tokens=15,beams=3)\n",
    "        \n",
    "    if \"symtomatic\" in test_data:\n",
    "        if low_beams:\n",
    "            outputs[\"symtomatic\"]=generate_output(model,test_data, test_attention,\"symtomatic\",tokens=15,beams=1)\n",
    "        else:\n",
    "            outputs[\"symtomatic\"]=generate_output(model,test_data, test_attention,\"symtomatic\",tokens=15,beams=5)\n",
    "        \n",
    "    if \"prosthesis\" in test_data:\n",
    "        outputs[\"prosthesis\"]=generate_output(model,test_data, test_attention,\"prosthesis\",tokens=6,beams=1)\n",
    "    if \"birads\" in test_data:\n",
    "        if low_beams:\n",
    "            outputs[\"birads\"]=generate_output(model,test_data, test_attention,\"birads\",tokens=10,beams=1)\n",
    "        else:\n",
    "            outputs[\"birads\"]=generate_output(model,test_data, test_attention,\"birads\",tokens=10,beams=5)\n",
    "        # outputs[\"birads\"]=generate_output(test_data,\"birads\",tokens=20,beams=3)\n",
    "        \n",
    "    if \"density_mammo\" in test_data:\n",
    "        if low_beams:\n",
    "            outputs[\"density_mammo\"]=generate_output(model,test_data, test_attention,\"density_mammo\",tokens=8,beams=1)\n",
    "        else:\n",
    "            outputs[\"density_mammo\"]=generate_output(model,test_data, test_attention,\"density_mammo\",tokens=8,beams=5)\n",
    "    if \"parenchymal_distortion\" in test_data:\n",
    "        if low_beams:\n",
    "            outputs[\"parenchymal_distortion\"]=generate_output(model,test_data, test_attention,\"parenchymal_distortion\",tokens=45,beams=1)\n",
    "        else:\n",
    "            outputs[\"parenchymal_distortion\"]=generate_output(model,test_data, test_attention,\"parenchymal_distortion\",tokens=45,beams=5)\n",
    "\n",
    "    if \"calcifications_benign\" in test_data:\n",
    "        outputs[\"calcifications_benign\"]=generate_output(model,test_data, test_attention,\"calcifications_benign\",tokens=6,beams=1)\n",
    "\n",
    "    if \"ganglio_mamo\" in test_data:\n",
    "        outputs[\"ganglio_mamo\"]=generate_output(model,test_data, test_attention,\"ganglio_mamo\",tokens=6,beams=1)\n",
    "        \n",
    "    if \"density_echo\" in test_data:\n",
    "        if low_beams:\n",
    "            outputs[\"density_echo\"]=generate_output(model,test_data, test_attention,\"density_echo\",tokens=15,beams=1)\n",
    "        else:\n",
    "            outputs[\"density_echo\"]=generate_output(model,test_data, test_attention,\"density_echo\",tokens=15,beams=5)\n",
    "        \n",
    "    if \"lymph_suspicious\" in test_data:\n",
    "        outputs[\"lymph_suspicious\"]=generate_output(model,test_data, test_attention,\"lymph_suspicious\",tokens=6,beams=1)\n",
    "    if \"lymph_benign\" in test_data:\n",
    "        outputs[\"lymph_benign\"]=generate_output(model,test_data, test_attention,\"lymph_benign\",tokens=6,beams=1)\n",
    "\n",
    "    if \"simple_cyst\" in test_data:\n",
    "        outputs[\"simple_cyst\"]=generate_output(model,test_data, test_attention,\"simple_cyst\",tokens=6,beams=1)\n",
    "\n",
    "    if \"ductal_ectasia\" in test_data:\n",
    "        outputs[\"ductal_ectasia\"]=generate_output(model,test_data, test_attention,\"ductal_ectasia\",tokens=6,beams=1)\n",
    "        \n",
    "    if \"nodules_echo_num\" in test_data:\n",
    "        outputs[\"nodules_echo_num\"]=generate_output(model,test_data, test_attention,\"nodules_echo_num\",tokens=6,beams=3)\n",
    "\n",
    "    if \"nodules_echo_description\" in test_data:\n",
    "        if low_beams:\n",
    "            outputs[\"nodules_echo_description\"]=generate_output(model,test_data, test_attention,\"nodules_echo_description\",tokens=60,beams=1)\n",
    "            \n",
    "        else:\n",
    "            outputs[\"nodules_echo_description\"]=generate_output(model,test_data, test_attention,\"nodules_echo_description\",tokens=60,beams=5)\n",
    "        \n",
    "    if \"nodules_echo_shape\" in test_data:\n",
    "        if low_beams:\n",
    "            outputs[\"nodules_echo_shape\"]=generate_output(model,test_data, test_attention,\"nodules_echo_shape\",tokens=8,beams=1)\n",
    "        else:\n",
    "            outputs[\"nodules_echo_shape\"]=generate_output(model,test_data, test_attention,\"nodules_echo_shape\",tokens=8,beams=3)\n",
    "\n",
    "    if \"nodules_echo_margin\" in test_data:\n",
    "        if low_beams:\n",
    "            outputs[\"nodules_echo_margin\"]=generate_output(model,test_data, test_attention,\"nodules_echo_margin\",tokens=10,beams=1)\n",
    "        else:\n",
    "            outputs[\"nodules_echo_margin\"]=generate_output(model,test_data, test_attention,\"nodules_echo_margin\",tokens=10,beams=3)\n",
    "\n",
    "    if \"nodules_echo_echogenicity\" in test_data:\n",
    "        if low_beams:\n",
    "            outputs[\"nodules_echo_echogenicity\"]=generate_output(model,test_data, test_attention,\"nodules_echo_echogenicity\",tokens=10,beams=1)\n",
    "        else:\n",
    "            outputs[\"nodules_echo_echogenicity\"]=generate_output(model,test_data, test_attention,\"nodules_echo_echogenicity\",tokens=10,beams=3)\n",
    "    if \"nodules_echo_location\" in test_data:\n",
    "        if low_beams:\n",
    "            outputs[\"nodules_echo_location\"]=generate_output(model,test_data, test_attention,\"nodules_echo_location\",tokens=30,beams=1)\n",
    "        else:\n",
    "            outputs[\"nodules_echo_location\"]=generate_output(model,test_data, test_attention,\"nodules_echo_location\",tokens=30,beams=5)\n",
    "    if \"nodules_echo_size\" in test_data:\n",
    "        if low_beams:\n",
    "            outputs[\"nodules_echo_size\"]=generate_output(model,test_data, test_attention,\"nodules_echo_size\",tokens=15,beams=1)\n",
    "        else:\n",
    "            outputs[\"nodules_echo_size\"]=generate_output(model,test_data, test_attention,\"nodules_echo_size\",tokens=15,beams=3)\n",
    "        \n",
    "    if \"nodules_echo_known\" in test_data:\n",
    "        outputs[\"nodules_echo_known\"]=generate_output(model,test_data, test_attention,\"nodules_echo_known\",tokens=6,beams=1)\n",
    "        \n",
    "    if \"nodules_echo_stable\" in test_data:\n",
    "        if low_beams:\n",
    "            outputs[\"nodules_echo_stable\"]=generate_output(model,test_data, test_attention,\"nodules_echo_stable\",tokens=6,beams=1)\n",
    "        else:\n",
    "            outputs[\"nodules_echo_stable\"]=generate_output(model,test_data, test_attention,\"nodules_echo_stable\",tokens=6,beams=3)\n",
    "        \n",
    "    text_out={}\n",
    "    for tipo in questions:\n",
    "        if tipo in outputs:\n",
    "            text_out[tipo]=tokenizer.batch_decode(outputs[tipo], skip_special_tokens=True)\n",
    "            # print(text_out[tipo])\n",
    "            # text_out[tipo]=[re.search(r\"Answer: (.+)\", texto).group(1) if re.search(r\"Answer: (.+)\", texto) else \"\" for texto in tokenizer.batch_decode(outputs[tipo], skip_special_tokens=True)]\n",
    "            print(f\"{tipo} outputs\")\n",
    "            print(text_out[tipo])\n",
    "            print(f\"{tipo} labels\")\n",
    "            print(test_label[tipo])\n",
    "            \n",
    "    \n",
    "    # # Mostrar los resultados finales\n",
    "    # print(text_out_age)\n",
    "    # print(test_label_age)\n",
    "\n",
    "    # print(text_out_tipo)\n",
    "    # print(test_label_tipo)\n",
    "\n",
    "    # print(text_out_tecnica)\n",
    "    # print(test_label_tecnica)\n",
    "\n",
    "    # print(text_out_history)\n",
    "    # print(test_label_history)\n",
    "    \n",
    "    \n",
    "   \n",
    "    # print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    \n",
    "    ind_fold={tipo: [key for key in ind if \"_\"+tipo in key] for tipo in questions}\n",
    "    \n",
    "    \n",
    "    for tipo in questions:\n",
    "        if tipo in text_out:\n",
    "            print(f\"{tipo} errors\")\n",
    "            # visualize_errors(valid_dataset[tipo],test_label[tipo],text_out[tipo],ind_fold[tipo])\n",
    "        else:\n",
    "            print(f\"{tipo} does not appear in this fold\")\n",
    "    \n",
    "\n",
    "\n",
    "            # Diccionario para almacenar accuracies por categoría\n",
    "    return test_label, text_out, ind_fold\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eca141-a2a3-45b2-a161-eaea49420383",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cargar modelo y tokenizador\n",
    "model_name = \"luqh/ClinicalT5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "inputs,targets = flatten_and_filter_dataset(ground_truth,report_data)  \n",
    "\n",
    "dataset_final=pd.DataFrame.from_dict(inputs,orient='index')\n",
    "targets=pd.DataFrame.from_dict(targets,orient='index')\n",
    "dataset_final.columns=[\"text\"]\n",
    "targets.columns=[\"label\"]\n",
    "test_label,text_out,ind_fold=generative_test(dataset_final, targets, model_name,low_beams=False)\n",
    "\n",
    "# Calcular accuracies por categoría\n",
    "output_dic={}\n",
    "output_dic_t={}\n",
    "for tipo in questions:\n",
    "    if tipo in text_out:\n",
    "        acc = accuracy_score(test_label[tipo], text_out[tipo])\n",
    "        \n",
    "        print(f\"Accuracy for {tipo}: {acc:.4f}\")\n",
    "        \n",
    "        output_dic_t[tipo]={ind:test_label[tipo][i] for i, ind in enumerate(ind_fold[tipo])}\n",
    "        # with open(f\"test_results/truth_dic/{tipo}.pkl\", \"wb\") as file:\n",
    "        #     pickle.dump(output_dic_t[tipo], file)\n",
    "        output_dic[tipo]={ind:text_out[tipo][i] for i, ind in enumerate(ind_fold[tipo])}\n",
    "\n",
    "for tipo in questions:\n",
    "    print(tipo)\n",
    "    with open(f\"test_results/results_dic_{tipo}/clinicalt5_tokenized.pkl\", \"wb\") as file:\n",
    "        pickle.dump(output_dic[tipo], file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0d3106-fb31-46f3-be9c-6284eb730d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dic.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e5102e-60a7-4683-b41e-21436ba94f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "questions=[\"tipo\",\"tecnica\",\"family\",\n",
    "           \"prosthesis\",\"birads\",\"density_mammo\",\"calcifications_benign\",\"ganglio_mamo\",\"density_echo\",\"lymph_benign\",\"lymph_suspicious\",\"simple_cyst\",\"ductal_ectasia\"]\n",
    "\n",
    "TIPO=[\"biopsy report\", \"nodal staging ultrasound report\", \"normal control or revision report\"]\n",
    "TECNICA=[\"only ultrasound study\", \"only mammography study\", \"mammography and ultrasound\"]\n",
    "FAMILY=[\"no family history\", \"first degree\", \"second degree\"]\n",
    "PROSTHESIS=[\"no prosthesis\",\"yes prosthesis\"]\n",
    "BIRADS=[\"BI-RADS 0\",\"BI-RADS 1\",\"BI-RADS 2\",\"BI-RADS 3\",\"BI-RADS 4A\",\"BI-RADS 4B\",\"BI-RADS 4C\",\"BI-RADS 5\",\"BI-RADS 6\"]\n",
    "DENSITY_MAMMO=[\"ACR A\",\"ACR B\",\"ACR C\",\"ACR D\",\"unknown density mammo\"]\n",
    "CALCIFICATIONS_BENIGN=[\"no calcifications\",\"yes calcifications\"]\n",
    "GANGLIO_MAMO=[\"no ganglio\",\"yes ganglio\"]\n",
    "DENSITY_ECHO=[\"homogeneous fibroglandular\",\"heterogeneous fibroglandular\",\"fibroglandular and fat\",\"homogeneous fatty\",\"unknown density echo\"]\n",
    "LYMPH_BENIGN=[\"no lymph benign\",\"yes lymph benign\"]\n",
    "LYMPH_SUSPICIOUS=[\"no lymph suspicious\",\"yes lymph suspicious\"]\n",
    "SIMPLE_CYST=[\"no cyst\",\"yes cyst\"]\n",
    "DUCTAL_ECTASIA=[\"no ectasia\",\"yes ectasia\"]\n",
    "NODULES_ECHO=[\"no nodules\", \"yes nodules\"]\n",
    "NODULES_SHAPE=[\"oval\",\"round\",\"lobulated\",\"irregular\",\"unknown shape\"]\n",
    "NODULES_MARGIN=[\"circumscribed\",\"spiculated\",\"indistinct\",\"not circumscribed\",\"unknown margin\"]\n",
    "NODULES_ECHOGENICITY=[\"hypoechoic\", \"isoechoic\", \"heterogeneous\",\"complex cystic and solid\",\"unknown echogenicity\"]\n",
    "NODULES_KNOWN=[\"no known\", \"yes known\"]\n",
    "NODULES_STABLE=[\"grown stable\",\"shrunk stable\", \"yes stable\"]\n",
    "\n",
    "\n",
    "TIPO.sort()\n",
    "TECNICA.sort()\n",
    "FAMILY.sort()\n",
    "PROSTHESIS.sort()\n",
    "BIRADS.sort()\n",
    "DENSITY_MAMMO.sort()\n",
    "CALCIFICATIONS_BENIGN.sort()\n",
    "GANGLIO_MAMO.sort()\n",
    "DENSITY_ECHO.sort()\n",
    "LYMPH_BENIGN.sort()\n",
    "SIMPLE_CYST.sort()\n",
    "DUCTAL_ECTASIA.sort()\n",
    "NODULES_ECHO.sort()\n",
    "NODULES_SHAPE.sort()\n",
    "NODULES_MARGIN.sort()\n",
    "NODULES_ECHOGENICITY.sort()\n",
    "NODULES_KNOWN.sort()\n",
    "NODULES_STABLE.sort()\n",
    "\n",
    "\n",
    "word_to_idx_tipo={word:idx for idx,word in enumerate(TIPO)}\n",
    "idx_to_word_tipo={idx:word for idx,word in enumerate(TIPO)}\n",
    "\n",
    "word_to_idx_tecnica={word:idx for idx,word in enumerate(TECNICA)}\n",
    "idx_to_word_tecnica={idx:word for idx,word in enumerate(TECNICA)}\n",
    "\n",
    "word_to_idx_family={word:idx for idx,word in enumerate(FAMILY)}\n",
    "idx_to_word_family={idx:word for idx,word in enumerate(FAMILY)}\n",
    "\n",
    "word_to_idx_prosthesis={word:idx for idx,word in enumerate(PROSTHESIS)}\n",
    "idx_to_word_prosthesis={idx:word for idx,word in enumerate(PROSTHESIS)}\n",
    "\n",
    "word_to_idx_birads={word:idx for idx,word in enumerate(BIRADS)}\n",
    "idx_to_word_birads={idx:word for idx,word in enumerate(BIRADS)}\n",
    "\n",
    "word_to_idx_density_mammo={word:idx for idx,word in enumerate(DENSITY_MAMMO)}\n",
    "idx_to_word_density_mammo={idx:word for idx,word in enumerate(DENSITY_MAMMO)}\n",
    "\n",
    "word_to_idx_calcifications_benign={word:idx for idx,word in enumerate(CALCIFICATIONS_BENIGN)}\n",
    "idx_to_word_calcifications_benign={idx:word for idx,word in enumerate(CALCIFICATIONS_BENIGN)}\n",
    "\n",
    "word_to_idx_ganglio_mamo={word:idx for idx,word in enumerate(GANGLIO_MAMO)}\n",
    "idx_to_word_ganglio_mamo={idx:word for idx,word in enumerate(GANGLIO_MAMO)}\n",
    "\n",
    "word_to_idx_density_echo={word:idx for idx,word in enumerate(DENSITY_ECHO)}\n",
    "idx_to_word_density_echo={idx:word for idx,word in enumerate(DENSITY_ECHO)}\n",
    "\n",
    "word_to_idx_lymph_benign={word:idx for idx,word in enumerate(LYMPH_BENIGN)}\n",
    "idx_to_word_lymph_benign={idx:word for idx,word in enumerate(LYMPH_BENIGN)}\n",
    "\n",
    "word_to_idx_lymph_suspicious={word:idx for idx,word in enumerate(LYMPH_SUSPICIOUS)}\n",
    "idx_to_word_lymph_suspicious={idx:word for idx,word in enumerate(LYMPH_SUSPICIOUS)}\n",
    "\n",
    "word_to_idx_simple_cyst={word:idx for idx,word in enumerate(SIMPLE_CYST)}\n",
    "idx_to_word_simple_cyst={idx:word for idx,word in enumerate(SIMPLE_CYST)}\n",
    "\n",
    "word_to_idx_ductal_ectasia={word:idx for idx,word in enumerate(DUCTAL_ECTASIA)}\n",
    "idx_to_word_ductal_ectasia={idx:word for idx,word in enumerate(DUCTAL_ECTASIA)}\n",
    "DICTIONARY={\"tipo\":TIPO,\"tecnica\":TECNICA,\"family\":FAMILY,\"prosthesis\":PROSTHESIS,\"birads\":BIRADS,\"density_mammo\":DENSITY_MAMMO,\"calcifications_benign\":CALCIFICATIONS_BENIGN,\n",
    "            \"ganglio_mamo\":GANGLIO_MAMO,\"density_echo\":DENSITY_ECHO,\"lymph_benign\":LYMPH_BENIGN,\"lymph_suspicious\":LYMPH_SUSPICIOUS,\"simple_cyst\":SIMPLE_CYST,\"ductal_ectasia\":DUCTAL_ECTASIA,\n",
    "           \"nodules_echo\": NODULES_ECHO,\"nodules_shape\":NODULES_SHAPE,\"nodules_margin\":NODULES_MARGIN, \"nodules_echogenicity\":NODULES_ECHOGENICITY, \"nodules_known\":NODULES_KNOWN, \"nodules_stable\":NODULES_STABLE}\n",
    "\n",
    "\n",
    "outputs=[]\n",
    "for tipo in DICTIONARY.values():\n",
    "    outputs+=tipo\n",
    "print(outputs)\n",
    "\n",
    "word_to_idx_out={word:idx for idx,word in enumerate(outputs)}\n",
    "idx_to_word_out={idx:word for idx,word in enumerate(outputs)}\n",
    "import gc\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def fix_brackets_spaces(texto):\n",
    "    ''' \n",
    "        Introduce espacios por delante y por detrás de los paréntesis.\n",
    "        Esta medida mejora el tokenizado de Spacy\n",
    "    '''\n",
    "    \n",
    "    texto = re.sub(r'([(\\[¿!])', r' \\1', texto)\n",
    "    texto = re.sub(r'([)\\]?¡])', r'\\1 ', texto)\n",
    "                \n",
    "    return texto\n",
    "    \n",
    "def preprocess_text(text):\n",
    "    text= fix_brackets_spaces(text)\n",
    "    # print(text)\n",
    "    \n",
    "    # print(text)\n",
    "    return text\n",
    "\n",
    "    \n",
    "def flatten_and_filter_dataset(ground_truth,reports):\n",
    "    \"\"\"\n",
    "    Esta función toma un conjunto de datos en el formato original (con estructura jerárquica)\n",
    "    y devuelve un conjunto de datos plano, donde cada entrada tiene un solo `context`, `question` y `answer`.\n",
    "    \n",
    "    Argumentos:\n",
    "        dataset: Un conjunto de datos en formato original (puede ser train, validation, test).\n",
    "    \n",
    "    Retorno:\n",
    "        Un conjunto de datos de Hugging Face en formato plano, con solo ejemplos completos.\n",
    "    \"\"\"\n",
    "    # Lista para almacenar ejemplos en formato plano\n",
    "    \n",
    "    j=0\n",
    "    flattened_examples = {}\n",
    "    examples_raw={}\n",
    "    targets={}\n",
    "    val_data={}\n",
    "    question_tipo={}\n",
    "    previous_message_answer_tipo={}\n",
    "    options_tipo={}\n",
    "    answers_tipo={}\n",
    "    j=0\n",
    "    \n",
    "    question_tipo[\"tipo\"]= 'is the following breast medical report a biopsy report or a nodal staging ultrasound report?'\n",
    "    previous_message_answer_tipo[\"tipo\"]=\"biopsy reports are Image-Guided Biopsy or Fine needle aspiration and is normally said that they are referred to the hospital for biopsy. Nodal staging ultrasound reports can also be written as 'axilla ultrasound'. If it is any of these it will be written in the beginning of the report, normally in the used technique. These kind of reports are only ultrasound.\"\n",
    "    \n",
    "\n",
    "    question_tipo[\"tecnica\"]= 'what diagnostic technique was used in the following breast medical report?'\n",
    "    previous_message_answer_tipo[\"tecnica\"]=\"biopsy reports, simple cysts and analysis of lymph or axillary nodes are only seen on ultrasound. On the other hand, if the ACR density is given or parenchymal distortions are analysed, the technique will be a mammogram. Tomosyntesis is a mammography type. The report may include an ultrasound examination, a mammography examination or both.\"\n",
    "    \n",
    "\n",
    "    question_tipo[\"family\"]= \"does the patient have any family history in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"family\"]=\"family history of breast cancer is categorized based on the degree of relatives affected: First-degree relatives: Parents, siblings, or children. Second-degree relatives: Grandparents, aunts, uncles, nieces, nephews, or half-siblings. Third-degree relatives: Great-grandparents, great-aunts/uncles, or first cousins.\"\n",
    "    \n",
    "    question_tipo[\"prosthesis\"]= \"does the patient have a prosthesis in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"prosthesis\"]=\"it is normally clearly indicated at the beginning of the report. Sometimes it is written as implants instead of prosthesis.\"\n",
    "    \n",
    "    question_tipo[\"birads\"]= \"what is the final BI-RADS classification given to the patient in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"birads\"]=\"the final BI-RADS of the patient is given in the conclusions of the report, normally at the end.\"\n",
    "\n",
    "    question_tipo[\"density_mammo\"]= \"what is the breast density found in the mammography study of the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"density_mammo\"]=\"breast density in mammography is classified into four categories: ACR A (= Almost entirely fatty), ACR B (= Scattered areas of fibroglandular density), ACR C (= Heterogeneously dense), ACR D (= Extremely or very dense breasts). Sometimes it is written as 'density type x' or with their real meaning (very dense breasts = C).\"\n",
    "       \n",
    "    question_tipo[\"density_echo\"]= \"what is the breast density found in the ultrasound study of the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"density_echo\"]=\"breast composition in ultrasound is classified into four categories: fibroglandular and fat (mixed distribution of fibroglandular and adipose tissue), heterogeneous fibroglandular (predominantly fibroglandular tissue with varying echogenicity and scattered fat areas), homogeneous fatty (uniform fatty tissue with consistent echogenicity and minimal fibroglandular content), and homogeneous fibroglandular (uniform fibroglandular tissue with consistent echogenicity and minimal fat content).\"\n",
    "    \n",
    "    question_tipo[\"calcifications_benign\"]= \"does the following breast medical report mention the appearence of benign calcifications in the mammography exam?\"\n",
    "    previous_message_answer_tipo[\"calcifications_benign\"]=\"Consider only benign calcifications in the mammography.\"\n",
    "      \n",
    "    question_tipo[\"ganglio_mamo\"]= \"does the following breast medical report mention any lymph nodes in the mammography exam?\"\n",
    "    previous_message_answer_tipo[\"ganglio_mamo\"]=\"Consider only lymph nodes that appear in the mammography.\"\n",
    "    \n",
    "    question_tipo[\"lymph_suspicious\"]= \"does the following breast medical report mention any suspicious axillary lymph nodes in the ultrasound exam?\"\n",
    "    previous_message_answer_tipo[\"lymph_suspicious\"]=\"if a lymph node is suspicious the report will recomend a biopsy or Fine Needle Aspiration. A lymph node is considered suspicious when it has eccentric cortical thickening ≥ 3 mm, Short axis >10 mm, round shape, loss of fatty hilum, abnormal vascularity, or irregular margins—especially when associated with known malignancy or progressive enlargement. They can also be classified as UN3, UN4 or UN5. An exam may have both suspicious and benign lymph nodes.\"\n",
    "\n",
    "    question_tipo[\"lymph_benign\"]= \"does the following breast medical report mention any benign or not suspicious axillary lymph nodes in the ultrasound exam?\"\n",
    "    previous_message_answer_tipo[\"lymph_benign\"]=\"if a lymph node is suspicious the report will recomend a biopsy or Fine Needle Aspiration. A lymph node is considered benign when it has uniform cortex < 3 mm, preserved fatty hilum, oval shape, no abnormal vascularity, no irregular margins and homogeneous internal echo pattern. Benign axillary nodes can be classified as UN1 or UN2. A reactive axillary node is not suspicious. An exam may have both suspicious and benign lymph nodes.\"\n",
    "    \n",
    "    question_tipo[\"simple_cyst\"]= \"does the following breast medical report mention any simple cysts or microcysts in the ultrasound exam?\"\n",
    "    previous_message_answer_tipo[\"simple_cyst\"]=\"The words symple cysts or microcysts will appear only in the ultrasound exam. Sometimes they can say that some of the cysts have echogenic content, but we still will consider them simple cysts and not nodules.\"\n",
    "    \n",
    "    question_tipo[\"ductal_ectasia\"]= \"does the following breast medical report mention any ductal ectasia in the ultrasound exam?\"\n",
    "    previous_message_answer_tipo[\"ductal_ectasia\"]=\"The word ductal ectasia will appear only in the ultrasound exam.\"\n",
    "\n",
    "    question_tipo[\"nodules_echo\"]= \"is there any nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"nodules_echo\"]=\"The localization, echogenicity and size of the nodules are normally said.\"\n",
    "    \n",
    "    question_tipo[\"nodules_shape\"]= \"what is the shape of the first nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"nodules_shape\"]=\"Shapes can be 'oval', 'round', 'lobulated' and 'irregular'. Sometimes irregular is also used for the margin, but in this case it is written as 'irregular margin' or 'irregular borders'. \"\n",
    "    \n",
    "    question_tipo[\"nodules_margin\"]= \"what is the margin of the first nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"nodules_margin\"]=\"Margin can be 'circumscribed' and 'not circumscribed'. Inside the not circumscribed we have 'spiculated', 'angulated', 'microlobulated' or 'indistinc' ('not defined') margins. Sometimes irregular is also used for the margin, but in this case it is written as 'irregular margin' or 'irregular borders', in this case classify it as 'not circumscribed'.\"\n",
    "    \n",
    "    question_tipo[\"nodules_echogenicity\"]= \"what is the echogenicity of the first nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"nodules_echogenicity\"]=\"Echogenicity can be 'anechoic', 'hypoechoic', 'heterogeneous' and 'complex cystic and solid'.\" \n",
    "    \n",
    "    question_tipo[\"nodules_known\"]= \"is the first nodule described in the ultrasound exam of the following breast medical report previously known?\"\n",
    "    previous_message_answer_tipo[\"nodules_known\"]=\"If the nodule is known from before the report, it will say if it it is stable or if it has grown or shrink.\"\n",
    "    \n",
    "    question_tipo[\"nodules_stable\"]= \"is the first known nodule described in the ultrasound exam stable in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"nodules_stable\"]=\"If the nodule is known from before the examination, it will be analysed to see if it is stable or if it got bigger or smaller. \"\n",
    "    \n",
    "    for i, report in enumerate(reports[\"informes_ingles\"]):\n",
    "        informe=preprocess_text(report)\n",
    "        key=reports[\"keys\"][i]\n",
    "        \n",
    "        if key not in ground_truth.index:\n",
    "            continue\n",
    "        if key in flattened_examples:\n",
    "            continue\n",
    "\n",
    "        n_tipo=np.zeros(len(outputs))\n",
    "        n_tecnica=np.zeros(len(outputs))\n",
    "        n_family=np.zeros(len(outputs))\n",
    "        n_prosthesis=np.zeros(len(outputs))\n",
    "        n_birads=np.zeros(len(outputs))\n",
    "        n_density_mammo=np.zeros(len(outputs))\n",
    "        n_calcifications_benign=np.zeros(len(outputs))\n",
    "        n_ganglio_mamo=np.zeros(len(outputs))\n",
    "        n_density_echo=np.zeros(len(outputs))\n",
    "        n_lymph_benign=np.zeros(len(outputs))\n",
    "        n_lymph_suspicious=np.zeros(len(outputs))\n",
    "        n_simple_cyst=np.zeros(len(outputs))\n",
    "        n_ductal_ectasia=np.zeros(len(outputs))\n",
    "        n_nodules_echo=np.zeros(len(outputs))\n",
    "        n_nodules_shape=np.zeros(len(outputs))\n",
    "        n_nodules_margin=np.zeros(len(outputs))\n",
    "        n_nodules_echogenicity=np.zeros(len(outputs))\n",
    "        n_nodules_known=np.zeros(len(outputs))\n",
    "        n_nodules_stable=np.zeros(len(outputs))\n",
    "        row=ground_truth.loc[key]\n",
    "        answer_tipo={}\n",
    "        #TIPO\n",
    "        normal_control=False\n",
    "        if row[\"Biopsy_report\"].lower()==\"yes\":\n",
    "            n_tipo[word_to_idx_out[\"biopsy report\"]]=1\n",
    "            \n",
    "        elif row[\"Ganglio_report\"].lower()==\"yes\":\n",
    "            n_tipo[word_to_idx_out[\"nodal staging ultrasound report\"]]=1\n",
    "        else:\n",
    "            normal_control=True\n",
    "            n_tipo[word_to_idx_out[\"normal control or revision report\"]]=1\n",
    "        answer_tipo[\"tipo\"]=n_tipo\n",
    "        #TECHNIQUE\n",
    "        tecnica=row[\"Technique\"]\n",
    "        # Verificar si el ejemplo tiene preguntas\n",
    "        if tecnica==\"only ultrasound study\":\n",
    "            n_tecnica[word_to_idx_out[\"only ultrasound study\"]]=1          \n",
    "        elif tecnica==\"only mammography mammography\":\n",
    "            n_tecnica[word_to_idx_out[\"only mammography study\"]]=1\n",
    "        elif not pd.isna(tecnica):\n",
    "            n_tecnica[word_to_idx_out[tecnica]]=1\n",
    "        else:\n",
    "            print(key,report)\n",
    "        answer_tipo[\"tecnica\"]=n_tecnica\n",
    "        # \n",
    "        # HISTORY\n",
    "        #No consideramos las biopsias o las ecografías de estadificación ganglionar.\n",
    "        if normal_control:\n",
    "            \n",
    "            family=row[\"Family_history\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(family,str) or family.lower()==\"no\":\n",
    "                n_family[word_to_idx_out[\"no family history\"]]=1 \n",
    "                answer_tipo[\"family\"]=n_family\n",
    "            elif family not in word_to_idx_out:\n",
    "                n_family[word_to_idx_out[\"no family history\"]]=1\n",
    "                \n",
    "            else:\n",
    "                n_family[word_to_idx_out[family]]=1\n",
    "                answer_tipo[\"family\"]=n_family\n",
    "                \n",
    "            # PROSTHESIS\n",
    "            prosthesis=row[\"Prosthesis\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(prosthesis,str) or prosthesis.lower()==\"no\":\n",
    "                n_prosthesis[word_to_idx_out[\"no prosthesis\"]]=1        \n",
    "            else:\n",
    "                n_prosthesis[word_to_idx_out[\"yes prosthesis\"]]=1\n",
    "            answer_tipo[\"prosthesis\"]=n_prosthesis\n",
    "            #BIRADS\n",
    "            birads=row[\"BI-RADS\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(birads,str) or birads==\"unknown\":\n",
    "                n_birads[word_to_idx_out[\"unknown BI-RADS\"]]=1           \n",
    "            else:\n",
    "                n_birads[word_to_idx_out[birads]]=1\n",
    "            answer_tipo[\"birads\"]=n_birads\n",
    "            #Density mammo\n",
    "            density_mammo=row[\"Density_mamo\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(density_mammo,str) or density_mammo not in DENSITY_MAMMO:\n",
    "                n_density_mammo[word_to_idx_out[\"unknown density mammo\"]]=1       \n",
    "            else:\n",
    "                n_density_mammo[word_to_idx_out[density_mammo]]=1\n",
    "            answer_tipo[\"density_mammo\"]=n_density_mammo\n",
    "            #Lymp nodes mammo\n",
    "            ganglio_mamo=row[\"Ganglio_mamo\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(ganglio_mamo,str):\n",
    "                n_ganglio_mamo[word_to_idx_out[\"no ganglio\"]]=1            \n",
    "            else:\n",
    "                n_ganglio_mamo[word_to_idx_out[ganglio_mamo.lower()+\" ganglio\"]]=1\n",
    "            answer_tipo[\"ganglio_mamo\"]=n_ganglio_mamo\n",
    "            #Calcifications benign\n",
    "            calcifications_benign=row[\"Calcifications_benign_mamo\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(calcifications_benign,str):\n",
    "                n_calcifications_benign[word_to_idx_out[\"no calcifications\"]]=1       \n",
    "            else:\n",
    "                n_calcifications_benign[word_to_idx_out[calcifications_benign.lower()+ \" calcifications\"]]=1\n",
    "            answer_tipo[\"calcifications_benign\"]=n_calcifications_benign\n",
    "        \n",
    "    \n",
    "            #Density echo\n",
    "            density_echo=row[\"Density_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(density_echo,str)or density_echo not in DENSITY_ECHO:\n",
    "                n_density_echo[word_to_idx_out[\"unknown density echo\"]]=1         \n",
    "            else:\n",
    "                n_density_echo[word_to_idx_out[density_echo]]=1\n",
    "            answer_tipo[\"density_echo\"]=n_density_echo\n",
    "            #Benign lymph nodes\n",
    "            simple_cyst=row[\"simple_cyst_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(simple_cyst,str):\n",
    "                n_simple_cyst[word_to_idx_out[\"no cyst\"]]=1         \n",
    "            else:\n",
    "                n_simple_cyst[word_to_idx_out[simple_cyst.lower()+\" cyst\"]]=1\n",
    "\n",
    "            answer_tipo[\"simple_cyst\"]=n_simple_cyst\n",
    "            #Suspicious lymph nodes\n",
    "            lymph_suspicious=row[\"Ganglio_suspicious_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(lymph_suspicious,str):\n",
    "                n_lymph_suspicious[word_to_idx_out[\"no lymph suspicious\"]]=1         \n",
    "            else:\n",
    "                n_lymph_suspicious[word_to_idx_out[lymph_suspicious.lower()+ \" lymph suspicious\"]]=1\n",
    "            answer_tipo[\"lymph_suspicious\"]=n_lymph_suspicious\n",
    "            #Benign lymph nodes\n",
    "            lymph_benign=row[\"Ganglio_benign_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            \n",
    "            if not isinstance(lymph_benign,str):\n",
    "                n_lymph_benign[word_to_idx_out[\"no lymph benign\"]]=1           \n",
    "            else:\n",
    "                n_lymph_benign[word_to_idx_out[lymph_benign.lower()+ \" lymph benign\"]]=1\n",
    "            answer_tipo[\"lymph_benign\"]=n_lymph_benign\n",
    "            #Ductal ectasia\n",
    "            ductal_ectasia=row[\"Ductal_ectasia_eco\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(ductal_ectasia,str):\n",
    "                n_ductal_ectasia[word_to_idx_out[\"no ectasia\"]]=1    \n",
    "            else:\n",
    "                n_ductal_ectasia[word_to_idx_out[ductal_ectasia.lower()+\" ectasia\"]]=1\n",
    "            answer_tipo[\"ductal_ectasia\"]=n_ductal_ectasia\n",
    "\n",
    "            nodules_echo=row[\"Nodules_eco\"]\n",
    "            nodules_bool=False\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(nodules_echo,str) and not isinstance(nodules_echo,int):\n",
    "                n_nodules_echo[word_to_idx_out[\"no nodules\"]]=1\n",
    "            elif isinstance(nodules_echo,str) and nodules_echo.lower()==\"no\":\n",
    "                n_nodules_echo[word_to_idx_out[\"no nodules\"]]=1\n",
    "            else:\n",
    "                nodules_bool=True\n",
    "                n_nodules_echo[word_to_idx_out[\"yes nodules\"]]=1\n",
    "            answer_tipo[\"nodules_echo\"]=n_nodules_echo\n",
    "            if nodules_bool:\n",
    "                #Density echo\n",
    "                nodules_shape=row[\"Shape_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_shape,str)or nodules_shape not in NODULES_SHAPE:\n",
    "                    n_nodules_shape[word_to_idx_out[\"unknown shape\"]]=1         \n",
    "                else:\n",
    "                    n_nodules_shape[word_to_idx_out[nodules_shape]]=1\n",
    "                answer_tipo[\"nodules_shape\"]=n_nodules_shape\n",
    "\n",
    "                nodules_margin=row[\"Margin_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_margin,str)or nodules_margin not in NODULES_MARGIN:\n",
    "                    n_nodules_margin[word_to_idx_out[\"unknown margin\"]]=1         \n",
    "                else:\n",
    "                    n_nodules_margin[word_to_idx_out[nodules_margin]]=1\n",
    "                answer_tipo[\"nodules_margin\"]=n_nodules_margin\n",
    "\n",
    "                nodules_echogenicity=row[\"Echogenicity_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_echogenicity,str)or nodules_echogenicity not in NODULES_ECHOGENICITY:\n",
    "                    n_nodules_echogenicity[word_to_idx_out[\"unknown echogenicity\"]]=1         \n",
    "                else:\n",
    "                    n_nodules_echogenicity[word_to_idx_out[nodules_echogenicity]]=1\n",
    "                answer_tipo[\"nodules_echogenicity\"]=n_nodules_echogenicity\n",
    "\n",
    "                #Nodules echo known\n",
    "                nodules_known=row[\"new_eco_1\"]\n",
    "                known_bool=False\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_known,str):\n",
    "                    n_nodules_known[word_to_idx_out[\"unknown known\"]]=1\n",
    "                elif nodules_known.lower()==\"no\":\n",
    "                    known_bool=True\n",
    "                    n_nodules_known[word_to_idx_out[\"yes known\"]]=1    \n",
    "                else:\n",
    "                    n_nodules_known[word_to_idx_out[\"no known\"]]=1\n",
    "                answer_tipo[\"nodules_known\"]=n_nodules_known\n",
    "                if known_bool:\n",
    "                    #Nodules echo stable\n",
    "                    nodules_stable=row[\"Stable_eco_1\"]\n",
    "                    # Verificar si el ejemplo tiene preguntas\n",
    "                    if not isinstance(nodules_stable,str):\n",
    "                        n_nodules_stable[word_to_idx_out[\"unknown stable\"]]=1\n",
    "                    else:\n",
    "                        n_nodules_stable[word_to_idx_out[nodules_stable.lower()+\" stable\"]]=1\n",
    "                    answer_tipo[\"nodules_stable\"]=n_nodules_stable\n",
    "\n",
    "                \n",
    "                \n",
    "\n",
    "        for tipo in answer_tipo:\n",
    "            #Si está el tipo en las respuestas que hemos recogido lo metemos a la base de datos.\n",
    "            key_tipo=key+\"_\"+tipo\n",
    "            if key_tipo in flattened_examples:\n",
    "                continue\n",
    "                key_tipo=key_tipo+\"_copy\"\n",
    "            examples_raw[key_tipo]=report\n",
    "            answer=answer_tipo[tipo]\n",
    "            \n",
    "    \n",
    "            inputs_tipo = \"Question: \" + question_tipo[tipo] +\" Extra information: \"+ previous_message_answer_tipo[tipo]+ \" Context: \" + informe\n",
    "            flattened_examples[key_tipo]=inputs_tipo\n",
    "            targets[key_tipo]=int(np.argmax(answer))\n",
    "    return flattened_examples,targets\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def visualize_errors(valid_dataset,valid_targets,validation_predictions,keys):\n",
    "    # Crear un DataFrame con los textos originales, las etiquetas reales y las predicciones\n",
    "    results_df = pd.DataFrame({\n",
    "        'key':list(keys),\n",
    "        'Text': list(valid_dataset),  # Usamos los textos originales\n",
    "        'True Label': list(valid_targets),\n",
    "        'Predicted Label': list(validation_predictions)\n",
    "    })\n",
    "    \n",
    "    # Filtrar los ejemplos en los que el modelo falló\n",
    "    errors_df = results_df[results_df['True Label'] != results_df['Predicted Label']]\n",
    "    \n",
    "    for ind,row in errors_df.iterrows():\n",
    "        print(row[\"key\"])\n",
    "        print(\"EJEMPLO\")\n",
    "        print(row[\"Text\"])\n",
    "        print(\"PREDICTED\")\n",
    "        print(idx_to_word_out[row[\"Predicted Label\"]])\n",
    "        print(\"TRUE\")\n",
    "        print(idx_to_word_out[row[\"True Label\"]])\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name_original)\n",
    "    texts = examples[\"text\"]\n",
    "    \n",
    "    outputs = tokenizer(\n",
    "        texts,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "    # Verificar truncación\n",
    "    for i, text in enumerate(texts):\n",
    "        untruncated = tokenizer(\n",
    "            text,\n",
    "            truncation=False,\n",
    "            add_special_tokens=True\n",
    "        )\n",
    "        if len(untruncated[\"input_ids\"]) > 512:\n",
    "            print(\"⚠️ Truncation occurred!\")\n",
    "            print(f\"Original length: {len(untruncated['input_ids'])}, Truncated to: 512\")\n",
    "            print(\"Sample text:\", text[:200], \"...\\n\")\n",
    "\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def evaluate_per_question(predicted, tested, DICTIONARY):\n",
    "    \"\"\"\n",
    "    Evaluate model predictions per question type.\n",
    "    \n",
    "    Parameters:\n",
    "    - predicted: array of predicted label indices (flattened from all folds)\n",
    "    - tested: array of true label indices (same shape as predicted)\n",
    "    - DICTIONARY: dict mapping each question to its list of class names\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Build global index → (question, class_name) mapping\n",
    "    idx_to_question_value = {}\n",
    "    offset = 0\n",
    "    question_offsets = {}\n",
    "    for question, class_list in DICTIONARY.items():\n",
    "        question_offsets[question] = offset\n",
    "        for i, label in enumerate(class_list):\n",
    "            idx_to_question_value[offset + i] = (question, label)\n",
    "        offset += len(class_list)\n",
    "\n",
    "    # Step 2: Group predictions by question\n",
    "    per_question_true = defaultdict(list)\n",
    "    per_question_pred = defaultdict(list)\n",
    "\n",
    "    for true_idx, pred_idx in zip(tested, predicted):\n",
    "        q_true, _ = idx_to_question_value[true_idx]\n",
    "        # You can check if q_true == q_pred here for safety if needed\n",
    "        per_question_true[q_true].append(true_idx)\n",
    "        per_question_pred[q_true].append(pred_idx)\n",
    "\n",
    "    # Step 3: Classification reports\n",
    "    print(\"\\n🔍 Per-question classification reports:\\n\")\n",
    "    for question, true_labels in per_question_true.items():\n",
    "        pred_labels = per_question_pred[question]\n",
    "        label_names = DICTIONARY[question]\n",
    "        start = question_offsets[question]\n",
    "        end = start + len(label_names)\n",
    "        question_label_ids = list(range(start, end))\n",
    "\n",
    "        print(f\"\\n📘 Question: {question}\")\n",
    "        try:\n",
    "            print(classification_report(true_labels, pred_labels, labels=question_label_ids, target_names=label_names))\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Could not generate report for '{question}': {e}\")\n",
    "\n",
    "    print(\"\\n📊 Accuracy per class and per question:\\n\")\n",
    "    for question in DICTIONARY:\n",
    "        y_true = np.array(per_question_true[question])\n",
    "        y_pred = np.array(per_question_pred[question])\n",
    "        class_list = DICTIONARY[question]\n",
    "        start = question_offsets[question]\n",
    "    \n",
    "        if len(y_true) == 0:\n",
    "            print(f\"\\n❌ {question}: [No data]\")\n",
    "            continue\n",
    "    \n",
    "        print(f\"\\n✅ Accuracy for: {question}\")\n",
    "        # Per-class accuracy\n",
    "        for i, class_name in enumerate(class_list):\n",
    "            global_idx = start + i\n",
    "            mask = y_true == global_idx\n",
    "            if mask.sum() == 0:\n",
    "                print(f\"  {class_name}: [No samples]\")\n",
    "                continue\n",
    "            acc = accuracy_score(y_true[mask], y_pred[mask])\n",
    "            print(f\"  {class_name}: {acc:.4f}\")\n",
    "        \n",
    "        # Overall accuracy for the question\n",
    "        overall_acc = accuracy_score(y_true, y_pred)\n",
    "        print(f\"🎯 Overall accuracy: {overall_acc:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "def cross_validation(X,Y,save_name):\n",
    "\n",
    "    test=X\n",
    "    test_y=Y.loc[test.index]\n",
    "    test[\"label\"]=test_y[\"label\"]\n",
    "    print(test)\n",
    "    \n",
    "    test.columns=[\"text\",\"label\"]\n",
    "    print(test)\n",
    "    ind=list(test.index)\n",
    "    \n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=64 # Cambia según tus clases\n",
    "    )\n",
    "    \n",
    "    test_data=Dataset.from_pandas(test)\n",
    "    \n",
    "    test_data = test_data.map(tokenize_function, batched=True)\n",
    "    test_data = test_data.rename_column(\"label\", \"labels\")\n",
    "    test_data = test_data.remove_columns([\"text\"])\n",
    "    test_data.set_format(\"torch\")\n",
    "    \n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        )\n",
    "    pred = trainer.predict(test_data)\n",
    "    outputs=pred.predictions.argmax(axis=-1)\n",
    "    print(outputs)\n",
    "    accuracy = accuracy_score(test[\"label\"], outputs)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(test[\"label\"], outputs))\n",
    "    evaluate_per_question(outputs, test[\"label\"], DICTIONARY)\n",
    "    # valid_dataset=[report for key,report in examples_raw.items() if key in ind]\n",
    "    # visualize_errors(valid_dataset,np.array(test[\"label\"]).squeeze(),outputs,ind)\n",
    "    \n",
    "    \n",
    "    \n",
    "    np.save(f\"test_results/predicted_{save_name}.npy\", outputs)\n",
    "    np.save(f\"test_results/tested_{save_name}.npy\", test[\"label\"].values)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89a1d6a-3821-4d5c-9f28-6885eaa22d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs,targets = flatten_and_filter_dataset(ground_truth,report_data)   \n",
    "\n",
    "dataset_final=pd.DataFrame.from_dict(inputs,orient='index')\n",
    "targets=pd.DataFrame.from_dict(targets,orient='index')\n",
    "dataset_final.columns=[\"text\"]\n",
    "targets.columns=[\"label\"]\n",
    "\n",
    "\n",
    "model_name_original=\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\"\n",
    "model_name=f\"results/{model_name_original}_model_final_classification\"\n",
    "\n",
    "save_name=\"biomed_classification\"\n",
    "\n",
    "cross_validation(dataset_final,targets,save_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a42cb76-e980-4b7f-b078-1d9eb6187672",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs,targets = flatten_and_filter_dataset(ground_truth,report_data)   \n",
    "\n",
    "dataset_final=pd.DataFrame.from_dict(inputs,orient='index')\n",
    "targets=pd.DataFrame.from_dict(targets,orient='index')\n",
    "dataset_final.columns=[\"text\"]\n",
    "targets.columns=[\"label\"]\n",
    "\n",
    "\n",
    "model_name_original=\"dmis-lab/biobert-base-cased-v1.1\"\n",
    "model_name=f\"results/{model_name_original}_model_final_classification\"\n",
    "\n",
    "save_name=\"biobert_classification\"\n",
    "\n",
    "cross_validation(dataset_final,targets,save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a189ef-f9f8-4d73-9dcd-731c2af27b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs,targets = flatten_and_filter_dataset(ground_truth,report_data)   \n",
    "\n",
    "dataset_final=pd.DataFrame.from_dict(inputs,orient='index')\n",
    "targets=pd.DataFrame.from_dict(targets,orient='index')\n",
    "dataset_final.columns=[\"text\"]\n",
    "targets.columns=[\"label\"]\n",
    "\n",
    "\n",
    "model_name_original=\"bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12\"\n",
    "model_name=f\"results/{model_name_original}_model_final_classification\"\n",
    "\n",
    "save_name=\"bluebert_classification\"\n",
    "\n",
    "cross_validation(dataset_final,targets,save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff7d057-989c-4284-b81e-f88f630f4330",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import numpy as np\n",
    "import gc\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "questions=[\"age\",\"history\",\"parenchymal_distortion\",\"nodules_echo_size\"]\n",
    "\n",
    "def flatten_and_filter_dataset(ground_truth,reports):\n",
    "    \"\"\"\n",
    "    Esta función toma un conjunto de datos en el formato original (con estructura jerárquica)\n",
    "    y devuelve un conjunto de datos plano, donde cada entrada tiene un solo `context`, `question` y `answer`.\n",
    "    \n",
    "    Argumentos:\n",
    "        dataset: Un conjunto de datos en formato original (puede ser train, validation, test).\n",
    "    \n",
    "    Retorno:\n",
    "        Un conjunto de datos de Hugging Face en formato plano, con solo ejemplos completos.\n",
    "    \"\"\"\n",
    "    # Lista para almacenar ejemplos en formato plano\n",
    "    flattened_examples = {}\n",
    "    examples_raw={}\n",
    "    targets={}\n",
    "    questions_examples={}\n",
    "    val_data={}\n",
    "    question_tipo={}\n",
    "    previous_message_answer_tipo={}\n",
    "    options_tipo={}\n",
    "    answers_tipo={}\n",
    "    j=0\n",
    "    \n",
    "    question_tipo[\"age\"]= \"does the patient's age appear in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"age\"]=\"search for numbers, but do not mistake it with the age of a familiar. If a number appears without any context between two dots it is surely the age.\"\n",
    "    \n",
    "\n",
    "    question_tipo[\"history\"]= \"does the patient have any non-familiar history in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"history\"]=\"check for the history at the beginning of the report. Normally it is a previous biopsy result, mastectomy or cancer. It normally starts with 'history of ...'.\"\n",
    "\n",
    "    question_tipo[\"parenchymal_distortion\"]= \"does the following breast medical report mention any parenchymal distortion or asymmetry in the mammography exam?\"\n",
    "    previous_message_answer_tipo[\"parenchymal_distortion\"]=\"If it has any it will appear in the results of the mammography exam using the words distortion, asymmetry or sometimes it can also be surgical changes.\"\n",
    "    \n",
    "\n",
    "    # question_tipo[\"nodules_echo_location_1\"]= \"In which location is the first nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "    # previous_message_answer_tipo[\"nodules_echo_location_1\"]=\"do not consider if a nodule is described in the mammography exam or if it is in the axilla. If the nodule is mentioned previously in the mammography, the location can be found also there. sometimes the breast location of the tumour may be written in a different part than the quadrant. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "    \n",
    "    \n",
    "    question_tipo[\"nodules_echo_size_1\"]= \"what is the size of the first nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"nodules_echo_size_1\"]=\"do not consider if a nodule is described in the mammography exam. The localization, echogenicity and size of the nodules are normally said. More than one nodule can be described simultaneously ('several', 'two', 'three', etc.). If the number is unspecified, only the ones with size will be considered. Sometimes it can also say 'similar characteristics' or 'similar to the previous', consider in this case the answer to the previous tumour.\"\n",
    "    \n",
    "    # Iterar sobre cada ejemplo en el conjunto de datos original\n",
    "    for i, report in enumerate(reports[\"informes_ingles\"]):\n",
    "        informe=report\n",
    "        key=reports[\"keys\"][i]\n",
    "        \n",
    "        if key not in ground_truth.index:\n",
    "            continue\n",
    "        answer_tipo={}\n",
    "        row=ground_truth.loc[key]\n",
    "        age=str(row[\"Age\"])\n",
    "        # Verificar si el ejemplo tiene preguntas\n",
    "        if age.isdigit():\n",
    "            answer_tipo[\"age\"]=age\n",
    "            \n",
    "        else:\n",
    "            answer_tipo[\"age\"]=\"no response\"\n",
    "\n",
    "        if row[\"Biopsy_report\"].lower()!=\"yes\" and row[\"Ganglio_report\"].lower()!=\"yes\":\n",
    "            history=row[\"Other_history\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(history,str) or history.lower()==\"no\" or history.lower()==\"no history was found\":\n",
    "                answer_tipo[\"history\"]=\"no response\"           \n",
    "            else:\n",
    "                answer_tipo[\"history\"]=history\n",
    "\n",
    "\n",
    "            #Parenchymal distortion\n",
    "            parenchymal_distortion=row[\"parenchymal_distortions_asymmetry\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(parenchymal_distortion,str) or parenchymal_distortion.lower()==\"no\":\n",
    "                answer_tipo[\"parenchymal_distortion\"]=\"no response\"        \n",
    "            else:\n",
    "                answer_tipo[\"parenchymal_distortion\"]=parenchymal_distortion.lower()\n",
    "\n",
    "            #Nodules echo\n",
    "            nodules_echo_num=row[\"Nodules_eco\"]\n",
    "            \n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(nodules_echo_num,str) and not isinstance(nodules_echo_num,int):\n",
    "                nodules=False\n",
    "            elif isinstance(nodules_echo_num,str) and nodules_echo_num.lower()==\"no\":\n",
    "                nodules=False\n",
    "            else:\n",
    "                nodules=True\n",
    "            if nodules:\n",
    "                # nodules_echo_location=row[\"Location_eco_1\"]\n",
    "                # # Verificar si el ejemplo tiene preguntas\n",
    "                # if not isinstance(nodules_echo_location,str):\n",
    "                #     answer_tipo[\"nodules_echo_location_1\"]=\"no response\"\n",
    "                # else:\n",
    "                #     answer_tipo[\"nodules_echo_location_1\"]=nodules_echo_location.lower()\n",
    "                #Nodules echo size\n",
    "                nodules_echo_size=row[\"size_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_echo_size,str) or nodules_echo_size==\"unknown\":\n",
    "                    answer_tipo[\"nodules_echo_size_1\"]=\"no response\"         \n",
    "                else:\n",
    "                    answer_tipo[\"nodules_echo_size_1\"]=nodules_echo_size\n",
    "                \n",
    "\n",
    "            \n",
    "        for tipo in answer_tipo:\n",
    "            #Si está el tipo en las respuestas que hemos recogido lo metemos a la base de datos.\n",
    "            key_tipo=key+\"_\"+tipo\n",
    "            if key_tipo in flattened_examples:\n",
    "                continue\n",
    "                key_tipo=key_tipo+\"_copy\"\n",
    "            examples_raw[key_tipo]=report\n",
    "            answer=str(answer_tipo[tipo])\n",
    "            \n",
    "            questions_examples[key_tipo]=question_tipo[tipo]\n",
    "            inputs_tipo = \" Additional information: \"+ previous_message_answer_tipo[tipo]+ \" Context: \" + informe\n",
    "            flattened_examples[key_tipo]=inputs_tipo\n",
    "            targets[key_tipo]=answer.strip()\n",
    "        \n",
    "        \n",
    "        \n",
    "        # if answer==word_to_idx_out[\"other\"]:\n",
    "        #     for j in range(2):\n",
    "        #         examples_raw[key+\"_copy\"+str(j)]=report\n",
    "        #         flattened_examples[key+\"_copy\"+str(j)]=informe\n",
    "        #         targets[key+\"_copy\"+str(j)]=answer\n",
    "            \n",
    "        \n",
    "            \n",
    "        \n",
    "    # flattened_examples=pd.DataFrame.from_dict(flattened_examples,orient='index')\n",
    "    # targets=pd.DataFrame.from_dict(targets,orient='index')\n",
    "    return flattened_examples,questions_examples,targets,examples_raw\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def visualize_errors(valid_dataset,valid_targets,validation_predictions,keys):\n",
    "    # Crear un DataFrame con los textos originales, las etiquetas reales y las predicciones\n",
    "    results_df = pd.DataFrame({\n",
    "        'key':list(keys),\n",
    "        'Text': list(valid_dataset),  # Usamos los textos originales\n",
    "        'True Label': list(valid_targets),\n",
    "        'Predicted Label': list(validation_predictions)\n",
    "    })\n",
    "    \n",
    "    # Filtrar los ejemplos en los que el modelo falló\n",
    "    errors_df = results_df[results_df['True Label'] != results_df['Predicted Label']]\n",
    "    \n",
    "    for ind,row in errors_df.iterrows():\n",
    "        print(row[\"key\"])\n",
    "        print(\"EJEMPLO\")\n",
    "        print(row[\"Text\"])\n",
    "        print(\"PREDICTED\")\n",
    "        print(row[\"Predicted Label\"])\n",
    "        print(\"TRUE\")\n",
    "        print(row[\"True Label\"])\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    \n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\"],\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    context_texts = examples[\"text\"]\n",
    "    answer_texts = examples[\"label\"]\n",
    "    errors=[]\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "\n",
    "        context = context_texts[i]\n",
    "        answer = answer_texts[i]\n",
    "\n",
    "        # Default to CLS for no response\n",
    "        if answer == \"no response\" or answer.strip() == \"\":\n",
    "            start_positions.append(cls_index)\n",
    "            end_positions.append(cls_index)\n",
    "            continue\n",
    "\n",
    "        # Lowercase match to avoid case mismatch\n",
    "        start_char = context.lower().find(answer.lower())\n",
    "        if start_char == -1:\n",
    "            print(i)\n",
    "            errors.append(i)\n",
    "            print(f\"[WARNING] Could not find answer: '{answer}' in context:\\n{context}\")\n",
    "            start_positions.append(cls_index)\n",
    "            end_positions.append(cls_index)\n",
    "            continue\n",
    "\n",
    "        end_char = start_char + len(answer)\n",
    "\n",
    "        # Now find token positions\n",
    "        start_pos = None\n",
    "        end_pos = None\n",
    "        for idx, (start, end) in enumerate(offsets):\n",
    "            if start <= start_char < end and start_pos is None:\n",
    "                start_pos = idx\n",
    "            if start < end_char <= end:\n",
    "                end_pos = idx\n",
    "                break\n",
    "\n",
    "        if start_pos is None or end_pos is None:\n",
    "            # Fallback if something failed\n",
    "            print(f\"[WARNING] Failed to align answer '{answer}' in context\")\n",
    "            start_positions.append(cls_index)\n",
    "            end_positions.append(cls_index)\n",
    "        else:\n",
    "            start_positions.append(start_pos)\n",
    "            end_positions.append(end_pos)\n",
    "        \n",
    "    tokenized_examples[\"start_positions\"] = start_positions\n",
    "    tokenized_examples[\"end_positions\"] = end_positions\n",
    "    return tokenized_examples\n",
    "    \n",
    "\n",
    "def predict_indexes(pred):\n",
    "\n",
    "    # Extract logits from predictions\n",
    "    start_logits, end_logits = pred.predictions\n",
    "\n",
    "    \n",
    "    # Get the best start and end indices\n",
    "    start_indexes = np.argmax(start_logits, axis=1)\n",
    "    end_indexes = np.argmax(end_logits, axis=1)\n",
    "\n",
    "    \n",
    "    return start_indexes, end_indexes\n",
    "\n",
    "def extract_answer_from_tokens(tokenized_inputs, start_index, end_index):\n",
    "    \"\"\"\n",
    "    Extracts the predicted answer using tokenized input and index positions.\n",
    "    \n",
    "    Args:\n",
    "        tokenized_inputs: The tokenized dataset\n",
    "        start_index: Predicted start position\n",
    "        end_index: Predicted end position\n",
    "    \n",
    "    Returns:\n",
    "        Extracted text or \"No response\" if CLS token is chosen\n",
    "    \"\"\"\n",
    "    # Convert token IDs back to words\n",
    "    tokens = tokenizer.convert_ids_to_tokens(tokenized_inputs[\"input_ids\"])\n",
    "    \n",
    "    \n",
    "    # If CLS token is chosen (indicating no answer)\n",
    "    if start_index == 0 or end_index == 0 or start_index > end_index:\n",
    "        return \"no response\"\n",
    "\n",
    "    # Extract the predicted text\n",
    "    answer_tokens = tokens[start_index:end_index+1]\n",
    "    answer = tokenizer.convert_tokens_to_string(answer_tokens)\n",
    "    \n",
    "\n",
    "    \n",
    "    return answer\n",
    "\n",
    "\n",
    "def cross_validation(X, Y,model_save):\n",
    "    import torch\n",
    "    from transformers import AutoModelForQuestionAnswering, Trainer\n",
    "    from datasets import Dataset\n",
    "    from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "    test=X\n",
    "    test_y=Y.loc[test.index]\n",
    "    test[\"label\"]=test_y[\"label\"]\n",
    "    \n",
    "    ind=list(test.index)\n",
    "        \n",
    "\n",
    "    model = AutoModelForQuestionAnswering.from_pretrained(\n",
    "        model_name\n",
    "    )\n",
    "    \n",
    "        \n",
    "\n",
    "        \n",
    "    test_data = Dataset.from_pandas(test)\n",
    "\n",
    "    # Tokenize datasets\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    print(\"ERRORES TEST\")\n",
    "    test_data = test_data.map(tokenize_function, batched=True)\n",
    "    test_data = test_data.rename_column(\"label\", \"labels\")\n",
    "    test_data = test_data.remove_columns([\"text\"])\n",
    "    test_data.set_format(\"torch\")\n",
    "    # for j, indice in enumerate(train_ind):\n",
    "    #     print(j,indice)\n",
    "\n",
    "    \n",
    "            \n",
    "\n",
    "    # **Make Predictions**\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        )\n",
    "    pred = trainer.predict(test_data)\n",
    "    \n",
    "    start_indexes, end_indexes = predict_indexes(pred)\n",
    "\n",
    "    answers = []\n",
    "    for j in range(len(start_indexes)):\n",
    "        # Extract answer from tokenized test data\n",
    "        tokenized_example = test_data[j]\n",
    "        answer = extract_answer_from_tokens(tokenized_example, start_indexes[j], end_indexes[j])\n",
    "        answers.append(answer)\n",
    "        # print(f\"Extracted Answer {j+1}: {answer}\")\n",
    "\n",
    "    test_data={}\n",
    "    test_label={}\n",
    "    for tipo in questions:\n",
    "        #Primero creamos la lista y luego vemos que no esté vacía para hacer el stack\n",
    "        data=[output for j,output in enumerate(answers) if re.search(rf\"_{tipo}(_\\d+)?$\", ind[j])]\n",
    "        print(data)\n",
    "        \n",
    "        if data:\n",
    "            test_data[tipo]=data\n",
    "            \n",
    "            del data\n",
    "                \n",
    "\n",
    "        labels=[output for j,output in enumerate(test[\"label\"])  if re.search(rf\"_{tipo}(_\\d+)?$\", ind[j])]\n",
    "        \n",
    "        if labels:\n",
    "            #Convertimos a token y luego str para que tenga el mismo formato que las respuestas.\n",
    "            test_label[tipo] = [\n",
    "            tokenizer.convert_tokens_to_string(tokenizer.tokenize(lab)).strip() \n",
    "            for lab in labels\n",
    "        ]\n",
    "            print(test_label[tipo])\n",
    "            \n",
    "    ind_fold={tipo: [key for key in ind if re.search(rf\"_{tipo}(_\\d+)?$\", key)] for tipo in questions}\n",
    "        \n",
    "        \n",
    "    # **Ensure Label Comparison Works Correctly**\n",
    "    ground_truths = test[\"label\"].tolist()\n",
    "    valid_dataset = [examples_raw[key] for key in ind]\n",
    "\n",
    "    for tipo in questions:\n",
    "        if tipo in test_data:\n",
    "            acc = accuracy_score(test_label[tipo], test_data[tipo])\n",
    "            \n",
    "            print(f\"Accuracy for {tipo}: {acc:.4f}\")\n",
    "            \n",
    "    # # **Evaluate Accuracy**\n",
    "    # accuracy = accuracy_score(ground_truths, answers)\n",
    "    \n",
    "\n",
    "   \n",
    "\n",
    "    # **Visualize Errors**\n",
    "    \n",
    "    visualize_errors(valid_dataset, np.array(ground_truths), answers, ind)\n",
    "\n",
    "       \n",
    "    output_dic={}\n",
    "    output_dic_t={}\n",
    "    for tipo in questions:\n",
    "\n",
    "        output_dic[tipo]={ind:test_data[tipo][i] for i, ind in enumerate(ind_fold[tipo])}\n",
    "        output_dic_t[tipo]={ind:test_label[tipo][i] for i, ind in enumerate(ind_fold[tipo])}\n",
    "        with open(f\"test_results/results_dic_{tipo}/{model_save}truth.pkl\", \"wb\") as file:\n",
    "            pickle.dump(output_dic_t[tipo], file)\n",
    "    for tipo in questions:\n",
    "        print(tipo)\n",
    "        with open(f\"test_results/results_dic_{tipo}/{model_save}2.pkl\", \"wb\") as file:\n",
    "            pickle.dump(output_dic[tipo], file)    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2c497b-67a9-46c8-9698-9a6cf9118cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs,questions_examples,targets,examples_raw = flatten_and_filter_dataset(ground_truth,report_data)  \n",
    "dataset_final=pd.DataFrame.from_dict(inputs,orient='index')\n",
    "questions_examples=pd.DataFrame.from_dict(questions_examples,orient='index')\n",
    "\n",
    "print(len(dataset_final),len(questions_examples),len(targets))\n",
    "\n",
    "targets=pd.DataFrame.from_dict(targets,orient='index')\n",
    "dataset_final.columns=[\"text\"]\n",
    "\n",
    "dataset_final[\"question\"]=questions_examples\n",
    "\n",
    "targets.columns=[\"label\"]\n",
    "\n",
    "model_save=\"biomedbert\"\n",
    "\n",
    "model_name_original=\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\"\n",
    "\n",
    "model_name=f\"results/{model_name_original}_model_final2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_original)\n",
    "\n",
    "cross_validation(dataset_final,targets,model_save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55828cd-eb64-4beb-9608-f3a703017c45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs,questions_examples,targets,examples_raw = flatten_and_filter_dataset(ground_truth,report_data)  \n",
    "dataset_final=pd.DataFrame.from_dict(inputs,orient='index')\n",
    "questions_examples=pd.DataFrame.from_dict(questions_examples,orient='index')\n",
    "\n",
    "print(len(dataset_final),len(questions_examples),len(targets))\n",
    "\n",
    "targets=pd.DataFrame.from_dict(targets,orient='index')\n",
    "dataset_final.columns=[\"text\"]\n",
    "\n",
    "dataset_final[\"question\"]=questions_examples\n",
    "\n",
    "targets.columns=[\"label\"]\n",
    "\n",
    "model_save=\"biobert\"\n",
    "\n",
    "model_name_original=\"dmis-lab/biobert-base-cased-v1.1\"\n",
    "\n",
    "model_name=f\"results/{model_name_original}_model_final2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_original)\n",
    "\n",
    "cross_validation(dataset_final,targets,model_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c9fbf1-edc9-4076-b396-a5e5e2c58c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs,questions_examples,targets,examples_raw = flatten_and_filter_dataset(ground_truth,report_data)  \n",
    "dataset_final=pd.DataFrame.from_dict(inputs,orient='index')\n",
    "questions_examples=pd.DataFrame.from_dict(questions_examples,orient='index')\n",
    "\n",
    "print(len(dataset_final),len(questions_examples),len(targets))\n",
    "\n",
    "targets=pd.DataFrame.from_dict(targets,orient='index')\n",
    "dataset_final.columns=[\"text\"]\n",
    "\n",
    "dataset_final[\"question\"]=questions_examples\n",
    "\n",
    "targets.columns=[\"label\"]\n",
    "\n",
    "model_save=\"bluebert\"\n",
    "\n",
    "model_name_original=\"bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12\"\n",
    "\n",
    "\n",
    "model_name=f\"results/{model_name_original}_model_final2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_original)\n",
    "\n",
    "cross_validation(dataset_final,targets,model_save)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
