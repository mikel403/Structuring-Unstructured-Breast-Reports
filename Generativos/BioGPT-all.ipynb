{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32d72f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<weakproxy at 0x7f1b1cd29120; to 'numba.cuda.cudadrv.driver.Device' at 0x7f1b217ddd30>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "gpu_device = 0    # nÃºmero identificador del device puede ser: 0, 1, 2, o 3\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpu_device)\n",
    "from numba import cuda\n",
    "cuda.select_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb74c3f9-d20e-43db-bfc5-b83bca52ef2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcarrilero/pytorch_env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from datasets import Dataset,concatenate_datasets,load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca9860e1-592f-4391-b485-82d9ab093295",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/data.ipynb\n",
    "%run ../utils/Generatives-small_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5021829-1521-4069-a820-2e5bbe267ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcarrilero/pytorch_env/lib/python3.13/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/mcarrilero/pytorch_env/lib/python3.13/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/mcarrilero/pytorch_env/lib/python3.13/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cargar modelo y tokenizador\n",
    "model_name = \"microsoft/biogpt\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "inputs,targets,val_data,examples_raw = flatten_and_filter_dataset(ground_truth,report_data)  \n",
    "inputs2,targets2,val_data2,examples_raw2= flatten_and_filter_dataset_no_prev(ground_truth,report_data) \n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-6,\n",
    "    per_device_train_batch_size=4,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "training_args_all = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    # evaluation_strategy=\"epoch\",\n",
    "    learning_rate=1e-5,  # Increased for better adaptation\n",
    "    per_device_train_batch_size=8,\n",
    "    fp16=True,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=2,  # Increased epochs to account for repeated reports\n",
    "    weight_decay=0.01,  # Prevents overfitting\n",
    "    save_total_limit=2,\n",
    "    eval_steps=40,\n",
    ")\n",
    "training_args_answer = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    # evaluation_strategy=\"epoch\",\n",
    "    learning_rate=1e-5,  # Lower for fine-tuning without losing generalization\n",
    "    fp16=True,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    \n",
    "    num_train_epochs=5,  # Shorter fine-tuning stage\n",
    "    weight_decay=0.01,  # Lower weight decay to preserve learned features\n",
    "    save_total_limit=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c75590c-3dc9-41ab-9502-54d7918e3f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_final=pd.DataFrame.from_dict(inputs,orient='index')\n",
    "targets=pd.DataFrame.from_dict(targets,orient='index')\n",
    "val_data=pd.DataFrame.from_dict(val_data,orient='index')\n",
    "dataset_final.columns=[\"text\"]\n",
    "targets.columns=[\"label\"]\n",
    "val_data.columns=[\"val_data\"]\n",
    "dataset_final=pd.concat([dataset_final, val_data],axis=1)\n",
    "\n",
    "dataset_final2=pd.DataFrame.from_dict(inputs2,orient='index')\n",
    "targets2=pd.DataFrame.from_dict(targets2,orient='index')\n",
    "val_data2=pd.DataFrame.from_dict(val_data2,orient='index')\n",
    "dataset_final2.columns=[\"text\"]\n",
    "targets2.columns=[\"label\"]\n",
    "val_data2.columns=[\"val_data\"]\n",
    "dataset_final2=pd.concat([dataset_final2, val_data2],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a872428a-b2a7-4410-b756-22eb701c675e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "ya existe\n",
      "                                                                                             val_data  \\\n",
      "001-323-702-20221219-120748.390_age                 Question: does the patient's age appear in the...   \n",
      "001-323-702-20221219-120748.390_birads              Question: what is the final BI-RADS classifica...   \n",
      "001-323-702-20221219-120748.390_calcifications_...  Question: does the following breast medical re...   \n",
      "001-323-702-20221219-120748.390_density_echo        Question: what is the breast density found in ...   \n",
      "001-323-702-20221219-120748.390_density_mammo       Question: what is the breast density found in ...   \n",
      "...                                                                                               ...   \n",
      "046-630-291-20230619-112356_age                     Question: does the patient's age appear in the...   \n",
      "046-630-291-20230619-112356_family                  Question: does the patient have any family his...   \n",
      "046-630-291-20230619-112356_history                 Question: does the patient have any non-famili...   \n",
      "046-630-291-20230619-112356_tecnica                 Question: what diagnostic technique was used i...   \n",
      "046-630-291-20230619-112356_tipo                    Question: is the following breast medical repo...   \n",
      "\n",
      "                                                                                 label  \n",
      "001-323-702-20221219-120748.390_age                                                no.  \n",
      "001-323-702-20221219-120748.390_birads                                      BI-RADS 2.  \n",
      "001-323-702-20221219-120748.390_calcifications_...                                yes.  \n",
      "001-323-702-20221219-120748.390_density_echo             heterogeneous fibroglandular.  \n",
      "001-323-702-20221219-120748.390_density_mammo                                   ACR C.  \n",
      "...                                                                                ...  \n",
      "046-630-291-20230619-112356_age                                                    no.  \n",
      "046-630-291-20230619-112356_family                                  no family history.  \n",
      "046-630-291-20230619-112356_history                              no history was found.  \n",
      "046-630-291-20230619-112356_tecnica                             only ultrasound study.  \n",
      "046-630-291-20230619-112356_tipo                    normal control or revision report.  \n",
      "\n",
      "[405 rows x 2 columns]\n",
      "3636 405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3636/3636 [00:20<00:00, 175.85 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 405/405 [00:02<00:00, 182.93 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 405/405 [00:02<00:00, 159.09 examples/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 31.12 MiB is free. Process 796300 has 306.00 MiB memory in use. Including non-PyTorch memory, this process has 15.44 GiB memory in use. Of the allocated memory 15.02 GiB is allocated by PyTorch, and 50.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m accuracies,output_dic=\u001b[43mcross_validation_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_final\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mlow_beams\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mtesting\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/tmp/ipykernel_4019488/2165214166.py:1156\u001b[39m, in \u001b[36mcross_validation_all\u001b[39m\u001b[34m(X, Y, X2, Y2, training, low_beams, testing)\u001b[39m\n\u001b[32m   1149\u001b[39m trainer_all = Trainer(\n\u001b[32m   1150\u001b[39m model=model,\n\u001b[32m   1151\u001b[39m     args=training_args_all,\n\u001b[32m   1152\u001b[39m     train_dataset=train_data_all,\n\u001b[32m   1153\u001b[39m     eval_dataset=test_val_during_training_all  \u001b[38;5;66;03m# Si tienes datos de validaciÃ³n, Ãºsalos aquÃ­\u001b[39;00m\n\u001b[32m   1154\u001b[39m )\n\u001b[32m   1155\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[32m-> \u001b[39m\u001b[32m1156\u001b[39m     \u001b[43mtrainer_all\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m testing==\u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m   1158\u001b[39m     trainer_all.save_model(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mresults/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_first_stage_model\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.13/site-packages/transformers/trainer.py:2241\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2239\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2240\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2242\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2245\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2246\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.13/site-packages/transformers/trainer.py:2548\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2541\u001b[39m context = (\n\u001b[32m   2542\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2543\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2544\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2545\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2546\u001b[39m )\n\u001b[32m   2547\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2548\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2550\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2551\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2552\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2553\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2554\u001b[39m ):\n\u001b[32m   2555\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2556\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.13/site-packages/transformers/trainer.py:3698\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3695\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb.reduce_mean().detach().to(\u001b[38;5;28mself\u001b[39m.args.device)\n\u001b[32m   3697\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_context_manager():\n\u001b[32m-> \u001b[39m\u001b[32m3698\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3700\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[32m   3701\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   3702\u001b[39m     \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3703\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.global_step % \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps == \u001b[32m0\u001b[39m\n\u001b[32m   3704\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.13/site-packages/transformers/trainer.py:3759\u001b[39m, in \u001b[36mTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3757\u001b[39m         loss_kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_items_in_batch\u001b[39m\u001b[33m\"\u001b[39m] = num_items_in_batch\n\u001b[32m   3758\u001b[39m     inputs = {**inputs, **loss_kwargs}\n\u001b[32m-> \u001b[39m\u001b[32m3759\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3760\u001b[39m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[32m   3761\u001b[39m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[32m   3762\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.past_index >= \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.13/site-packages/accelerate/utils/operations.py:819\u001b[39m, in \u001b[36mconvert_outputs_to_fp32.<locals>.forward\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m819\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.13/site-packages/accelerate/utils/operations.py:807\u001b[39m, in \u001b[36mConvertOutputsToFp32.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    806\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m807\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_to_fp32\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.13/site-packages/accelerate/utils/operations.py:786\u001b[39m, in \u001b[36mconvert_to_fp32\u001b[39m\u001b[34m(tensor)\u001b[39m\n\u001b[32m    780\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_is_fp16_bf16_tensor\u001b[39m(tensor):\n\u001b[32m    781\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (is_torch_tensor(tensor) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tensor, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m tensor.dtype \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[32m    782\u001b[39m         torch.float16,\n\u001b[32m    783\u001b[39m         torch.bfloat16,\n\u001b[32m    784\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m786\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrecursively_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_convert_to_fp32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_is_fp16_bf16_tensor\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.13/site-packages/accelerate/utils/operations.py:119\u001b[39m, in \u001b[36mrecursively_apply\u001b[39m\u001b[34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[39m\n\u001b[32m    107\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m honor_type(\n\u001b[32m    108\u001b[39m         data,\n\u001b[32m    109\u001b[39m         (\n\u001b[32m   (...)\u001b[39m\u001b[32m    114\u001b[39m         ),\n\u001b[32m    115\u001b[39m     )\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Mapping):\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\n\u001b[32m    118\u001b[39m         {\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m             k: \u001b[43mrecursively_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_on_other_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_on_other_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m data.items()\n\u001b[32m    123\u001b[39m         }\n\u001b[32m    124\u001b[39m     )\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m test_type(data):\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m func(data, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.13/site-packages/accelerate/utils/operations.py:107\u001b[39m, in \u001b[36mrecursively_apply\u001b[39m\u001b[34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[33;03mRecursively apply a function on a data structure that is a nested list/tuple/dictionary of a given base type.\u001b[39;00m\n\u001b[32m     87\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    104\u001b[39m \u001b[33;03m    The same data structure as `data` with `func` applied to every object of type `main_type`.\u001b[39;00m\n\u001b[32m    105\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhonor_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrecursively_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_on_other_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_on_other_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Mapping):\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\n\u001b[32m    118\u001b[39m         {\n\u001b[32m    119\u001b[39m             k: recursively_apply(\n\u001b[32m   (...)\u001b[39m\u001b[32m    123\u001b[39m         }\n\u001b[32m    124\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.13/site-packages/accelerate/utils/operations.py:81\u001b[39m, in \u001b[36mhonor_type\u001b[39m\u001b[34m(obj, generator)\u001b[39m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(obj)(*\u001b[38;5;28mlist\u001b[39m(generator))\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.13/site-packages/accelerate/utils/operations.py:110\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[33;03mRecursively apply a function on a data structure that is a nested list/tuple/dictionary of a given base type.\u001b[39;00m\n\u001b[32m     87\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    104\u001b[39m \u001b[33;03m    The same data structure as `data` with `func` applied to every object of type `main_type`.\u001b[39;00m\n\u001b[32m    105\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[32m    107\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m honor_type(\n\u001b[32m    108\u001b[39m         data,\n\u001b[32m    109\u001b[39m         (\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m             \u001b[43mrecursively_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_on_other_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_on_other_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m data\n\u001b[32m    114\u001b[39m         ),\n\u001b[32m    115\u001b[39m     )\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Mapping):\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\n\u001b[32m    118\u001b[39m         {\n\u001b[32m    119\u001b[39m             k: recursively_apply(\n\u001b[32m   (...)\u001b[39m\u001b[32m    123\u001b[39m         }\n\u001b[32m    124\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.13/site-packages/accelerate/utils/operations.py:107\u001b[39m, in \u001b[36mrecursively_apply\u001b[39m\u001b[34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[33;03mRecursively apply a function on a data structure that is a nested list/tuple/dictionary of a given base type.\u001b[39;00m\n\u001b[32m     87\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    104\u001b[39m \u001b[33;03m    The same data structure as `data` with `func` applied to every object of type `main_type`.\u001b[39;00m\n\u001b[32m    105\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhonor_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrecursively_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_on_other_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_on_other_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Mapping):\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\n\u001b[32m    118\u001b[39m         {\n\u001b[32m    119\u001b[39m             k: recursively_apply(\n\u001b[32m   (...)\u001b[39m\u001b[32m    123\u001b[39m         }\n\u001b[32m    124\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.13/site-packages/accelerate/utils/operations.py:81\u001b[39m, in \u001b[36mhonor_type\u001b[39m\u001b[34m(obj, generator)\u001b[39m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(obj)(*\u001b[38;5;28mlist\u001b[39m(generator))\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.13/site-packages/accelerate/utils/operations.py:110\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[33;03mRecursively apply a function on a data structure that is a nested list/tuple/dictionary of a given base type.\u001b[39;00m\n\u001b[32m     87\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    104\u001b[39m \u001b[33;03m    The same data structure as `data` with `func` applied to every object of type `main_type`.\u001b[39;00m\n\u001b[32m    105\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[32m    107\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m honor_type(\n\u001b[32m    108\u001b[39m         data,\n\u001b[32m    109\u001b[39m         (\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m             \u001b[43mrecursively_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_on_other_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_on_other_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m data\n\u001b[32m    114\u001b[39m         ),\n\u001b[32m    115\u001b[39m     )\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Mapping):\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\n\u001b[32m    118\u001b[39m         {\n\u001b[32m    119\u001b[39m             k: recursively_apply(\n\u001b[32m   (...)\u001b[39m\u001b[32m    123\u001b[39m         }\n\u001b[32m    124\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.13/site-packages/accelerate/utils/operations.py:126\u001b[39m, in \u001b[36mrecursively_apply\u001b[39m\u001b[34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\n\u001b[32m    118\u001b[39m         {\n\u001b[32m    119\u001b[39m             k: recursively_apply(\n\u001b[32m   (...)\u001b[39m\u001b[32m    123\u001b[39m         }\n\u001b[32m    124\u001b[39m     )\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m test_type(data):\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m error_on_other_type:\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    129\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnsupported types (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) passed to `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`. Only nested list/tuple/dicts of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    130\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mobjects that are valid for `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_type.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` should be passed.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    131\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.13/site-packages/accelerate/utils/operations.py:778\u001b[39m, in \u001b[36mconvert_to_fp32.<locals>._convert_to_fp32\u001b[39m\u001b[34m(tensor)\u001b[39m\n\u001b[32m    777\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_convert_to_fp32\u001b[39m(tensor):\n\u001b[32m--> \u001b[39m\u001b[32m778\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 31.12 MiB is free. Process 796300 has 306.00 MiB memory in use. Including non-PyTorch memory, this process has 15.44 GiB memory in use. Of the allocated memory 15.02 GiB is allocated by PyTorch, and 50.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "accuracies,output_dic=cross_validation_all(dataset_final,targets,training=True,low_beams=False,testing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffa1b232-0b73-49b7-84fe-ca39d00d1eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9952830188679245,\n",
       " 0.8773584905660378,\n",
       " 0.9811320754716981,\n",
       " 0.8548387096774194,\n",
       " 0.010752688172043012,\n",
       " 0.010752688172043012,\n",
       " 0.9946236559139785,\n",
       " 0.9838709677419355,\n",
       " 0.978494623655914,\n",
       " 0.9946236559139785,\n",
       " 0.19021739130434784,\n",
       " 0.967741935483871,\n",
       " 0.9408602150537635,\n",
       " 0.9623655913978495,\n",
       " 0.016129032258064516,\n",
       " 0.989247311827957,\n",
       " 0.989247311827957,\n",
       " 0.9354838709677419,\n",
       " 0.012195121951219513,\n",
       " 0.2804878048780488,\n",
       " 0.06097560975609756,\n",
       " 0.08536585365853659,\n",
       " 0.024390243902439025,\n",
       " 0.2804878048780488,\n",
       " 0.7926829268292683,\n",
       " 0.9069767441860465]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e08833-5e85-4b35-8130-d6cc949c68c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "first fold\n",
    "4 epoch 1e-5\n",
    "Accuracy for age: 1.0000\n",
    "Accuracy for tipo: 1.0000\n",
    "Accuracy for tecnica: 1.0000\n",
    "Accuracy for family: 1.0000\n",
    "Accuracy for history: 0.9500\n",
    "Accuracy for symtomatic: 0.9500\n",
    "Accuracy for prosthesis: 1.0000\n",
    "Accuracy for birads: 1.0000\n",
    "Accuracy for density_mammo: 0.9474\n",
    "Accuracy for density_echo: 0.8947\n",
    "Accuracy for lymph_suspicious: 1.0000\n",
    "Accuracy for nodules_echo_num: 0.9474\n",
    "Accuracy for nodules_echo_margin: 0.8750\n",
    "Accuracy for nodules_echo_echogenicity: 1.0000\n",
    "Accuracy for nodules_echo_location: 0.8750\n",
    "Accuracy for nodules_echo_size: 0.8750\n",
    "Accuracy for nodules_echo_known: 0.8750\n",
    "Accuracy for nodules_echo_stable: 1.0000\n",
    "\n",
    "\n",
    "2 epoch 5e-6\n",
    "Accuracy for age: 1.0000\n",
    "Accuracy for tipo: 1.0000\n",
    "Accuracy for tecnica: 1.0000\n",
    "Accuracy for family: 1.0000\n",
    "Accuracy for history: 1.0000\n",
    "Accuracy for symtomatic: 0.9500\n",
    "Accuracy for prosthesis: 1.0000\n",
    "Accuracy for birads: 1.0000\n",
    "Accuracy for density_mammo: 0.9474\n",
    "Accuracy for density_echo: 0.8947\n",
    "Accuracy for lymph_suspicious: 1.0000\n",
    "Accuracy for nodules_echo_num: 0.9474\n",
    "Accuracy for nodules_echo_shape: 0.8750\n",
    "Accuracy for nodules_echo_margin: 0.7500\n",
    "Accuracy for nodules_echo_echogenicity: 1.0000\n",
    "Accuracy for nodules_echo_location: 0.5000\n",
    "Accuracy for nodules_echo_size: 0.8750\n",
    "Accuracy for nodules_echo_known: 1.0000\n",
    "Accuracy for nodules_echo_stable: 1.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b5b218-c1ed-4cc4-a8b4-7507d6a5c2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "second fold\n",
    "Accuracy for age: 1.0000\n",
    "Accuracy for tipo: 0.9048\n",
    "Accuracy for tecnica: 1.0000\n",
    "Accuracy for family: 1.0000\n",
    "Accuracy for history: 1.0000\n",
    "Accuracy for symtomatic: 0.8824\n",
    "Accuracy for prosthesis: 1.0000\n",
    "Accuracy for birads: 0.8889\n",
    "Accuracy for density_mammo: 1.0000\n",
    "Accuracy for density_echo: 1.0000\n",
    "Accuracy for lymph_suspicious: 1.0000\n",
    "Accuracy for nodules_echo_num: 0.7778\n",
    "Accuracy for nodules_echo_margin: 0.8000\n",
    "Accuracy for nodules_echo_echogenicity: 0.8000\n",
    "Accuracy for nodules_echo_location: 0.7000\n",
    "Accuracy for nodules_echo_size: 0.8889\n",
    "Accuracy for nodules_echo_known: 0.7778\n",
    "Accuracy for nodules_echo_stable: 0.6000\n",
    "\n",
    "Accuracy for age: 1.0000\n",
    "Accuracy for tipo: 0.9048\n",
    "Accuracy for tecnica: 1.0000\n",
    "Accuracy for family: 1.0000\n",
    "Accuracy for history: 1.0000\n",
    "Accuracy for symtomatic: 0.9412\n",
    "Accuracy for prosthesis: 1.0000\n",
    "Accuracy for birads: 0.9444\n",
    "Accuracy for density_mammo: 1.0000\n",
    "Accuracy for density_echo: 1.0000\n",
    "Accuracy for lymph_suspicious: 0.9444\n",
    "Accuracy for nodules_echo_num: 0.6111\n",
    "Accuracy for nodules_echo_shape: 0.8000\n",
    "Accuracy for nodules_echo_margin: 0.6000\n",
    "Accuracy for nodules_echo_echogenicity: 0.8000\n",
    "Accuracy for nodules_echo_location: 0.5000\n",
    "Accuracy for nodules_echo_size: 1.0000\n",
    "Accuracy for nodules_echo_known: 0.7778\n",
    "Accuracy for nodules_echo_stable: 0.8000\n",
    "\n",
    "Accuracy for age: 1.0000\n",
    "Accuracy for tipo: 0.9524\n",
    "Accuracy for tecnica: 1.0000\n",
    "Accuracy for family: 1.0000\n",
    "Accuracy for history: 0.5882\n",
    "Accuracy for symtomatic: 0.8235\n",
    "Accuracy for prosthesis: 1.0000\n",
    "Accuracy for birads: 0.9444\n",
    "Accuracy for density_mammo: 1.0000\n",
    "Accuracy for density_echo: 0.8889\n",
    "Accuracy for lymph_suspicious: 1.0000\n",
    "Accuracy for nodules_echo_num: 0.7222\n",
    "Accuracy for nodules_echo_shape: 0.9000\n",
    "Accuracy for nodules_echo_margin: 0.7000\n",
    "Accuracy for nodules_echo_echogenicity: 0.6000\n",
    "Accuracy for nodules_echo_location: 0.6000\n",
    "Accuracy for nodules_echo_size: 1.0000\n",
    "Accuracy for nodules_echo_known: 0.7778\n",
    "Accuracy for nodules_echo_stable: 0.6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db318f5f-7f75-4575-acdc-c0bcf3ee69b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "third fold\n",
    "Accuracy for age: 0.9500\n",
    "Accuracy for tipo: 0.9500\n",
    "Accuracy for tecnica: 0.9000\n",
    "Accuracy for family: 1.0000\n",
    "Accuracy for history: 0.7222\n",
    "Accuracy for symtomatic: 0.9444\n",
    "Accuracy for prosthesis: 1.0000\n",
    "Accuracy for birads: 1.0000\n",
    "Accuracy for density_mammo: 1.0000\n",
    "Accuracy for density_echo: 0.8333\n",
    "Accuracy for lymph_suspicious: 0.9444\n",
    "Accuracy for nodules_echo_num: 0.8333\n",
    "Accuracy for nodules_echo_margin: 0.8889\n",
    "Accuracy for nodules_echo_echogenicity: 0.8889\n",
    "Accuracy for nodules_echo_location: 0.7778\n",
    "Accuracy for nodules_echo_size: 1.0000\n",
    "Accuracy for nodules_echo_known: 0.9000\n",
    "Accuracy for nodules_echo_stable: 0.8571"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ced9d30f-d4d4-432d-b13c-933ee4ac5060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age 0.9952830188679245\n",
      "tipo 0.8773584905660378\n",
      "tecnica 0.9811320754716981\n",
      "family 0.8548387096774194\n",
      "history 0.010752688172043012\n",
      "symtomatic 0.010752688172043012\n",
      "prosthesis 0.9946236559139785\n",
      "birads 0.9838709677419355\n",
      "density_mammo 0.978494623655914\n",
      "calcifications_benign 0.9946236559139785\n",
      "density_echo 0.19021739130434784\n",
      "ganglio_mamo 0.967741935483871\n",
      "lymph_benign 0.9408602150537635\n",
      "lymph_suspicious 0.9623655913978495\n",
      "parenchymal_distortion 0.016129032258064516\n",
      "simple_cyst 0.989247311827957\n",
      "ductal_ectasia 0.989247311827957\n",
      "nodules_echo_num 0.9354838709677419\n",
      "nodules_echo_description 0.012195121951219513\n",
      "nodules_echo_shape 0.2804878048780488\n",
      "nodules_echo_margin 0.06097560975609756\n",
      "nodules_echo_echogenicity 0.08536585365853659\n",
      "nodules_echo_location 0.024390243902439025\n",
      "nodules_echo_size 0.2804878048780488\n",
      "nodules_echo_known 0.7926829268292683\n",
      "nodules_echo_stable 0.9069767441860465\n"
     ]
    }
   ],
   "source": [
    "for i,tipo in enumerate(questions):\n",
    "    print(tipo, accuracies[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce5d521-3905-462b-865c-9aaaa6600de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "age 0.9952830188679245\n",
    "tipo 0.9716981132075472\n",
    "tecnica 0.9858490566037735\n",
    "family 0.989247311827957\n",
    "history 0.9301075268817204\n",
    "symtomatic 0.0\n",
    "prosthesis 0.9946236559139785\n",
    "birads 0.967741935483871\n",
    "density_mammo 0.9516129032258065\n",
    "density_echo 0.6935483870967742\n",
    "lymph_suspicious 0.9731182795698925\n",
    "nodules_echo_num 0.7849462365591398\n",
    "nodules_echo_size 0.7349397590361446\n",
    "nodules_echo_known 0.7831325301204819\n",
    "nodules_echo_stable nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b53fee22-5564-4140-a315-918ae24f9d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'tipo',\n",
       " 'tecnica',\n",
       " 'family',\n",
       " 'history',\n",
       " 'symtomatic',\n",
       " 'prosthesis',\n",
       " 'birads',\n",
       " 'density_mammo',\n",
       " 'calcifications_benign',\n",
       " 'density_echo',\n",
       " 'ganglio_mamo',\n",
       " 'lymph_benign',\n",
       " 'lymph_suspicious',\n",
       " 'parenchymal_distortion',\n",
       " 'simple_cyst',\n",
       " 'ductal_ectasia',\n",
       " 'nodules_echo_num',\n",
       " 'nodules_echo_description',\n",
       " 'nodules_echo_shape',\n",
       " 'nodules_echo_margin',\n",
       " 'nodules_echo_echogenicity',\n",
       " 'nodules_echo_location',\n",
       " 'nodules_echo_size',\n",
       " 'nodules_echo_known',\n",
       " 'nodules_echo_stable']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9a69cf-ed72-4dca-8a9e-fabfa7c1c030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15167d3f-8034-42e0-aaba-f6a8fb55aab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "tipo\n",
      "tecnica\n",
      "family\n",
      "history\n",
      "symtomatic\n",
      "prosthesis\n",
      "birads\n",
      "density_mammo\n",
      "calcifications_benign\n",
      "density_echo\n",
      "ganglio_mamo\n",
      "lymph_benign\n",
      "lymph_suspicious\n",
      "parenchymal_distortion\n",
      "simple_cyst\n",
      "ductal_ectasia\n",
      "nodules_echo_num\n",
      "nodules_echo_description\n",
      "nodules_echo_shape\n",
      "nodules_echo_margin\n",
      "nodules_echo_echogenicity\n",
      "nodules_echo_location\n",
      "nodules_echo_size\n",
      "nodules_echo_known\n",
      "nodules_echo_stable\n"
     ]
    }
   ],
   "source": [
    "model_name=\"biogpt\"+\"21e51e57\"+\"no_copy\"+\"description\"+\"16batch\"+\"final\"\n",
    "for tipo in questions:\n",
    "    print(tipo)\n",
    "    with open(f\"results_dic_{tipo}/{model_name.split(\"/\")[-1]}.pkl\", \"wb\") as file:\n",
    "        pickle.dump(output_dic[tipo], file)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f97d103d-03af-470d-aa99-d509fc3dd410",
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = cuda.gpus\n",
    "dev=devices.current\n",
    "cuda.select_device(dev.id)\n",
    "cuda.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08bbaabd-498f-4633-8718-a19e438f44ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9952830188679245, 0.9764150943396226, 0.9764150943396226]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies 4 epochs 1 e-5\n",
    "[0.9952830188679245, 0.9764150943396226, 0.9764150943396226]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ca77a72-e0ea-42c2-8743-dcc4ba659884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9952830188679245, 0.013636363636363624)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc,acc_std\n",
    "solo un fallo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368be4e8-79d7-48ed-ae17-480ce506847a",
   "metadata": {},
   "outputs": [],
   "source": [
    "2 epoch eta bikoitza\n",
    "(0.9811320754716981, 0.026424662271916612)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7416252d-332a-4622-b8b0-1ed7f38b5535",
   "metadata": {},
   "outputs": [],
   "source": [
    "con 8 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becb5c3a-bdcd-4cef-be78-80acb93179eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "con 4 epochs pero aÃ±adiendo los datos sin etiqueta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf74c772-2dac-45d8-979e-b8bd624719e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9811320754716981, 0.022268088570756142)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5 epochs 1e-5\n",
    "\" Important! We do not want biopsy, BAG, post BAG, nodal staging ultrasound or BI-RADS 6 (Cancer patients) reports. Answer 'no' if it is any of these. answer: \"\n",
    "(0.9811320754716981, 0.022268088570756142)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
