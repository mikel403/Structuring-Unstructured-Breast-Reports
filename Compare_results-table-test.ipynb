{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a39df26-137d-4c5d-93cb-8d89499143d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9a4bc1-fba6-4f73-b3f8-26884c13772c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#symptomatic, location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033e1180-456b-43ac-a0d7-e197dd58635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions=[\"age\",\"tipo\",\"tecnica\",\"family\",\"history\",\"symtomatic\",\n",
    "           \"prosthesis\",\"birads\",\"density_mammo\",\"calcifications_benign\",\"density_echo\",\"ganglio_mamo\",\"lymph_benign\",\"lymph_suspicious\",\"parenchymal_distortion\",\"simple_cyst\",\"ductal_ectasia\",\n",
    "          \"nodules_echo_num\",\"nodules_echo_description\",\"nodules_echo_shape\",\"nodules_echo_margin\",\"nodules_echo_echogenicity\",\"nodules_echo_location\",\"nodules_echo_size\",\"nodules_echo_known\",\"nodules_echo_stable\"]\n",
    "questions=[\"tipo\",\"tecnica\",\"family\",\n",
    "           \"prosthesis\",\"birads\",\"density_mammo\",\"calcifications_benign\",\"ganglio_mamo\",\"density_echo\",\"lymph_benign\",\"lymph_suspicious\",\"simple_cyst\",\"ductal_ectasia\",\"nodules_echo_num\",\"nodules_echo_shape\",\"nodules_echo_margin\",\"nodules_echo_echogenicity\",\"nodules_echo_known\",\"nodules_echo_stable\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb2e12b-a0bf-486b-a9c8-fbd25b15fa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "def calculate_f1(pred,truth,point=False,average='macro'):\n",
    "    pred_clean={}\n",
    "    truth_clean={}\n",
    "    for key,real in truth.items():\n",
    "        if key in pred:\n",
    "            \n",
    "            predicted=pred[key] \n",
    "            if point==True:\n",
    "                predicted=predicted.split(\".\")[0]+\".\"\n",
    "            elif point==\"mm\":\n",
    "                if \"unknown\" in predicted:\n",
    "                    predicted=predicted.split(\".\")[0]+\".\"\n",
    "                else:\n",
    "                    predicted=predicted.split(\"mm\")[0]+\"mm.\"\n",
    "                \n",
    "            pred_clean[key]=predicted.lower()\n",
    "            truth_clean[key]=str(real).lower()\n",
    "    # Get ground truth and predicted labels\n",
    "    y_true = list(truth_clean.values())\n",
    "    y_pred = list(pred_clean.values())\n",
    "    \n",
    "    # Define the valid labels based on the truth only\n",
    "    valid_labels = sorted(set(y_true))\n",
    "    \n",
    "    # Replace out-of-scope predictions with something invalid\n",
    "    # e.g., keep them but let them be counted as wrong\n",
    "    y_pred_cleaned = [\n",
    "        p if p in valid_labels else 'INVALID' for p in y_pred\n",
    "    ]\n",
    "    \n",
    "    # Now align with true values\n",
    "    y_true_final = []\n",
    "    y_pred_final = []\n",
    "    \n",
    "    for yt, yp in zip(y_true, y_pred_cleaned):\n",
    "        y_true_final.append(yt)\n",
    "        y_pred_final.append(yp)\n",
    "    \n",
    "    # Compute F1 over valid labels only\n",
    "    f1 = f1_score(\n",
    "        y_true_final,\n",
    "        y_pred_final,\n",
    "        labels=valid_labels,   # Only ground-truth classes\n",
    "        average='macro'        # or whatever average you want\n",
    "    )\n",
    "    report = classification_report(\n",
    "        y_true,\n",
    "        y_pred_cleaned,\n",
    "        labels=valid_labels,     # Only ground truth classes\n",
    "        zero_division=0,         # Avoid warnings for undefined precision/recall\n",
    "        digits=4                 # Optional: better precision\n",
    "    )\n",
    "    print(report)\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4cc2ae-b72e-4f9c-8ec5-078c1bf19cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_acc(pred,truth,point=False):\n",
    "    acc=0\n",
    "    total=0\n",
    "    for key,real in truth.items():\n",
    "        if key in pred:\n",
    "            total+=1\n",
    "            predicted=pred[key]    \n",
    "            if point==True:\n",
    "\n",
    "                predicted=predicted.split(\".\")[0]+\".\"\n",
    "\n",
    "            elif point==\"mm\":\n",
    "                if \"unknown\" in predicted:\n",
    "                    predicted=predicted.split(\".\")[0]+\".\"\n",
    "                else:\n",
    "                    predicted=predicted.split(\"mm\")[0]+\"mm.\"\n",
    "            if predicted.lower()==str(real).lower():\n",
    "                acc+=1\n",
    "            else:\n",
    "                print(key,real,predicted)\n",
    "        else:\n",
    "            print(key,real)\n",
    "        # else:\n",
    "        #     print(key)\n",
    "    return acc/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978a8c48-c9ed-4f98-be5a-34e2b3e73913",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "accuracies=defaultdict(list)\n",
    "f1s=defaultdict(list)\n",
    "models=[\"biogpt\",\"clinicalt5\",\"clinicalt5_tokenized\", \"biogpt_no_info\",\"biogpt_answer\"]\n",
    "for model in models:\n",
    "    print(model)\n",
    "    accuracies[\"model\"].append(model)\n",
    "    f1s[\"model\"].append(model)\n",
    "    for tipo in questions:\n",
    "        \n",
    "        print(tipo)\n",
    "        with open(f\"test_results/truth_dic/{tipo}.pkl\", \"rb\") as file:\n",
    "                truth=pickle.load(file)\n",
    "        with open(f\"test_results/results_dic_{tipo}/{model}.pkl\", \"rb\") as file:\n",
    "                output=pickle.load(file)\n",
    "        if tipo==\"family\":\n",
    "            print(len(output))\n",
    "        if tipo==\"birads\":\n",
    "            truth[\"746-766-264-20240605-182548_birads\"]=\"BI-RADS 2.\"\n",
    "        \n",
    "        if tipo!=\"nodules_echo_size\":\n",
    "            acc=calculate_acc(output,truth,point=True)\n",
    "            \n",
    "            f1=calculate_f1(output,truth,point=True)\n",
    "            if tipo==\"density_echo\":\n",
    "                print(truth,output)\n",
    "                print(f1)\n",
    "                print(len(truth),len(output))\n",
    "        else:\n",
    "            acc=calculate_acc(output,truth,point=\"mm\")\n",
    "            f1=calculate_f1(output,truth,point=\"mm\")\n",
    "        accuracies[tipo].append(acc)\n",
    "        f1s[tipo].append(f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbfe9f1-4042-4ace-aad8-59976ff2e9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame(accuracies)\n",
    "data=data.set_index(\"model\")\n",
    "data['average'] = data.mean(axis=1)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c845cdd0-9ed6-4f37-8973-c6d90bbe28cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "biogpt_acc = list(data.loc[\"biogpt\",:])[:-1]\n",
    "biogpt_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0035f20b-2abf-4352-bcf3-533109c5c84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame(f1s)\n",
    "data=data.set_index(\"model\")\n",
    "data['average'] = data.mean(axis=1)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad25265-b382-4147-9951-811596c6f92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "biogpt_f1 = list(data.loc[\"biogpt\",:])[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e44825d-0313-4240-84cf-6bf87c3d65bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIPO=[\"biopsy report\", \"nodal staging ultrasound report\", \"normal control or revision report\"]\n",
    "TECNICA=[\"only ultrasound study\", \"only mammography study\", \"mammography and ultrasound\"]\n",
    "FAMILY=[\"no family history\", \"first degree\", \"second degree\"]\n",
    "PROSTHESIS=[\"no prosthesis\",\"yes prosthesis\"]\n",
    "BIRADS=[\"BI-RADS 0\",\"BI-RADS 1\",\"BI-RADS 2\",\"BI-RADS 3\",\"BI-RADS 4A\",\"BI-RADS 4B\",\"BI-RADS 4C\",\"BI-RADS 5\",\"BI-RADS 6\"]\n",
    "DENSITY_MAMMO=[\"ACR A\",\"ACR B\",\"ACR C\",\"ACR D\",\"unknown density mammo\"]\n",
    "CALCIFICATIONS_BENIGN=[\"no calcifications\",\"yes calcifications\"]\n",
    "GANGLIO_MAMO=[\"no ganglio\",\"yes ganglio\"]\n",
    "DENSITY_ECHO=[\"homogeneous fibroglandular\",\"heterogeneous fibroglandular\",\"fibroglandular and fat\",\"homogeneous fatty\",\"unknown density echo\"]\n",
    "LYMPH_BENIGN=[\"no lymph benign\",\"yes lymph benign\"]\n",
    "LYMPH_SUSPICIOUS=[\"no lymph suspicious\",\"yes lymph suspicious\"]\n",
    "SIMPLE_CYST=[\"no cyst\",\"yes cyst\"]\n",
    "DUCTAL_ECTASIA=[\"no ectasia\",\"yes ectasia\"]\n",
    "NODULES_ECHO=[\"no nodules\", \"yes nodules\"]\n",
    "NODULES_SHAPE=[\"oval\",\"round\",\"lobulated\",\"irregular\",\"unknown shape\"]\n",
    "NODULES_MARGIN=[\"circumscribed\",\"spiculated\",\"indistinct\",\"not circumscribed\",\"unknown margin\"]\n",
    "NODULES_ECHOGENICITY=[\"hypoechoic\", \"isoechoic\", \"heterogeneous\",\"complex cystic and solid\",\"unknown echogenicity\"]\n",
    "NODULES_KNOWN=[\"no known\", \"yes known\"]\n",
    "NODULES_STABLE=[\"grown stable\",\"shrunk stable\", \"yes stable\"]\n",
    "\n",
    "DICTIONARY={\"tipo\":TIPO,\"tecnica\":TECNICA,\"family\":FAMILY,\"prosthesis\":PROSTHESIS,\"birads\":BIRADS,\"density_mammo\":DENSITY_MAMMO,\"calcifications_benign\":CALCIFICATIONS_BENIGN,\n",
    "            \"ganglio_mamo\":GANGLIO_MAMO,\"density_echo\":DENSITY_ECHO,\"lymph_benign\":LYMPH_BENIGN,\"lymph_suspicious\":LYMPH_SUSPICIOUS,\"simple_cyst\":SIMPLE_CYST,\"ductal_ectasia\":DUCTAL_ECTASIA,\n",
    "           \"nodules_echo\": NODULES_ECHO,\"nodules_shape\":NODULES_SHAPE,\"nodules_margin\":NODULES_MARGIN, \"nodules_echogenicity\":NODULES_ECHOGENICITY, \"nodules_known\":NODULES_KNOWN, \"nodules_stable\":NODULES_STABLE}\n",
    "\n",
    "def evaluate_per_question(predicted, tested, DICTIONARY, average=\"macro\"):\n",
    "    \"\"\"\n",
    "    Evaluate model predictions per question type.\n",
    "    \n",
    "    Parameters:\n",
    "    - predicted: array of predicted label indices (flattened from all folds)\n",
    "    - tested: array of true label indices (same shape as predicted)\n",
    "    - DICTIONARY: dict mapping each question to its list of class names\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Build global index → (question, class_name) mapping\n",
    "    idx_to_question_value = {}\n",
    "    offset = 0\n",
    "    question_offsets = {}\n",
    "    for question, class_list in DICTIONARY.items():\n",
    "        question_offsets[question] = offset\n",
    "        for i, label in enumerate(class_list):\n",
    "            idx_to_question_value[offset + i] = (question, label)\n",
    "        offset += len(class_list)\n",
    "\n",
    "    # Step 2: Group predictions by question\n",
    "    per_question_true = defaultdict(list)\n",
    "    per_question_pred = defaultdict(list)\n",
    "\n",
    "    for true_idx, pred_idx in zip(tested, predicted):\n",
    "        q_true, _ = idx_to_question_value[true_idx]\n",
    "        # You can check if q_true == q_pred here for safety if needed\n",
    "        per_question_true[q_true].append(int(true_idx))\n",
    "        per_question_pred[q_true].append(int(pred_idx))\n",
    "\n",
    "    # Step 3: Classification reports\n",
    "\n",
    "    f1s={}\n",
    "    accuracies={}\n",
    "    for question, true_labels in per_question_true.items():\n",
    "        pred_labels = per_question_pred[question]\n",
    "        label_names = DICTIONARY[question]\n",
    "        start = question_offsets[question]\n",
    "        end = start + len(label_names)\n",
    "        question_label_ids = list(range(start, end))\n",
    "        # print(question)\n",
    "        #Añadimos el family history third que los BERT modelos no pueden capturar\n",
    "        print(len(true_labels))\n",
    "        if question==\"family\":\n",
    "            print(len(true_labels))\n",
    "            true_labels=[200]+true_labels\n",
    "            pred_labels=[7]+pred_labels\n",
    "            print(len(true_labels))\n",
    "        \n",
    "        f1=f1_score(true_labels,pred_labels,labels=sorted(set(true_labels)),average=average)\n",
    "        f1s[question]=f1\n",
    "        accuracy=accuracy_score(true_labels,pred_labels)\n",
    "        accuracies[question]=accuracy\n",
    "    return f1s,accuracies        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a058ab-7e98-4f96-b778-d525fe51543a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "models=[\"predicted_biobert\",\"predicted_biomed\",\"predicted_bluebert\"]\n",
    "accuracies=defaultdict(list)\n",
    "f1s=defaultdict(list)\n",
    "for model in models:\n",
    "    model_truth=re.sub(\"predicted\",\"tested\",model)\n",
    "    truth=np.load(f\"test_results/{model_truth}_classification.npy\")\n",
    "    outputs=np.load(f\"test_results/{model}_classification.npy\")\n",
    "    print(truth)\n",
    "    \n",
    "    f1s_model,accuracies_model=evaluate_per_question(outputs,truth,DICTIONARY)\n",
    "    accuracies[\"model\"].append(model)\n",
    "    f1s[\"model\"].append(model)\n",
    "    for question in DICTIONARY.keys():\n",
    "        accuracies[question].append(accuracies_model[question])\n",
    "        f1s[question].append(f1s_model[question])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8336560a-4c56-4552-b484-a21abe8f9f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame(f1s)\n",
    "data=data.set_index(\"model\")\n",
    "data['average'] = data.mean(axis=1)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121c8184-ae73-4825-9baa-bc93a3ebdc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "biomed_f1 = list(data.loc[\"predicted_biomed\",:])[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e28930-a539-4018-ae68-97ec8cd675d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame(accuracies)\n",
    "data=data.set_index(\"model\")\n",
    "data['average'] = data.mean(axis=1)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b563228-d78b-4afc-afc3-a240cd67b9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "biomed_acc = list(data.loc[\"predicted_biomed\",:])[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa542dc-1937-460e-bad3-74ac73a7e14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "\n",
    "\n",
    "# Perform Wilcoxon signed-rank test (one-sided: model1 > model2)\n",
    "statistic, p_value = wilcoxon(biogpt_acc, biomed_acc, alternative='greater')\n",
    "\n",
    "print(f\"Wilcoxon statistic: {statistic}\")\n",
    "print(f\"p-value: {p_value}\")\n",
    "\n",
    "# Perform Wilcoxon signed-rank test (one-sided: model1 > model2)\n",
    "statistic, p_value = wilcoxon(biogpt_f1, biomed_f1, alternative='greater')\n",
    "\n",
    "print(f\"Wilcoxon statistic f1: {statistic}\")\n",
    "print(f\"p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c0b11b-1413-4ebf-a010-94fe34577e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "biogpt=[1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.1677,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.0019,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.2638,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.8763,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.3209,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.4092,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.8641,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.5016,\n",
    " 0.1649,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.252,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.0623,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.9951,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.8368,\n",
    " 1.0,\n",
    " 0.3967,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.9867,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.489]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a8b243-a3a5-4a00-b69e-b2a3be52a3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "biogpt_no_age=[1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.1677,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.0019,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.2638,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.8763,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.3209,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.4092,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.8641,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.5016,\n",
    " 0.1649,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.252,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.0623,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.9951,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.8368,\n",
    " 1.0,\n",
    " 0.3967,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.9867,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.489]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a4b8b4-a0bc-4a63-9394-e22987c610e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BioMedBERT=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7013, 1.0, 1.0, 1.0, 0.1352, 0.1352, 1.0, -0.0418, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0964, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7602, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4887, 1.0, 0.1503, 1.0, 1.0, 1.0, 1.0, 0.7231, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8368, 1.0, 0.3967, 1.0, 1.0, 0.991, 1.0, 1.0, 0.5678, 1.0, 1.0, 1.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3244398e-e430-4955-94b4-0aebef46ae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "BioMedBERT_no_age=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7013, 1.0, 1.0, 1.0, 0.1352, 0.1352, 1.0, -0.0418, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0964, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7602, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4887, 1.0, 0.1503, 1.0, 1.0, 1.0, 1.0, 0.7231, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8368, 1.0, 0.3967, 1.0, 1.0, 0.991, 1.0, 1.0, 0.5678, 1.0, 1.0, 1.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272f5e19-33c1-42d5-ae3c-b01280a0ce6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "\n",
    "\n",
    "# Perform Wilcoxon signed-rank test (one-sided: model1 > model2)\n",
    "statistic, p_value = wilcoxon(BioMedBERT,biogpt, alternative='greater')\n",
    "\n",
    "print(f\"Wilcoxon statistic: {statistic}\")\n",
    "print(f\"p-value: {p_value}\")\n",
    "\n",
    "# Perform Wilcoxon signed-rank test (one-sided: model1 > model2)\n",
    "statistic, p_value = wilcoxon(BioMedBERT_no_age,biogpt_no_age, alternative='greater')\n",
    "\n",
    "print(f\"Wilcoxon statistic f1: {statistic}\")\n",
    "print(f\"p-value: {p_value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
