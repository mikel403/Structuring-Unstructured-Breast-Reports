{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a39df26-137d-4c5d-93cb-8d89499143d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9a4bc1-fba6-4f73-b3f8-26884c13772c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#symptomatic, location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "033e1180-456b-43ac-a0d7-e197dd58635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions=[\"age\",\"tipo\",\"tecnica\",\"family\",\"history\",\"symtomatic\",\n",
    "           \"prosthesis\",\"birads\",\"density_mammo\",\"calcifications_benign\",\"density_echo\",\"ganglio_mamo\",\"lymph_benign\",\"lymph_suspicious\",\"parenchymal_distortion\",\"simple_cyst\",\"ductal_ectasia\",\n",
    "          \"nodules_echo_num\",\"nodules_echo_description\",\"nodules_echo_shape\",\"nodules_echo_margin\",\"nodules_echo_echogenicity\",\"nodules_echo_location\",\"nodules_echo_size\",\"nodules_echo_known\",\"nodules_echo_stable\"]\n",
    "questions=[\"tipo\",\"tecnica\",\"family\",\n",
    "           \"prosthesis\",\"birads\",\"density_mammo\",\"calcifications_benign\",\"ganglio_mamo\",\"density_echo\",\"lymph_benign\",\"lymph_suspicious\",\"simple_cyst\",\"ductal_ectasia\",\"nodules_echo_num\",\"nodules_echo_shape\",\"nodules_echo_margin\",\"nodules_echo_echogenicity\",\"nodules_echo_known\",\"nodules_echo_stable\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beb2e12b-a0bf-486b-a9c8-fbd25b15fa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "def calculate_f1(pred,truth,point=False,average='macro'):\n",
    "    pred_clean={}\n",
    "    truth_clean={}\n",
    "    for key,real in truth.items():\n",
    "        if key in pred:\n",
    "            \n",
    "            predicted=pred[key] \n",
    "            if point==True:\n",
    "                predicted=predicted.split(\".\")[0]+\".\"\n",
    "            elif point==\"mm\":\n",
    "                if \"unknown\" in predicted:\n",
    "                    predicted=predicted.split(\".\")[0]+\".\"\n",
    "                else:\n",
    "                    predicted=predicted.split(\"mm\")[0]+\"mm.\"\n",
    "                \n",
    "            pred_clean[key]=predicted.lower()\n",
    "            truth_clean[key]=str(real).lower()\n",
    "    # Get ground truth and predicted labels\n",
    "    y_true = list(truth_clean.values())\n",
    "    y_pred = list(pred_clean.values())\n",
    "    \n",
    "    # Define the valid labels based on the truth only\n",
    "    valid_labels = sorted(set(y_true))\n",
    "    \n",
    "    # Replace out-of-scope predictions with something invalid\n",
    "    # e.g., keep them but let them be counted as wrong\n",
    "    y_pred_cleaned = [\n",
    "        p if p in valid_labels else 'INVALID' for p in y_pred\n",
    "    ]\n",
    "    \n",
    "    # Now align with true values\n",
    "    y_true_final = []\n",
    "    y_pred_final = []\n",
    "    \n",
    "    for yt, yp in zip(y_true, y_pred_cleaned):\n",
    "        y_true_final.append(yt)\n",
    "        y_pred_final.append(yp)\n",
    "    \n",
    "    # Compute F1 over valid labels only\n",
    "    f1 = f1_score(\n",
    "        y_true_final,\n",
    "        y_pred_final,\n",
    "        labels=valid_labels,   # Only ground-truth classes\n",
    "        average='macro'        # or whatever average you want\n",
    "    )\n",
    "    report = classification_report(\n",
    "        y_true,\n",
    "        y_pred_cleaned,\n",
    "        labels=valid_labels,     # Only ground truth classes\n",
    "        zero_division=0,         # Avoid warnings for undefined precision/recall\n",
    "        digits=4                 # Optional: better precision\n",
    "    )\n",
    "    print(report)\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b4cc2ae-b72e-4f9c-8ec5-078c1bf19cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_acc(pred,truth,point=False):\n",
    "    acc=0\n",
    "    total=0\n",
    "    for key,real in truth.items():\n",
    "        if key in pred:\n",
    "            total+=1\n",
    "            predicted=pred[key]    \n",
    "            if point==True:\n",
    "\n",
    "                predicted=predicted.split(\".\")[0]+\".\"\n",
    "\n",
    "            elif point==\"mm\":\n",
    "                if \"unknown\" in predicted:\n",
    "                    predicted=predicted.split(\".\")[0]+\".\"\n",
    "                else:\n",
    "                    predicted=predicted.split(\"mm\")[0]+\"mm.\"\n",
    "            if predicted.lower()==str(real).lower():\n",
    "                acc+=1\n",
    "            # else:\n",
    "            #     print(key,real,predicted)\n",
    "        # else:\n",
    "        #     print(key)\n",
    "    return acc/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978a8c48-c9ed-4f98-be5a-34e2b3e73913",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accuracies=defaultdict(list)\n",
    "f1s=defaultdict(list)\n",
    "models=[\"biogpt\"+\"51e535e65\"+\"no_copy\"+\"description\"+\"16batch\"+\"final_answer_freeze\",\"biogptQA2e55e66no_copydescription8batchfinal\",\"biogptQA1e55e66no_copydescription8batchfinal\",\"clinicalt5\"+\"1e47\"+\"no_copy\"+\"description\"+\"16batch\"+\"final\"+\"tokenized\",\"clinicalt5\"+\"1e45\"+\"no_copy\"+\"description\"+\"16batch\"+\"final\"+\"tokenized\",\"clinicalt55e58no_copydescription16batchfinal\",\"clinicalt57e510no_copydescription16batchfinal\",\"clinicalt5\"+\"7e57\"+\"no_copy\"+\"description\"+\"16batch\"+\"final\",\"clinicalt5\"+\"7e57\"+\"no_copy\"+\"description\"+\"16batch\"+\"final\"+\"tokenized\",\"clinicalt5\"+\"7e53\"+\"no_copy\"+\"description\"+\"16batch\"+\"final\"+\"tokenized\",\"biogpt1e57no_copydescription16batchfinal\",\"biogpt21e51e57no_copydescription16batchfinal\",\"biogpt21e51e55no_copydescription16batchfinal\",\"biogpt\"+\"1e57\"+\"no_copy\"+\"description\"+\"16batch\"+\"final\"+\"no_info\"]\n",
    "for model in models:\n",
    "    accuracies[\"model\"].append(model)\n",
    "    f1s[\"model\"].append(model)\n",
    "    for tipo in questions:\n",
    "        print(tipo,model)\n",
    "        \n",
    "        with open(f\"Generativos/truth_dic/{tipo}.pkl\", \"rb\") as file:\n",
    "                truth=pickle.load(file)\n",
    "        with open(f\"Generativos/results_dic_{tipo}/{model}.pkl\", \"rb\") as file:\n",
    "                output=pickle.load(file)\n",
    "        if tipo==\"age\":\n",
    "            print(truth)\n",
    "            print(output)\n",
    "        if tipo!=\"nodules_echo_size\":\n",
    "            acc=calculate_acc(output,truth,point=True)\n",
    "            f1=calculate_f1(output,truth,point=True)\n",
    "        else:\n",
    "            acc=calculate_acc(output,truth,point=\"mm\")\n",
    "            \n",
    "            f1=calculate_f1(output,truth,point=\"mm\")\n",
    "        accuracies[tipo].append(acc)\n",
    "        f1s[tipo].append(f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbfe9f1-4042-4ace-aad8-59976ff2e9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame(accuracies)\n",
    "data=data.set_index(\"model\")\n",
    "data['average'] = data.mean(axis=1)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee4aa476-5508-4bdb-99db-c8c49c3cde1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "biogpt_acc = list(data.loc[\"biogpt1e57no_copydescription16batchfinal\",:])[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0035f20b-2abf-4352-bcf3-533109c5c84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame(f1s)\n",
    "data=data.set_index(\"model\")\n",
    "data['average'] = data.mean(axis=1)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e9b5769-b3fd-45e8-9416-29604fd771db",
   "metadata": {},
   "outputs": [],
   "source": [
    "biogpt_f1 = list(data.loc[\"biogpt1e57no_copydescription16batchfinal\",:])[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e44825d-0313-4240-84cf-6bf87c3d65bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIPO=[\"biopsy report\", \"nodal staging ultrasound report\", \"normal control or revision report\"]\n",
    "TECNICA=[\"only ultrasound study\", \"only mammography study\", \"mammography and ultrasound\"]\n",
    "FAMILY=[\"no family history\", \"first degree\", \"second degree\"]\n",
    "PROSTHESIS=[\"no prosthesis\",\"yes prosthesis\"]\n",
    "BIRADS=[\"BI-RADS 0\",\"BI-RADS 1\",\"BI-RADS 2\",\"BI-RADS 3\",\"BI-RADS 4A\",\"BI-RADS 4B\",\"BI-RADS 4C\",\"BI-RADS 5\",\"BI-RADS 6\"]\n",
    "DENSITY_MAMMO=[\"ACR A\",\"ACR B\",\"ACR C\",\"ACR D\",\"unknown density mammo\"]\n",
    "CALCIFICATIONS_BENIGN=[\"no calcifications\",\"yes calcifications\"]\n",
    "GANGLIO_MAMO=[\"no ganglio\",\"yes ganglio\"]\n",
    "DENSITY_ECHO=[\"homogeneous fibroglandular\",\"heterogeneous fibroglandular\",\"fibroglandular and fat\",\"homogeneous fatty\",\"unknown density echo\"]\n",
    "LYMPH_BENIGN=[\"no lymph benign\",\"yes lymph benign\"]\n",
    "LYMPH_SUSPICIOUS=[\"no lymph suspicious\",\"yes lymph suspicious\"]\n",
    "SIMPLE_CYST=[\"no cyst\",\"yes cyst\"]\n",
    "DUCTAL_ECTASIA=[\"no ectasia\",\"yes ectasia\"]\n",
    "NODULES_ECHO=[\"no nodules\", \"yes nodules\"]\n",
    "NODULES_SHAPE=[\"oval\",\"round\",\"lobulated\",\"irregular\",\"unknown shape\"]\n",
    "NODULES_MARGIN=[\"circumscribed\",\"spiculated\",\"indistinct\",\"not circumscribed\",\"unknown margin\"]\n",
    "NODULES_ECHOGENICITY=[\"hypoechoic\", \"isoechoic\", \"heterogeneous\",\"complex cystic and solid\",\"unknown echogenicity\"]\n",
    "NODULES_KNOWN=[\"no known\", \"yes known\"]\n",
    "NODULES_STABLE=[\"grown stable\",\"shrunk stable\", \"yes stable\"]\n",
    "\n",
    "DICTIONARY={\"tipo\":TIPO,\"tecnica\":TECNICA,\"family\":FAMILY,\"prosthesis\":PROSTHESIS,\"birads\":BIRADS,\"density_mammo\":DENSITY_MAMMO,\"calcifications_benign\":CALCIFICATIONS_BENIGN,\n",
    "            \"ganglio_mamo\":GANGLIO_MAMO,\"density_echo\":DENSITY_ECHO,\"lymph_benign\":LYMPH_BENIGN,\"lymph_suspicious\":LYMPH_SUSPICIOUS,\"simple_cyst\":SIMPLE_CYST,\"ductal_ectasia\":DUCTAL_ECTASIA,\n",
    "           \"nodules_echo\": NODULES_ECHO,\"nodules_shape\":NODULES_SHAPE,\"nodules_margin\":NODULES_MARGIN, \"nodules_echogenicity\":NODULES_ECHOGENICITY, \"nodules_known\":NODULES_KNOWN, \"nodules_stable\":NODULES_STABLE}\n",
    "\n",
    "def evaluate_per_question(predicted, tested, DICTIONARY, average=\"macro\"):\n",
    "    \"\"\"\n",
    "    Evaluate model predictions per question type.\n",
    "    \n",
    "    Parameters:\n",
    "    - predicted: array of predicted label indices (flattened from all folds)\n",
    "    - tested: array of true label indices (same shape as predicted)\n",
    "    - DICTIONARY: dict mapping each question to its list of class names\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Build global index â†’ (question, class_name) mapping\n",
    "    idx_to_question_value = {}\n",
    "    offset = 0\n",
    "    question_offsets = {}\n",
    "    for question, class_list in DICTIONARY.items():\n",
    "        question_offsets[question] = offset\n",
    "        for i, label in enumerate(class_list):\n",
    "            idx_to_question_value[offset + i] = (question, label)\n",
    "        offset += len(class_list)\n",
    "\n",
    "    # Step 2: Group predictions by question\n",
    "    per_question_true = defaultdict(list)\n",
    "    per_question_pred = defaultdict(list)\n",
    "\n",
    "    for true_idx, pred_idx in zip(tested, predicted):\n",
    "        q_true, _ = idx_to_question_value[true_idx]\n",
    "        # You can check if q_true == q_pred here for safety if needed\n",
    "        per_question_true[q_true].append(true_idx)\n",
    "        per_question_pred[q_true].append(pred_idx)\n",
    "\n",
    "    # Step 3: Classification reports\n",
    "\n",
    "    f1s={}\n",
    "    accuracies={}\n",
    "    for question, true_labels in per_question_true.items():\n",
    "        pred_labels = per_question_pred[question]\n",
    "        label_names = DICTIONARY[question]\n",
    "        start = question_offsets[question]\n",
    "        end = start + len(label_names)\n",
    "        question_label_ids = list(range(start, end))\n",
    "        f1=f1_score(true_labels,pred_labels,labels=sorted(set(true_labels)),average=average)\n",
    "        f1s[question]=f1\n",
    "        accuracy=accuracy_score(true_labels,pred_labels)\n",
    "        accuracies[question]=accuracy\n",
    "    return f1s,accuracies        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36a058ab-7e98-4f96-b778-d525fe51543a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "models=[\"predicted_bio\",\"predicted_biomed__no_prior\",\"predicted_biomed_8epoch\",\"predicted_biomed\",\"predicted_biomed_8epoch_truncate\",\"predicted_blue2\",\"predicted_biomed_8epoch_no_info\"]\n",
    "accuracies=defaultdict(list)\n",
    "f1s=defaultdict(list)\n",
    "for model in models:\n",
    "    model_truth=re.sub(\"predicted\",\"tested\",model)\n",
    "    truth=np.load(f\"BERT/{model_truth}.npy\")\n",
    "    outputs=np.load(f\"BERT/{model}.npy\")\n",
    "    f1s_model,accuracies_model=evaluate_per_question(outputs,truth,DICTIONARY)\n",
    "    accuracies[\"model\"].append(model)\n",
    "    f1s[\"model\"].append(model)\n",
    "    for question in DICTIONARY.keys():\n",
    "        accuracies[question].append(accuracies_model[question])\n",
    "        f1s[question].append(f1s_model[question])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8336560a-4c56-4552-b484-a21abe8f9f63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data=pd.DataFrame(f1s)\n",
    "data=data.set_index(\"model\")\n",
    "data['average'] = data.mean(axis=1)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "073bdfbb-18d1-4c38-9630-1afe6d572a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "biomed_f1 = list(data.loc[\"predicted_biomed\",:])[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0ed602-4a6c-4700-93cb-74d6a2110826",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame(accuracies)\n",
    "data=data.set_index(\"model\")\n",
    "data['average'] = data.mean(axis=1)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1db758a5-86d2-4517-81ff-c6698f6a4b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "biomed_acc = list(data.loc[\"predicted_biomed\",:])[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dadd1b-a8e7-4fcb-b9e1-4321497c885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "\n",
    "\n",
    "# Perform Wilcoxon signed-rank test (one-sided: model1 > model2)\n",
    "statistic, p_value = wilcoxon(biogpt_acc, biomed_acc, alternative='greater')\n",
    "\n",
    "print(f\"Wilcoxon statistic: {statistic}\")\n",
    "print(f\"p-value: {p_value}\")\n",
    "\n",
    "# Perform Wilcoxon signed-rank test (one-sided: model1 > model2)\n",
    "statistic, p_value = wilcoxon(biogpt_f1, biomed_f1, alternative='greater')\n",
    "\n",
    "print(f\"Wilcoxon statistic f1: {statistic}\")\n",
    "print(f\"p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "277c99ec-b4fd-4510-aba9-0955f9b261ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "BioMedBERT= [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4909, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.251, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1429, 0.1688, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1404, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.124, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2197, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8106, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8983, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2077, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.116, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5846, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7448, 1.0, 1.0, 1.0, 1.0, 0.7993, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5135, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1061, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0921, 1.0, 1.0, 0.791, 1.0, 0.1715, 0.8349, 0.0428, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0492, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4213, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.215, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2746, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1416, 1.0, 1.0, 1.0, 0.9432, 1.0, 1.0, 1.0, 1.0, 0.1577, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5547, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3d1c38b-73bf-40b3-8641-bce3bad6542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "biogpt=[1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.2917,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.4909,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.316,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.0527,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.251,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.6876,\n",
    " 0.146,\n",
    " 1.0,\n",
    " 0.1382,\n",
    " 0.8059,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.8059,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.2644,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.1616,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.2175,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.1423,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.5211,\n",
    " 1.0,\n",
    " 0.5211,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.5211,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.5211,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.5211,\n",
    " 1.0,\n",
    " 0.8087,\n",
    " 0.1618,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.8589,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.1786,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.3294,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.1156,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.961,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.1717,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.1757,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.1212,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.9459,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.1167,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.6714,\n",
    " 0.1913,\n",
    " 0.1913,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.433,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.788,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.8255,\n",
    " 0.5399,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.2685,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.8731,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.6953,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.8013,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.5633,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.7586,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.7297,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.901,\n",
    " 1.0,\n",
    " 0.2157,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.4595,\n",
    " 1.0,\n",
    " 0.3007,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.2157,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.9432,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.4039,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.5547,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 0.115,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0,\n",
    " 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf8acb0-7362-4858-b8a3-167bbf31ee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "\n",
    "\n",
    "# Perform Wilcoxon signed-rank test (one-sided: model1 > model2)\n",
    "statistic, p_value = wilcoxon(biogpt, BioMedBERT, alternative='greater')\n",
    "\n",
    "print(f\"Wilcoxon statistic: {statistic}\")\n",
    "print(f\"p-value: {p_value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
