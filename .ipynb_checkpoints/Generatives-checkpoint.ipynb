{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07fc9303-1647-4617-bb73-65ba8a8eaa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions=[\"age\",\"tipo\",\"tecnica\",\"family\",\"history\",\"symtomatic\",\n",
    "           \"prosthesis\",\"birads\",\"density_mammo\",\"density_echo\",\"lymph_suspicious\",\n",
    "          \"nodules_echo_num\",\"nodules_echo_size\",\"nodules_echo_known\",\"nodules_echo_stable\"]\n",
    "\n",
    "    \n",
    "def flatten_and_filter_dataset(ground_truth,reports):\n",
    "    \"\"\"\n",
    "    Esta función toma un conjunto de datos en el formato original (con estructura jerárquica)\n",
    "    y devuelve un conjunto de datos plano, donde cada entrada tiene un solo `context`, `question` y `answer`.\n",
    "    \n",
    "    Argumentos:\n",
    "        dataset: Un conjunto de datos en formato original (puede ser train, validation, test).\n",
    "    \n",
    "    Retorno:\n",
    "        Un conjunto de datos de Hugging Face en formato plano, con solo ejemplos completos.\n",
    "    \"\"\"\n",
    "    # Lista para almacenar ejemplos en formato plano\n",
    "    flattened_examples = {}\n",
    "    examples_raw={}\n",
    "    targets={}\n",
    "    val_data={}\n",
    "    question_tipo={}\n",
    "    previous_message_answer_tipo={}\n",
    "    answers_tipo={}\n",
    "    j=0\n",
    "    \n",
    "    question_tipo[\"age\"]= \"does the patient's age appear in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"age\"]=\" Important! Search for numbers, but do not mistake it with the age of a familiar. If a number appears without any context it is surely the age. answer: \"\n",
    "\n",
    "    question_tipo[\"tipo\"]= 'is the following breast medical report a biopsy report or nodal staging ultrasound report?'\n",
    "    previous_message_answer_tipo[\"tipo\"]=\" Important! biopsy reports are normally Image-Guided Biopsy and nodal staging ultrasound reports can also be written as only axilla ultrasound exam. If it is any of these it will be written in the beginning of the report. answer: \"\n",
    "\n",
    "    question_tipo[\"tecnica\"]= 'what diagnostic technique was used in the following breast medical report?'\n",
    "    previous_message_answer_tipo[\"tecnica\"]=\"Important: Biopsy reports, simple cysts and analysis of lymph or axillary nodes are only seen on ultrasound. On the other hand, if the ACR density is given or parenchymal distortions are analysed, the technique will be a mammogram. The report may include an ultrasound examination, a mammography examination or both: \"\n",
    "    # Iterar sobre cada ejemplo en el conjunto de datos original\n",
    "\n",
    "    question_tipo[\"family\"]= \"does the patient have any family history in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"family\"]=\" Important! Family history of breast cancer is categorized based on the degree of relatives affected: First-degree relatives: Parents, siblings, or children. Second-degree relatives: Grandparents, aunts, uncles, nieces, nephews, or half-siblings. Third-degree relatives: Great-grandparents, great-aunts/uncles, or first cousins. answer: \"\n",
    "    \n",
    "    question_tipo[\"history\"]= \"does the patient have any non-familiar history in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"history\"]=\" Important! Check for the history at the beginning of the report. Normally it is a previous biopsy result, mastectomy or cancer. answer: \"\n",
    "\n",
    "    question_tipo[\"symtomatic\"]= \"Is the reason for the consultation that the patient is symptomatic in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"symtomatic\"]=\" Important! The answer is at the beginning of the report, in the reason for consultation. It is normally a palpable lump, lumpectomy or nodule, sometimes painful. answer: \"\n",
    "\n",
    "    question_tipo[\"prosthesis\"]= \"does the patient have a prosthesis in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"prosthesis\"]=\" Important! It is normally clearly indicated at the beginning of the report. answer: \"\n",
    "\n",
    "    question_tipo[\"birads\"]= \"What is the final BI-RADS classification given to the patient in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"birads\"]=\" Important! The final BI-RADS of the patient is given in the conclusions of the report. answer: \"\n",
    "\n",
    "    question_tipo[\"density_mammo\"]= \"What is the breast density found in the mammography study in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"density_mammo\"]=\" Important! Breast density in mammography is classified into four categories: ACR A (Almost entirely fatty), ACR B (Scattered areas of fibroglandular density), ACR C (Heterogeneously dense), ACR D (Extremely or very dense). answer: \"\n",
    "    \n",
    "   \n",
    "    question_tipo[\"density_echo\"]= \"What is the breast density found in the ultrasound study in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"density_echo\"]=\" Important! Breast composition in ultrasound is classified into three categories: fibroglandular and fat (mixed distribution of fibroglandular and adipose tissue), heterogeneous fibroglandular (predominantly fibroglandular tissue with varying echogenicity and scattered fat areas), and homogeneous fibroglandular (uniform fibroglandular tissue with consistent echogenicity and minimal fat content). answer: \"\n",
    "\n",
    "    question_tipo[\"lymph_suspicious\"]= \"Does the report mention any suspicious axillary lymph nodes in the ultrasound exam of the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"lymph_suspicious\"]=\"Important! if a lymph node is suspicious the report will recomend a biopsy or Fine Needle Aspiration. A lymph node is considered suspicious when it has eccentric cortical thickening ≥ 3 mm, round shape, loss of fatty hilum, abnormal vascularity, or irregular margins—especially when associated with known malignancy or progressive enlargement. They can also be classified as UN 3, UN 4 or UN 5. answer:\"\n",
    "\n",
    "    question_tipo[\"nodules_echo_num\"]= \"How many nodules are described in the ultrasound exam of the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"nodules_echo\"]=\"Important! Do not consider if a nodule is described in the mammography exam. Sometimes they can not be counted so 'several' can be answered. The localization, echogenicity and size of the nodules are normally said. answer:\"\n",
    "\n",
    "    question_tipo[\"nodules_echo_size\"]= \"What is the size of the first nodule described in the ultrasound exam of the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"nodules_echo_size\"]=\"Important! Do not consider if a nodule is described in the mammography exam. The localization, echogenicity and size of the nodules are normally said. answer:\"\n",
    "\n",
    "    question_tipo[\"nodules_echo_known\"]= \"Is it the first nodule described in the ultrasound exam previously known in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"nodules_echo_known\"]=\"Important! Do not consider if a nodule is described in the mammography exam. If the nodule is known from before the examination, it will be analysed to see if it is stable. answer:\"\n",
    "\n",
    "    question_tipo[\"nodules_echo_stable\"]= \"Is it the first known nodule described in the ultrasound exam stable in the following breast medical report?\"\n",
    "    previous_message_answer_tipo[\"nodules_echo_stable\"]=\"Important! Do not consider if a nodule is described in the mammography exam. If the nodule is known from before the examination, it will be analysed to see if it is stable or if it got bigger or smaller. answer:\"\n",
    "    \n",
    "    for i, report in enumerate(reports[\"informes_ingles\"]):\n",
    "        informe=preprocess_text(report)\n",
    "        key=reports[\"keys\"][i]\n",
    "        \n",
    "        if key not in ground_truth.index:\n",
    "            continue\n",
    "        \n",
    "        row=ground_truth.loc[key]\n",
    "\n",
    "        #AGE\n",
    "        age=str(row[\"Age\"])\n",
    "        answer_tipo={}\n",
    "        # Verificar si el ejemplo tiene preguntas\n",
    "        if age.isdigit():\n",
    "            answer_tipo[\"age\"]=age\n",
    "            \n",
    "        else:\n",
    "            answer_tipo[\"age\"]=\"no\"\n",
    "        \n",
    "        #TIPO\n",
    "        if row[\"Biopsy_report\"]==\"Yes\":\n",
    "            answer_tipo[\"tipo\"]=\"yes\"\n",
    "            \n",
    "        elif row[\"BI-RADS_6_report\"]==\"Yes\":\n",
    "            answer_tipo[\"tipo\"]=\"yes\"\n",
    "        elif row[\"Ganglio_report\"]==\"Yes\":\n",
    "            answer_tipo[\"tipo\"]=\"yes\"\n",
    "        else:\n",
    "            answer_tipo[\"tipo\"]=\"no\"\n",
    "        \n",
    "        #TECHNIQUE\n",
    "        tecnica=row[\"Technique\"]\n",
    "        # Verificar si el ejemplo tiene preguntas\n",
    "        if tecnica==\"ultrasound\":\n",
    "            answer_tipo[\"tecnica\"]=\"only ultrasound study was performed\"            \n",
    "        elif tecnica==\"mammography\":\n",
    "            answer_tipo[\"tecnica\"]=\"only mammography study was performed\"\n",
    "        elif not pd.isna(tecnica):\n",
    "            answer_tipo[\"tecnica\"]=tecnica+\" was performed\"\n",
    "        else:\n",
    "            print(key,report)\n",
    "        \n",
    "        # \n",
    "        # HISTORY\n",
    "        history=row[\"Other_history\"]\n",
    "        # Verificar si el ejemplo tiene preguntas\n",
    "        if not isinstance(history,str) or history==\"No\":\n",
    "            answer_tipo[\"history\"]=\"no history was found\"            \n",
    "        else:\n",
    "            answer_tipo[\"history\"]=history\n",
    "\n",
    "        # FAMILY\n",
    "        family=row[\"Family_history\"]\n",
    "        # Verificar si el ejemplo tiene preguntas\n",
    "        if not isinstance(family,str) or family==\"No\":\n",
    "            answer_tipo[\"family\"]=\"no family history\"            \n",
    "        else:\n",
    "            answer_tipo[\"family\"]=family\n",
    "\n",
    "        # SYMTOMATIC\n",
    "        symtomatic=row[\"Syntomatic\"]\n",
    "        # Verificar si el ejemplo tiene preguntas\n",
    "        if not isinstance(symtomatic,str) or symtomatic==\"No\" or symtomatic==\"No estoy seguro\":\n",
    "            answer_tipo[\"symtomatic\"]=\"Non-symptomatic consultation\"            \n",
    "        else:\n",
    "            answer_tipo[\"symtomatic\"]=symtomatic\n",
    "\n",
    "        # PROSTHESIS\n",
    "        prosthesis=row[\"Prosthesis\"]\n",
    "        # Verificar si el ejemplo tiene preguntas\n",
    "        if not isinstance(prosthesis,str) or prosthesis==\"No\":\n",
    "            answer_tipo[\"prosthesis\"]=\"no\"            \n",
    "        else:\n",
    "            answer_tipo[\"prosthesis\"]=\"yes\"\n",
    "\n",
    "        #BIRADS\n",
    "        birads=row[\"BI-RADS\"]\n",
    "        # Verificar si el ejemplo tiene preguntas\n",
    "        if not isinstance(birads,str):\n",
    "            answer_tipo[\"birads\"]=\"none\"            \n",
    "        else:\n",
    "            answer_tipo[\"birads\"]=birads\n",
    "\n",
    "        #Density mammo\n",
    "        density_mammo=row[\"Density_mamo\"]\n",
    "        # Verificar si el ejemplo tiene preguntas\n",
    "        if not isinstance(density_mammo,str):\n",
    "            answer_tipo[\"density_mammo\"]=\"none\"            \n",
    "        else:\n",
    "            answer_tipo[\"density_mammo\"]=density_mammo\n",
    "\n",
    "        #Density echo\n",
    "        density_echo=row[\"Density_eco\"]\n",
    "        # Verificar si el ejemplo tiene preguntas\n",
    "        if not isinstance(density_echo,str):\n",
    "            answer_tipo[\"density_echo\"]=\"no density was found\"            \n",
    "        else:\n",
    "            answer_tipo[\"density_echo\"]=density_echo\n",
    "\n",
    "        #Suspicious lymph nodes\n",
    "        lymph_suspicious=row[\"Ganglio_suspicious_eco\"]\n",
    "        # Verificar si el ejemplo tiene preguntas\n",
    "        if not isinstance(lymph_suspicious,str):\n",
    "            answer_tipo[\"lymph_suspicious\"]=\"no\"            \n",
    "        else:\n",
    "            answer_tipo[\"lymph_suspicious\"]=lymph_suspicious.lower()\n",
    "\n",
    "        #Nodules echo\n",
    "        nodules_echo=row[\"Nodules_eco\"]\n",
    "        # Verificar si el ejemplo tiene preguntas\n",
    "        if not isinstance(nodules_echo,str) and not isinstance(nodules_echo,int):\n",
    "            answer_tipo[\"nodules_echo_num\"]=\"none\"            \n",
    "        else:\n",
    "            answer_tipo[\"nodules_echo_num\"]=nodules_echo\n",
    "\n",
    "        #Si existen nódulos se hace las preguntas correspondientes\n",
    "        if answer_tipo[\"nodules_echo_num\"]!=\"none\":\n",
    "            \n",
    "            #Nodules echo size\n",
    "            nodules_echo_size=row[\"size_eco_1\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(nodules_echo_size,str):\n",
    "                answer_tipo[\"nodules_echo_size\"]=\"no size was found\"            \n",
    "            else:\n",
    "                answer_tipo[\"nodules_echo_size\"]=nodules_echo_size\n",
    "    \n",
    "            #Nodules echo known\n",
    "            nodules_echo_known=row[\"new_eco_1\"]\n",
    "            # Verificar si el ejemplo tiene preguntas\n",
    "            if not isinstance(nodules_echo_known,str):\n",
    "                answer_tipo[\"nodules_echo_known\"]=\"unkown\"\n",
    "            elif nodules_echo_known==\"no\":\n",
    "                answer_tipo[\"nodules_echo_known\"]=\"yes\"            \n",
    "            else:\n",
    "                answer_tipo[\"nodules_echo_known\"]=\"no\"\n",
    "\n",
    "            if nodules_echo_known==\"yes\":\n",
    "                #Nodules echo stable\n",
    "                nodules_echo_stable=row[\"table_eco_1\"]\n",
    "                # Verificar si el ejemplo tiene preguntas\n",
    "                if not isinstance(nodules_echo_stable,str):\n",
    "                    answer_tipo[\"nodules_echo_stable\"]=\"It does not say\"\n",
    "                else:\n",
    "                    answer_tipo[\"nodules_echo_stable\"]=nodules_echo_stable\n",
    "            \n",
    "        for tipo in questions:\n",
    "            #Si está el tipo en las respuestas que hemos recogido lo metemos a la base de datos.\n",
    "            if tipo in answer_tipo:\n",
    "                key_tipo=key+\"_\"+tipo\n",
    "                if key_tipo in flattened_examples:\n",
    "                    key_tipo=key_tipo+\"_copy\"\n",
    "                examples_raw[key_tipo]=report\n",
    "        \n",
    "                inputs_tipo = \"question: \" + question_tipo[tipo] + \" context: \" + informe + previous_message_answer_tipo[tipo]+ answer_tipo[tipo]\n",
    "                flattened_examples[key_tipo]=inputs_tipo\n",
    "                targets[key_tipo]=answer_tipo[tipo]\n",
    "                \n",
    "                val_data[key_tipo]=\"question: \" + question_tipo[tipo] + \" context: \" + informe +previous_message_answer_tipo[tipo]\n",
    "                if tipo==\"tecnica\":\n",
    "                    print(targets[key_tipo])\n",
    "    return flattened_examples,targets,val_data,examples_raw\n",
    "\n",
    "def tokenize_function(inputs):\n",
    "    # Tokenizar el batch completo\n",
    "    model_inputs = tokenizer(\n",
    "        inputs[\"text\"], \n",
    "        max_length=1024, \n",
    "        truncation=True, \n",
    "        padding=\"max_length\", \n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # Crear las labels como una copia de los input_ids\n",
    "    labels = model_inputs[\"input_ids\"].clone()\n",
    "\n",
    "    # Obtener la secuencia de tokens para \"answer:\" (sin el token `<s>`)\n",
    "    answer_colon_tokens = tokenizer(\"answer:\").input_ids[1:]  # Ahora solo [9412, 20]\n",
    "\n",
    "    # Iterar sobre cada entrada en el batch\n",
    "    for idx in range(labels.shape[0]):  \n",
    "        input_ids = model_inputs[\"input_ids\"][idx].tolist()  # Convertir a lista para iterar\n",
    "        answer_start_idx = -1\n",
    "\n",
    "        # Buscar la secuencia exacta \"answer:\" en input_ids\n",
    "        for i in range(len(input_ids) - len(answer_colon_tokens) + 1):\n",
    "            if input_ids[i : i + len(answer_colon_tokens)] == answer_colon_tokens:\n",
    "                answer_start_idx = i + len(answer_colon_tokens)  # Inicio de la respuesta\n",
    "                break\n",
    "\n",
    "        if answer_start_idx != -1:\n",
    "            labels[idx, :answer_start_idx] = -100  # Enmascarar todo antes de la respuesta\n",
    "        else:\n",
    "            labels[idx, :] = -100  # Si no se encuentra, enmascarar todo\n",
    "\n",
    "    # Enmascarar también los tokens de padding\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "\n",
    "    return {\"input_ids\": model_inputs[\"input_ids\"], \"labels\": labels}\n",
    "def tokenize_function_test(inputs):\n",
    "    model_inputs = tokenizer(inputs[\"text\"], max_length=1024, padding_side='left',truncation=True,padding=\"max_length\",return_tensors=\"pt\")\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "def cross_validation(X,Y):\n",
    "    random.seed(1)\n",
    "    np.random.seed(1)\n",
    "    predicted=[]\n",
    "    tested=[]\n",
    "    acc_cv=[]\n",
    "    kappa_cv=[]\n",
    "    ind_cv={tipo:[] for tipo in questions}\n",
    "    preds_category_cv={tipo:[] for tipo in questions}\n",
    "    labels_category_cv={tipo:[] for tipo in questions}\n",
    "    accuracies_cv={tipo:[] for tipo in questions}\n",
    "    for i in range(10):\n",
    "        train, test, ind = test_train_split(i,X,Y)\n",
    "        \n",
    "        del train[\"val_data\"]\n",
    "        test_val_during_training=test.loc[:,[\"text\",\"label\"]]\n",
    "        del test[\"text\"]\n",
    "        test.columns=[\"text\",\"label\"]\n",
    "        # Diferenciamos el fit cuando el resultado es categorical o no.\n",
    "        print(len(train),len(test))\n",
    "        \n",
    "        \n",
    "        # model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "        model=AutoModelForCausalLM.from_pretrained(model_name)\n",
    "        train_data = Dataset.from_pandas(train)\n",
    "        test_data=Dataset.from_pandas(test)\n",
    "        test_val_during_training=Dataset.from_pandas(test_val_during_training)\n",
    "        train_data = train_data.map(tokenize_function, batched=True)\n",
    "        # train_data = train_data.rename_column(\"label\", \"labels\")\n",
    "        train_data = train_data.remove_columns([\"text\",\"label\"])\n",
    "        train_data.set_format(\"torch\")\n",
    "        test_val_during_training = test_val_during_training.map(tokenize_function, batched=True)\n",
    "        # train_data = train_data.rename_column(\"label\", \"labels\")\n",
    "        test_val_during_training = test_val_during_training.remove_columns([\"text\",\"label\"])\n",
    "        test_val_during_training.set_format(\"torch\")\n",
    "        \n",
    "        test_data_all = test_data.map(tokenize_function_test, batched=True)\n",
    "        # test_data_all = test_data.rename_column(\"label\", \"labels\")\n",
    "        test_data_all = test_data_all.remove_columns([\"text\",\"label\"])\n",
    "        test_data_all.set_format(\"torch\")\n",
    "        trainer = Trainer(\n",
    "        model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_data,\n",
    "            eval_dataset=test_val_during_training  # Si tienes datos de validación, úsalos aquí\n",
    "        )\n",
    "        trainer.train()\n",
    "        test_data={}\n",
    "        test_label={}\n",
    "        \n",
    "        for tipo in questions:\n",
    "            #Primero creamos la lista y luego vemos que no esté vacía para hacer el stack\n",
    "            data=[output for j,output in enumerate(test_data_all[\"input_ids\"].to(\"cuda\")) if \"_\"+tipo in ind[j]]\n",
    "            \n",
    "            if data:\n",
    "                test_data[tipo]=torch.stack(data)\n",
    "\n",
    "            labels=[output for j,output in enumerate(test[\"label\"]) if \"_\"+tipo in ind[j]]\n",
    "            if labels:\n",
    "                test_label[tipo]=labels\n",
    "        \n",
    "        \n",
    "        outputs={}\n",
    "        model=model.to(\"cuda\")\n",
    "        if \"age\" in test_data:\n",
    "            outputs[\"age\"] = model.generate(\n",
    "                test_data[\"age\"],         # Solo `input_ids` es necesario para la generación\n",
    "                max_new_tokens=1,              # Longitud máxima de la respuesta generada\n",
    "                num_beams=1,      # Número de respuestas a generar\n",
    "                \n",
    "                early_stopping=True          # Detener temprano si se alcanza una condición de finalización\n",
    "            ).cpu()\n",
    "        if \"tipo\" in test_data:\n",
    "            outputs[\"tipo\"] = model.generate(\n",
    "                test_data[\"tipo\"],         # Solo `input_ids` es necesario para la generación\n",
    "                max_new_tokens=1,              # Longitud máxima de la respuesta generada\n",
    "                num_beams=1,      # Número de respuestas a generar\n",
    "                \n",
    "                early_stopping=True          # Detener temprano si se alcanza una condición de finalización\n",
    "            ).cpu()\n",
    "\n",
    "        print(test_data[\"tecnica\"])\n",
    "        if \"tecnica\" in test_data:\n",
    "            outputs[\"tecnica\"] = model.generate(\n",
    "                test_data[\"tecnica\"],         # Solo `input_ids` es necesario para la generación\n",
    "                max_new_tokens=3,              # Longitud máxima de la respuesta generada\n",
    "                num_beams=2,      # Número de respuestas a generar\n",
    "                num_return_sequences=1,\n",
    "                early_stopping=True          # Detener temprano si se alcanza una condición de finalización\n",
    "            ).cpu()\n",
    "        if \"history\" in test_data:\n",
    "            outputs[\"history\"] = model.generate(\n",
    "                test_data[\"history\"],         # Solo `input_ids` es necesario para la generación\n",
    "                max_new_tokens=15,              # Longitud máxima de la respuesta generada\n",
    "                num_beams=2,      # Número de respuestas a generar\n",
    "                num_return_sequences=1,\n",
    "                early_stopping=True          # Detener temprano si se alcanza una condición de finalización\n",
    "            ).cpu()\n",
    "        if \"symtomatic\" in test_data:\n",
    "            outputs[\"symtomatic\"] = model.generate(\n",
    "                test_data[\"symtomatic\"],         # Solo `input_ids` es necesario para la generación\n",
    "                max_new_tokens=5,              # Longitud máxima de la respuesta generada\n",
    "                num_beams=2,      # Número de respuestas a generar\n",
    "                early_stopping=True          # Detener temprano si se alcanza una condición de finalización\n",
    "            ).cpu()\n",
    "        if \"prosthesis\" in test_data:\n",
    "            outputs[\"prosthesis\"] = model.generate(\n",
    "                test_data[\"prosthesis\"],         # Solo `input_ids` es necesario para la generación\n",
    "                max_new_tokens=1,              # Longitud máxima de la respuesta generada\n",
    "                    \n",
    "                early_stopping=True          # Detener temprano si se alcanza una condición de finalización\n",
    "            ).cpu()\n",
    "        if \"birads\" in test_data:\n",
    "            outputs[\"birads\"] = model.generate(\n",
    "                test_data[\"birads\"],         # Solo `input_ids` es necesario para la generación\n",
    "                max_new_tokens=4,              # Longitud máxima de la respuesta generada\n",
    "                num_beams=2,\n",
    "                num_return_sequences=1,      # Número de respuestas a generar\n",
    "                early_stopping=True          # Detener temprano si se alcanza una condición de finalización\n",
    "            ).cpu()\n",
    "        if \"density_mammo\" in test_data:\n",
    "            outputs[\"density_mammo\"] = model.generate(\n",
    "                test_data[\"density_mammo\"],         # Solo `input_ids` es necesario para la generación\n",
    "                max_new_tokens=2,              # Longitud máxima de la respuesta generada\n",
    "                num_beams=2,\n",
    "                num_return_sequences=1,      # Número de respuestas a generar\n",
    "                early_stopping=True          # Detener temprano si se alcanza una condición de finalización\n",
    "            ).cpu()\n",
    "        if \"density_echo\" in test_data:\n",
    "            outputs[\"density_echo\"] = model.generate(\n",
    "                test_data[\"density_echo\"],         # Solo `input_ids` es necesario para la generación\n",
    "                max_new_tokens=4,              # Longitud máxima de la respuesta generada\n",
    "                num_beams=2,\n",
    "                num_return_sequences=1,      # Número de respuestas a generar\n",
    "                early_stopping=True          # Detener temprano si se alcanza una condición de finalización\n",
    "            ).cpu()\n",
    "        if \"lymph_suspicious\" in test_data:\n",
    "            outputs[\"lymph_suspicious\"] = model.generate(\n",
    "                test_data[\"lymph_suspicious\"],         # Solo `input_ids` es necesario para la generación\n",
    "                max_new_tokens=1,              # Longitud máxima de la respuesta generada\n",
    "\n",
    "                early_stopping=True          # Detener temprano si se alcanza una condición de finalización\n",
    "            ).cpu()\n",
    "        if \"nodules_echo\" in test_data:\n",
    "            outputs[\"nodules_echo\"] = model.generate(\n",
    "                test_data[\"nodules_echo\"],         # Solo `input_ids` es necesario para la generación\n",
    "                max_new_tokens=1,              # Longitud máxima de la respuesta generada\n",
    "\n",
    "                early_stopping=True          # Detener temprano si se alcanza una condición de finalización\n",
    "            ).cpu()\n",
    "        if \"nodules_echo_size\" in test_data:\n",
    "            outputs[\"nodules_echo_size\"] = model.generate(\n",
    "                test_data[\"nodules_echo_size\"],         # Solo `input_ids` es necesario para la generación\n",
    "                max_new_tokens=6,              # Longitud máxima de la respuesta generada\n",
    "                num_beams=2,\n",
    "                num_return_sequences=1,      # Número de respuestas a generar\n",
    "                early_stopping=True          # Detener temprano si se alcanza una condición de finalización\n",
    "            ).cpu()\n",
    "        if \"nodules_echo_known\" in test_data:\n",
    "            outputs[\"nodules_echo_known\"] = model.generate(\n",
    "                test_data[\"nodules_echo_known\"],         # Solo `input_ids` es necesario para la generación\n",
    "                max_new_tokens=1,              # Longitud máxima de la respuesta generada\n",
    "\n",
    "                early_stopping=True          # Detener temprano si se alcanza una condición de finalización\n",
    "            ).cpu()\n",
    "        if \"nodules_echo_stable\" in test_data:\n",
    "            outputs[\"nodules_echo_stable\"] = model.generate(\n",
    "                test_data[\"nodules_echo_stable\"],         # Solo `input_ids` es necesario para la generación\n",
    "                max_new_tokens=1,              # Longitud máxima de la respuesta generada\n",
    "\n",
    "                early_stopping=True          # Detener temprano si se alcanza una condición de finalización\n",
    "            ).cpu()\n",
    "        \n",
    "        text_out={}\n",
    "        for tipo in questions:\n",
    "            if tipo in outputs:\n",
    "                text_out[tipo]=[re.search(r\"answer: (.+)\", texto).group(1) if re.search(r\"answer: (.+)\", texto) else \"\" for texto in tokenizer.batch_decode(outputs[tipo], skip_special_tokens=True)]\n",
    "                print(f\"{tipo} outputs\")\n",
    "                print(text_out[tipo])\n",
    "                print(f\"{tipo} labels\")\n",
    "                print(test_label[tipo])\n",
    "                \n",
    "        \n",
    "        # # Mostrar los resultados finales\n",
    "        # print(text_out_age)\n",
    "        # print(test_label_age)\n",
    "    \n",
    "        # print(text_out_tipo)\n",
    "        # print(test_label_tipo)\n",
    "    \n",
    "        # print(text_out_tecnica)\n",
    "        # print(test_label_tecnica)\n",
    "\n",
    "        # print(text_out_history)\n",
    "        # print(test_label_history)\n",
    "        \n",
    "        \n",
    "       \n",
    "        # print(f\"Accuracy: {accuracy:.2f}\")\n",
    "        \n",
    "        ind_fold={tipo: [key for key in ind if \"_\"+tipo in key] for tipo in questions}\n",
    "        for tipo in questions:\n",
    "            ind_cv[tipo].append(ind_fold[tipo])\n",
    "\n",
    "        valid_dataset={tipo: [report for key,report in examples_raw.items() if key in ind_fold[tipo]] for tipo in questions }\n",
    "        \n",
    "    \n",
    "        for tipo in questions:\n",
    "            if tipo in text_out:\n",
    "                print(f\"{tipo} errors\")\n",
    "                visualize_errors(valid_dataset[tipo],test_label[tipo],text_out[tipo],ind_fold[tipo])\n",
    "            else:\n",
    "                print(f\"{tipo} does not appear in this fold\")\n",
    "        \n",
    "    \n",
    "    \n",
    "                # Diccionario para almacenar accuracies por categoría\n",
    "        \n",
    "        # Calcular accuracies por categoría\n",
    "        for tipo in questions:\n",
    "            if tipo in text_out:\n",
    "                acc = accuracy_score(test_label[tipo], text_out[tipo])\n",
    "                accuracies_cv[tipo].append(acc)\n",
    "                print(f\"Accuracy for {tipo}: {acc:.4f}\")\n",
    "                preds_category_cv[tipo]+=text_out[tipo]\n",
    "                labels_category_cv[tipo]+=test_label[tipo]\n",
    "\n",
    "\n",
    "    \n",
    "    accuracies=[]    \n",
    "    output_dic={}\n",
    "    output_dic_t={}\n",
    "    for tipo in questions:\n",
    "        ind_cv[tipo]=np.concatenate(ind_cv[tipo])\n",
    "        acc = accuracy_score(labels_category_cv[tipo], preds_category_cv[tipo])\n",
    "        print(f\"Accuracy for {tipo}: {acc:.4f}\")\n",
    "        print(f\"Accuracy std for {tipo}: {np.std(accuracies_cv[tipo])}\")\n",
    "        accuracies.append(acc)\n",
    "        output_dic[tipo]={ind:preds_category_cv[tipo][i] for i, ind in enumerate(ind_cv[tipo])}\n",
    "        output_dic_t[tipo]={ind:labels_category_cv[tipo][i] for i, ind in enumerate(ind_cv[tipo])}\n",
    "        with open(f\"truth_dic/{tipo}.pkl\", \"wb\") as file:\n",
    "            pickle.dump(output_dic_t[tipo], file)\n",
    "        \n",
    "    \n",
    "    return accuracies,output_dic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
